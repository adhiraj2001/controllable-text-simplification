{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/aparna/miniconda3/envs/diffusion/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import csv\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "#Encoder-Decoder Model\n",
    "from transformers import EncoderDecoderModel\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import Trainer\n",
    "from evaluate import load\n",
    "#Training\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from transformers import  Seq2SeqTrainingArguments\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "from datasets import Dataset\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "bertscore = load(\"bertscore\") \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-small-finetuned-text-simplification\",cache_dir =\"/scratch/aparna\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mrm8488/t5-small-finetuned-text-simplification\",cache_dir =\"/scratch/aparna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/aparna/miniconda3/envs/diffusion/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/home2/aparna/miniconda3/envs/diffusion/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:377: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `120` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "0: A romantic friendship, passionate friendship, or affectionate friendship is a very close but typically non-sexual relationship between friends, often involving a degree of physical and emotional closeness.\n",
      "1: A romantic friendship, passionate friendship, or affectionate friendship is a very close but usually non-sexual relationship between friends, often involving a degree of physical and emotional closeness.\n",
      "2: A romantic friendship, passionate friendship, or affectionate friendship is a very close but typically non-sexual relationship between friends. SEP> It often involves a degree of physical and emotional closeness.\n",
      "3: A romantic friendship, passionate friendship, or affectionate friendship is a very close but usually non-sexual relationship between friends. SEP> It often involves a degree of physical and emotional closeness.\n",
      "4: A romantic friendship, passionate friendship, or affectionate friendship is a very close but typically non-sexual relationship between friends, often involving a degree of physical closeness beyond that which is common in the Western societies.\n",
      "5: A romantic friendship, passionate friendship, or affectionate friendship is a very close but usually non-sexual relationship between friends.\n",
      "6: A romantic friendship, passionate friendship, or affectionate friendship is a very close but typically non-sexual relationship between friends.\n",
      "7: A romantic friendship, passionate friendship, or affectionate friendship is a close but often non-sexual relationship between friends.\n",
      "8: A romantic friendship, passionate friendship, or affectionate friendship is a close but usually non-sexual relationship between friends.\n",
      "9: A romantic friendship, passionate friendship, or affectionate friendship is a relationship between friends.\n",
      "====================================\n",
      "0: The Alberta Junior Hockey League ( AJHL ) is an Alberta-based Junior A hockey league that belongs to the Canadian Junior Hockey League ( CJHL ).\n",
      "1: The Alberta Junior Hockey League ( AJHL ) is an Alberta-based ice hockey league that belongs to the Canadian Junior Hockey League ( CJHL ).\n",
      "2: The Alberta Junior Hockey League ( AJHL ) is an Alberta-based junior A hockey league that belongs to the Canadian Junior Hockey League ( CJHL ).\n",
      "3: The Alberta Junior Hockey League ( AJHL ) is an Alberta-based junior hockey league that belongs to the Canadian Junior Hockey League ( CJHL ).\n",
      "4: The Alberta Junior Hockey League ( AJHL ) is an Alberta-based Junior A ice hockey league that belongs to the Canadian Junior Hockey League.\n",
      "5: The Alberta Junior Hockey League ( AJHL ) is an Alberta-based Junior A ice hockey league.\n",
      "6: The Alberta Junior Hockey League ( AJHL ) is an Alberta-based Junior A hockey league. SEP> It belongs to the Canadian Junior Hockey League.\n",
      "7: The Alberta Junior Hockey League ( AJHL ) is an Alberta-based Junior A hockey league.\n",
      "8: The Alberta Junior Hockey League ( AJHL ) is a Canadian junior hockey league.\n",
      "9: The Alberta Junior Hockey League ( AJHL ) is a Canadian ice hockey league.\n",
      "====================================\n",
      "0: A switchgear is a combination of electrical switches, fuses or circuit breakers used to control, protect or isolate electrical equipment.\n",
      "1: A switchgear is a combination of electrical switches, fuses or circuit breakers used to control, protect and isolate electrical equipment.\n",
      "2: In an electric power system, switchgear is composed of electrical disconnect switches, fuses or circuit breakers used to control, protect and isolate electrical equipment.\n",
      "3: A switchgear is a combination of electrical switches, fuses and circuit breakers used to control, protect or isolate electrical equipment.\n",
      "4: A switchgear is a combination of electrical switches, fuses and circuit breakers used to control, protect and isolate electrical equipment.\n",
      "5: In an electric power system, switchgear is made of electrical disconnect switches, fuses or circuit breakers used to control, protect and isolate electrical equipment.\n",
      "6: A switchgear is a combination of electrical switches, fuses or circuit breakers used to control and isolate electrical equipment.\n",
      "7: A switchgear is a combination of electrical switches, fuses or circuit breakers used to control or isolate electrical equipment.\n",
      "8: In an electric power system, switchgear is composed of electrical disconnect switches, fuses or circuit breakers used to control, protect or isolate electrical equipment.\n",
      "9: In an electric power system, switchgear is a combination of electrical switches, fuses or circuit breakers used to control and isolate electrical equipment.\n"
     ]
    }
   ],
   "source": [
    "#generate\n",
    "texts= [\"A romantic friendship , passionate friendship , or affectionate friendship is a very close but typically non-sexual relationship between friends , often involving a degree of physical closeness beyond that which is common in the contemporary Western societies .\tA romantic friendship , passionate friendship or affectionate friendship is a close but non-sexual relationship between friends that often involves a degree of physical and emotional closeness.\",\"The Alberta Junior Hockey League ( AJHL ) is an Alberta-based Junior A ice hockey league that belongs to the Canadian Junior Hockey League ( CJHL ) .\tThe Alberta Junior Hockey League ( AJHL ) is an Alberta-based Junior A hockey league that belongs to the Canadian Junior Hockey League ( CJHL ) .\",\"In an electric power system , switchgear is composed of electrical disconnect switches , fuses or circuit breakers used to control , protect and isolate electrical equipment .\tA switchgear is a combination of electrical switches , fuses or circuit breakers used to control , protect or isolate electrical equipment.\"]\n",
    "\n",
    "for text in texts:\n",
    "    # encode the text into tensor of integers using the appropriate tokenizer\n",
    "    inputs = tokenizer.encode(\"paraphrase: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # generate text until the output length (which includes the context length) reaches 50\n",
    "    beam_output = model.generate(inputs, max_length=512, \n",
    "        num_beams=10, top_k=120, top_p=0.95, early_stopping=True, num_return_sequences=10)\n",
    "    print(\"====================================\")\n",
    "    for i, beam in enumerate(beam_output):\n",
    "        print(\"{}: {}\".format(i, tokenizer.decode(beam, skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "0: Passionate friendship is a close but non-sexual relationship between friends.\n",
      "1: Passionate friendship is a close relationship between friends.\n",
      "2: Passionate friendship is a close but non-sexual relationship between friends and family.\n",
      "3: Passionate friendship is a relationship between friends.\n",
      "4: Passionate friendship is a close but nonsexual relationship between friends.\n",
      "5: Passionate friendship is a close and non-sexual relationship between friends.\n",
      "6: Passionate friendship is a close but non-sexual relationship between friends and friends.\n",
      "7: Passionate friendship is a close friendship between friends.\n",
      "8: Passionate friendship is a relationship between friends and family.\n",
      "9: Passionate friendship is a close relationship between friends and family.\n",
      "====================================\n",
      "0: Electrical switches, fuses or circuit breakers were used to control, protect or isolate electrical equipment.\n",
      "1: Electrical switches, fuses and circuit breakers were used to control, protect or isolate electrical equipment.\n",
      "2: Electrical switches, fuses or circuit breaks were used to control, protect or isolate electrical equipment.\n",
      "3: Electrical switches, fuses or circuit breakers were used to control, protect or isolate electrical equipment.\n",
      "4: Electrical switches, fuses or circuit breakers were used to control, protect and isolate electrical equipment.\n",
      "5: Electric switches, fuses or circuit breakers were used to control, protect or isolate electrical equipment.\n",
      "6: Electrical switches, fuseries or circuit breakers were used to control, protect or isolate electrical equipment.\n",
      "7: Electrical switches, fuses or circuit breakers were used to control electrical equipment.\n",
      "8: Electrical switches, fuses or circuit breakers were used to control and protect electrical equipment.\n",
      "9: Electrical switches were used to control, protect or isolate electrical equipment.\n",
      "====================================\n",
      "0: A hockey league belongs to the Canadian Junior Hockey League.\n",
      "1: A hockey league is part of the Canadian Junior Hockey League.\n",
      "2: A hockey league belongs to the Canadian Junior Hockey League ( CHL ).\n",
      "3: A hockey league belongs to the Canadian Junior Hockey League ( CHL).\n",
      "4: A hockey league belongs to the Canadian Junior Hockey League ( NHL ).\n",
      "5: A hockey league belongs to the Canadian Junior Hockey League ( NHL).\n",
      "6: A hockey league belongs to the Canadian Junior Hockey League.\n",
      "7: A hockey league belongs to the Canadian Junior Hockey League (CHL).\n",
      "8: A hockey league belongs to the Canadian junior hockey league.\n",
      "9: A hockey league belongs to the Canadian Junior Hockey League (CHL ).\n"
     ]
    }
   ],
   "source": [
    "#generate\n",
    "texts= [\"Passionate friendship is a close but non-sexual relationship between friends\",\"Electrical switches , fuses or circuit breakers were used to control , protect or isolate electrical equipment.\",\"A hockey league belongs to the Canadian Junior Hockey League\"]\n",
    "\n",
    "for text in texts:\n",
    "    # encode the text into tensor of integers using the appropriate tokenizer\n",
    "    inputs = tokenizer.encode(\"paraphrase: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # generate text until the output length (which includes the context length) reaches 50\n",
    "    beam_output = model.generate(inputs, max_length=512, \n",
    "        num_beams=10, top_k=120, top_p=0.95, early_stopping=True, num_return_sequences=10)\n",
    "    print(\"====================================\")\n",
    "    for i, beam in enumerate(beam_output):\n",
    "        print(\"{}: {}\".format(i, tokenizer.decode(beam, skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]/tmp/ipykernel_20575/1962435399.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(input_ids).squeeze()\n",
      "/tmp/ipykernel_20575/1962435399.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(attention_mask).squeeze()\n",
      "/tmp/ipykernel_20575/1962435399.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_ids = torch.tensor(target_ids).squeeze()\n",
      "/tmp/ipykernel_20575/1962435399.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_attention_mask = torch.tensor(target_attention_mask).squeeze()\n",
      "Map: 100%|██████████| 20000/20000 [00:11<00:00, 1703.66 examples/s]\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from simpletransformers.t5 import T5Model, T5Args\n",
    "from transformers import pipeline\n",
    "#import train split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from google.transliteration import transliterate_word\n",
    "#import klib\n",
    "import os\n",
    "#bleu score\n",
    "from torchtext.data.metrics import bleu_score\n",
    "import csv\n",
    "colnames = ['source', 'target']\n",
    "input_file = \"train.tsv\"\n",
    "#df = pd.read_csv(input_file, sep=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8', header=None, names=colnames)\n",
    "test = pd.read_csv(\"valid.tsv\", sep=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8', header=None, names=colnames)\n",
    "test = Dataset.from_pandas(test)\n",
    "# %%\n",
    "#tokenize\n",
    "#tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-small\")\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': ['<sep>']})\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': ['<pad>']})\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': ['<s>']})\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': ['</s>']})\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': ['<unk>']})\n",
    "\n",
    "maxlen = 512\n",
    "def tokenize_df(df):\n",
    "    target = tokenizer(df['target'], padding='max_length', truncation=True, return_tensors=\"pt\", max_length=maxlen)\n",
    "    input = tokenizer(df['source'], padding='max_length', truncation=True, return_tensors=\"pt\", max_length=maxlen)\n",
    "    input_ids = input['input_ids']\n",
    "    attention_mask = input['attention_mask']\n",
    "    target_ids = target['input_ids']\n",
    "    target_attention_mask = target['attention_mask']\n",
    "    decoder_input_ids = target_ids.clone()\n",
    "    #convert to tensors\n",
    "    input_ids = torch.tensor(input_ids).squeeze()\n",
    "    attention_mask = torch.tensor(attention_mask).squeeze()\n",
    "    target_ids = torch.tensor(target_ids).squeeze()\n",
    "    target_attention_mask = torch.tensor(target_attention_mask).squeeze()\n",
    "   # decoder_input_ids = torch.tensor(decoder_input_ids)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': target_ids,\n",
    "        #'decoder_input_ids': decoder_input_ids,\n",
    "        #'decoder_attention_mask': target_attention_mask\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# train = load_dataset('csv', data_files='train.csv')\n",
    "# val = load_dataset('csv', data_files='val.csv')\n",
    "# test = load_dataset('csv', data_files='test.csv')\n",
    "# train = train.map(tokenize_df, batched=True, batch_size=128,remove_columns=['sentence','english_translation'])\n",
    "# val = val.map(tokenize_df, batched=True, batch_size=128,remove_columns=['sentence','english_translation'])\n",
    "test = test.map(tokenize_df, batched=True, batch_size=128,remove_columns=['source','target'])\n",
    "\n",
    "\n",
    "# %%\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def tokenize_sentence(arg):\n",
    "    encoded_arg =tokenizer(arg)\n",
    "    return tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
    "\n",
    "def metrics_func(eval_arg):\n",
    "    preds, labels = eval_arg\n",
    "    # Replace -100\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # Convert id tokens to text\n",
    "    text_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    text_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # Insert a line break (\\n) in each sentence for ROUGE scoring\n",
    "    # (Note : Please change this code, when you perform on other languages except for Japanese)\n",
    "    text_preds = [(p if p.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else p + \"。\") for p in text_preds]\n",
    "    text_labels = [(l if l.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else l + \"。\") for l in text_labels]\n",
    "    sent_tokenizer_jp = RegexpTokenizer(u'[^!！?？。]*[!！?？。]')\n",
    "    text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(p))) for p in text_preds]\n",
    "    text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(l))) for l in text_labels]\n",
    "    # compute ROUGE score with custom tokenization\n",
    "    #blue score\n",
    "    texts_bleu =[text.strip() for text in text_preds]\n",
    "    labels_bleu = [[text.strip()] for text in text_labels]\n",
    "    result = bleu_metric.compute(predictions=texts_bleu, references=labels_bleu)\n",
    "    return rouge_metric.compute(\n",
    "        predictions=text_preds,\n",
    "        references=text_labels,\n",
    "        tokenizer=tokenize_sentence\n",
    "    ), result['score']\n",
    "\n",
    "# %%\n",
    "from torch.utils.data import DataLoader\n",
    "#tokenizer = MT5Tokenizer.from_pretrained(\"./mt5\")\n",
    "def testing(model):\n",
    "    metrics =[]\n",
    "    sample_dataloader = DataLoader(\n",
    "      test.with_format(\"torch\"),\n",
    "      collate_fn=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
    "      batch_size=5)\n",
    "    for batch in sample_dataloader:\n",
    "      with torch.no_grad():\n",
    "        preds = model.generate(\n",
    "          batch[\"input_ids\"],\n",
    "          num_beams=15,\n",
    "          num_return_sequences=1,\n",
    "          no_repeat_ngram_size=1,\n",
    "          remove_invalid_values=True,\n",
    "          max_length=128,\n",
    "        )\n",
    "      labels = batch[\"labels\"]\n",
    "      metric = metrics_func([preds, labels])\n",
    "      metrics.append(metric)\n",
    "    return metrics\n",
    "\n",
    "def average_metric(metrics):\n",
    "    rouge = 0\n",
    "    rouge2 = 0\n",
    "    rougeL = 0\n",
    "    rougeLsum = 0\n",
    "    bleu = 0\n",
    "    for metric in metrics:\n",
    "        rouge += metric[0]['rouge1']\n",
    "        rouge2 += metric[0]['rouge2']\n",
    "        rougeL += metric[0]['rougeL']\n",
    "        rougeLsum += metric[0]['rougeLsum']\n",
    "        bleu += metric[1]\n",
    "    return rouge/len(metrics),rouge2/len(metrics),rougeL/len(metrics),rougeLsum/len(metrics),bleu/len(metrics)\n",
    "      \n",
    "\n",
    "# %%\n",
    "\n",
    "metrics = testing(model)\n",
    "\n",
    "# %%\n",
    "print(\"t5_small\")\n",
    "scores = average_metric(metrics)\n",
    "print(\"rouge:\",scores[0])\n",
    "print(\"rouge2:\",scores[1])\n",
    "print(\"rougeL:\",scores[2])\n",
    "print(\"rougeLsum:\",scores[3])\n",
    "print(\"bleu:\",scores[4])\n",
    "\n",
    "\n",
    "# %%\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Predict with test data (first 5 rows)\n",
    "sample_dataloader = DataLoader(\n",
    "  test.with_format(\"torch\"),\n",
    "  collate_fn=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
    "  batch_size=5)\n",
    "for batch in sample_dataloader:\n",
    "  with torch.no_grad():\n",
    "    preds = model.generate(\n",
    "      batch[\"input_ids\"],\n",
    "      num_beams=15,\n",
    "      num_return_sequences=1,\n",
    "      no_repeat_ngram_size=1,\n",
    "      remove_invalid_values=True,\n",
    "      max_length=128,\n",
    "    )\n",
    "  labels = batch[\"labels\"]\n",
    "  inputs = batch[\"input_ids\"]\n",
    "  break\n",
    "\n",
    "# Replace -100 (see above)\n",
    "inputs = np.where(inputs != -100, inputs, tokenizer.pad_token_id)\n",
    "labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "# Convert id tokens to text\n",
    "text_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "text_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "text_inputs = tokenizer.batch_decode(inputs, skip_special_tokens=True)\n",
    "#print(bleu_score(list(text_labels.split()),list(text_preds.split())))\n",
    "\n",
    "# Show result\n",
    "print(\"***** Input's Text *****\")\n",
    "print(text_inputs[2])\n",
    "print(\"***** summmary (True Value) *****\")\n",
    "print(text_labels[2])\n",
    "print(\"***** summary (Generated Text) *****\")\n",
    "print(text_preds[2])\n",
    "\n",
    "# %%\n",
    "for i in range(5):\n",
    "    print(\"***** Input's Text *****\")\n",
    "    print(text_inputs[i])\n",
    "    print(\"***** summarry (True Value) *****\")\n",
    "    print(text_labels[i])\n",
    "    print(\"***** summary (Generated Text) *****\")\n",
    "    print(text_preds[i])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
