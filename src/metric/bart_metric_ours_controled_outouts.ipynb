{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import transformers\n",
    "import torch\n",
    "# bertscore = load(\"bertscore\") \n",
    "tokenizer =  AutoTokenizer.from_pretrained('/ssd_scratch/cvit/aparna/control_bart/checkpoint-6000',cache_dir='/ssd_scratch/cvit/aparna/bart')\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained('/ssd_scratch/cvit/aparna/results/checkpoint-6000',cache_dir='/ssd_scratch/cvit/aparna/bart').to('cuda:1')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('/ssd_scratch/cvit/aparna/control_bart/checkpoint-6000',cache_dir='/ssd_scratch/cvit/aparna/bart').to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.35.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "sari_metric = evaluate.load(\"sari\")\n",
    "\n",
    "def tokenize_sentence(arg):\n",
    "    encoded_arg =tokenizer(arg)\n",
    "    return tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
    "\n",
    "def metrics_func(eval_arg):\n",
    "    print(len(eval_arg[0]),len(eval_arg[1]),len(eval_arg[2]))\n",
    "    print(len(eval_arg))\n",
    "    text_inputs = eval_arg[0]\n",
    "    text_preds = eval_arg[1]\n",
    "    text_labels = eval_arg[2]\n",
    "    texts_bleu =[text.strip() for text in text_preds]\n",
    "    labels_bleu = [[text.strip()] for text in text_labels[0]]\n",
    "    result = bleu_metric.compute(predictions=texts_bleu, references=text_inputs)\n",
    "    return result[\"score\"],sari_metric.compute(\n",
    "        predictions=text_preds,\n",
    "        references=text_labels,\n",
    "        sources=text_inputs,\n",
    "    )['sari']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_encoder = model.get_encoder()\n",
    "the_decoder = model.get_decoder()\n",
    "\n",
    "last_linear_layer = model.lm_head\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/10/test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours copy.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m test_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m../../data/10/test.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m test_data \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39mdropna()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m test_data \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/10/test.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_data = pd.read_csv(\"../../data/10/test.csv\")\n",
    "test_data = test_data.dropna()\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "#take 1000 samples\n",
    "test_data = test_data[:10000]\n",
    "texts = test_data[\"source\"].tolist()\n",
    "labels = test_data[\"target\"].tolist()\n",
    "\n",
    "\n",
    "metrics =[]\n",
    "inpu = []\n",
    "cands = []\n",
    "lab = []\n",
    "max_l = 512\n",
    "num_b = 10\n",
    "num_sub_b =1\n",
    "\n",
    "for  i  in tqdm(range(len(texts))):\n",
    "    text = texts[i]\n",
    "    # encode the text into tensor of integers using the appropriate tokenizer\n",
    "    inputs = tokenizer.encode(\"paraphrase: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # generate text until the output length (which includes the context length) reaches 50\n",
    "    beam_outputs = model.generate(inputs,max_length=max_l,num_beams=num_b,early_stopping=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        num_return_sequences=num_b,\n",
    "        top_k=4, top_p=0.95\n",
    "        # return_dict_in_generate=True,\n",
    "    )\n",
    "   # print(\"====================================\")\n",
    "    inpu.extend([text]*10)\n",
    "    c =[]\n",
    "    for x, beam in enumerate(beam_outputs):\n",
    "        #print(\"{}\".format(i, tokenizer.decode(beam, skip_special_tokens=True)))\n",
    "        c.append(tokenizer.decode(beam, skip_special_tokens=True))\n",
    "    cands.extend(c)\n",
    "    lab.extend([[labels[i]]]*10)\n",
    "    eval_arg = [inpu,cands,lab]\n",
    "    if i%100==0:\n",
    "        metric = metrics_func(eval_arg)\n",
    "        print(metric)\n",
    "\n",
    "\n",
    "print(len(inpu),len(cands),len(lab))\n",
    "metric = metrics_func(eval_arg)\n",
    "print(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>TheThe is� is� is town is mostly made of mud houses and small canals that supply water.</s>']\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "text = \"'<copy_1.0> <levsim_0.8> <cratio_0.8> The town is mostly constituted of mud houses and small canals that supply water.'\"\n",
    "    # encode the text into tensor of integers using the appropriate tokenizer\n",
    "input_ids  = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True).to('cuda:1')\n",
    "#input_ids = tokenizer(inpu, return_tensors='pt', padding=True).input_ids\n",
    "\n",
    "print(tokenizer.batch_decode(torch.argmax(model(input_ids = input_ids)[0], axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/aparna/miniconda3/envs/new/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/home2/aparna/miniconda3/envs/new/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:396: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `4` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The town is mostly made up of mud houses and small canals that supply water.\n",
      "1 The town is mostly made of mud houses and small canals that supply water.\n",
      "2 The town is made up of mud houses and small canals that supply water.\n",
      "3 It is mostly made up of mud houses and small canals that supply water.\n",
      "4 It is made up of mud houses and small canals that supply water.\n",
      "5 The town is made of mud houses and small canals that supply water.\n",
      "6 It is mostly made of mud houses and small canals that supply water.\n",
      "7 The town is mainly made up of mud houses and small canals that supply water.\n",
      "8 The town is mostly made up of mud houses and small canals.\n",
      "9 The town is mostly made up of mud houses and small canals that provide water.\n"
     ]
    }
   ],
   "source": [
    "max_l = 512\n",
    "num_b = 10\n",
    "num_sub_b =1\n",
    "text = \"<copy_1.0> <levsim_0.8> <cratio_0.8> The town is mostly constituted of mud houses and small canals that supply water.\"\n",
    "    # encode the text into tensor of integers using the appropriate tokenizer\n",
    "inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True).to('cuda:1')\n",
    "\n",
    "    # generate text until the output length (which includes the context length) reaches 50\n",
    "beam_outputs = model.generate(inputs,max_length=max_l,num_beams=num_b,early_stopping=True,\n",
    "    no_repeat_ngram_size=3,\n",
    "    num_return_sequences=10,\n",
    "    top_k=4, top_p=0.95\n",
    "    # return_dict_in_generate=True,\n",
    ")\n",
    "for x, beam in enumerate(beam_outputs):\n",
    "    print(\"{} {}\".format(x, tokenizer.decode(beam, skip_special_tokens=True, clean_up_tokenization_spaces=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<copy_0.1> <levsim_0.1> <cratio_0.1> The town is mostly made up of mud houses and canals.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.2> It has mud houses and canals.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.3> The town is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.4> The town is mostly made of mud houses and canals.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.5> The town is mostly made up of mud houses and canals.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.6> The town is mostly made of mud houses.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.7> The town is mostly made of mud houses and small canals.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.8> The town is mostly made up of mud houses and small canals.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.9> The town is mostly made up of mud houses and small canals that supply water.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.1> It has mud houses and canals.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.2> It is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.3> It is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.4> It has mud houses and canals.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.5> It has mud houses and canals.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.6> The town is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.7> The town is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.8> It has mud houses and canals.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.9> It is made up of mud houses and canals.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.1> The town is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.2> It is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.3> The town is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.4> The town is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.5> The town is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.6> The town is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.7> It is mostly made up of mud houses.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.8> The town is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.9> It has mud houses and small canals.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.1> The town is made up of mud houses and canals.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.2> It has mud houses and canals.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.3> The town is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.4> The town is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.5> The town is made up of mud houses and canals.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.6> The town is mostly mud houses.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.7> The town is mostly made up of mud houses.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.8> The town is mostly made up of mud houses and small canals.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.9> The town is mostly made up of mud houses and small canals.\n",
      "<copy_0.1> <levsim_0.5> <cratio_0.1> It is mostly made up of mud houses and canals.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours copy.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode( text, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, max_length\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda:1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m# generate text until the output length (which includes the context length) reaches 50\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m beam_outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(inputs,max_length\u001b[39m=\u001b[39;49mmax_l,num_beams\u001b[39m=\u001b[39;49mnum_b,early_stopping\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     no_repeat_ngram_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     top_k\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, top_p\u001b[39m=\u001b[39;49m\u001b[39m0.95\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# return_dict_in_generate=True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<copy_0.\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m> <levsim_0.\u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m> <cratio_0.\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m, tokenizer\u001b[39m.\u001b[39mdecode(beam_outputs[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)))\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/transformers/generation/utils.py:1752\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1746\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1747\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_beams,\n\u001b[1;32m   1748\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1749\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1750\u001b[0m     )\n\u001b[1;32m   1751\u001b[0m     \u001b[39m# 13. run beam search\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[1;32m   1753\u001b[0m         input_ids,\n\u001b[1;32m   1754\u001b[0m         beam_scorer,\n\u001b[1;32m   1755\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1756\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1757\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1758\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1759\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1760\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1761\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1762\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1763\u001b[0m     )\n\u001b[1;32m   1765\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mBEAM_SAMPLE:\n\u001b[1;32m   1766\u001b[0m     \u001b[39m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(generation_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/transformers/generation/utils.py:3107\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3102\u001b[0m next_token_logits \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlogits[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[1;32m   3103\u001b[0m next_token_scores \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mlog_softmax(\n\u001b[1;32m   3104\u001b[0m     next_token_logits, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   3105\u001b[0m )  \u001b[39m# (batch_size * num_beams, vocab_size)\u001b[39;00m\n\u001b[0;32m-> 3107\u001b[0m next_token_scores_processed \u001b[39m=\u001b[39m logits_processor(input_ids, next_token_scores)\n\u001b[1;32m   3108\u001b[0m next_token_scores \u001b[39m=\u001b[39m next_token_scores_processed \u001b[39m+\u001b[39m beam_scores[:, \u001b[39mNone\u001b[39;00m]\u001b[39m.\u001b[39mexpand_as(\n\u001b[1;32m   3109\u001b[0m     next_token_scores_processed\n\u001b[1;32m   3110\u001b[0m )\n\u001b[1;32m   3112\u001b[0m \u001b[39m# Store scores, attentions and hidden_states when required\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/transformers/generation/logits_process.py:97\u001b[0m, in \u001b[0;36mLogitsProcessorList.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         scores \u001b[39m=\u001b[39m processor(input_ids, scores, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     96\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m         scores \u001b[39m=\u001b[39m processor(input_ids, scores)\n\u001b[1;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/transformers/generation/logits_process.py:1259\u001b[0m, in \u001b[0;36mForcedBOSTokenLogitsProcessor.__call__\u001b[0;34m(self, input_ids, scores)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[39mif\u001b[39;00m cur_len \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1258\u001b[0m     num_tokens \u001b[39m=\u001b[39m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m-> 1259\u001b[0m     scores[:, [i \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(num_tokens) \u001b[39mif\u001b[39;49;00m i \u001b[39m!=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbos_token_id]] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1260\u001b[0m     scores[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbos_token_id] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1261\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#get output for diffrent combination of copy and lev and cratio\n",
    "for i in range(1,10):\n",
    "    for j in range(1,10):\n",
    "        for k in range(1,10):\n",
    "            text = \"<copy_0.{}> <levsim_0.{}> <cratio_0.{}> The town is mostly constituted of mud houses and small canals that supply water.\".format(i,j,k)\n",
    "            # encode the text into tensor of integers using the appropriate tokenizer\n",
    "            inputs = tokenizer.encode( text, return_tensors=\"pt\", max_length=512, truncation=True).to('cuda:1')\n",
    "                \n",
    "                    # generate text until the output length (which includes the context length) reaches 50\n",
    "            beam_outputs = model.generate(inputs,max_length=max_l,num_beams=num_b,early_stopping=True,\n",
    "                no_repeat_ngram_size=3,\n",
    "                num_return_sequences=10,\n",
    "                top_k=4, top_p=0.95\n",
    "                # return_dict_in_generate=True,\n",
    "            )\n",
    "       \n",
    "            print(\"{} {}\".format(f\"<copy_0.{i}> <levsim_0.{j}> <cratio_0.{k}>\", tokenizer.decode(beam_outputs[0], skip_special_tokens=True)))\n",
    "                \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 China's air pollution is very bad for human health.\n",
      "1 China's air pollution is very bad.\n",
      "2 China's air pollution is very harmful to human health.\n",
      "3 China's air pollution has a lot of health problems.\n",
      "4 China's air pollution affects human health.\n",
      "5 China's air pollution causes a lot of problems.\n",
      "6 China's air pollution causes a lot of health problems.\n",
      "7 China's air pollution is a huge problem.\n",
      "8 China's air pollution is very bad for health.\n",
      "9 China's air pollution is a very bad thing.\n"
     ]
    }
   ],
   "source": [
    "text = \"<copy_0.5> <levsim_0.8> <cratio_0.8> Experts say China's air pollution exacts a tremendous toll on human health.\"\n",
    "    # encode the text into tensor of integers using the appropriate tokenizer\n",
    "inputs = tokenizer.encode(\"paraphrase: \" + text, return_tensors=\"pt\", max_length=512, truncation=True).to('cuda:1')\n",
    "\n",
    "    # generate text until the output length (which includes the context length) reaches 50\n",
    "beam_outputs = model.generate(inputs,max_length=max_l,num_beams=num_b,early_stopping=True,\n",
    "    no_repeat_ngram_size=3,\n",
    "    num_return_sequences=10,\n",
    "    top_k=4, top_p=0.95\n",
    "    # return_dict_in_generate=True,\n",
    ")\n",
    "for x, beam in enumerate(beam_outputs):\n",
    "    print(\"{} {}\".format(x, tokenizer.decode(beam, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<copy_0.1> <levsim_0.1> <cratio_0.1> China's air pollution is very bad for human health.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.2> There is a lot of air pollution in China.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.3> It has a huge toll on human health.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.4> China's air pollution has a huge toll on human health.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.5> China's air pollution has a huge toll on human health.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.6> Experts say China's air pollution is very bad.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.7> Experts say China's air pollution has a huge toll on human health.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.8> China's air pollution has a huge toll on human health.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.9> China's air pollution has a huge toll on human health.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.1> There is a lot of air pollution in China.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.2> There is a lot of air pollution.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.3> China's air pollution is very bad.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.4> There is a lot of air pollution in China.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.5> There is a lot of air pollution in China.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.6> There is a lot of air pollution in China.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.7> There is a lot of air pollution in China.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.8> There is a lot of air pollution in China.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.9> There is a lot of air pollution in China.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.1> China's air pollution is very bad.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.2> China's air pollution is very bad.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.3> China's air pollution is very bad.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.4> It has a huge toll on human health.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.5> China's air pollution is very bad.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.6> China's air pollution is very bad.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.7> China's air pollution is very bad.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours copy.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode( text, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, max_length\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda:1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m# generate text until the output length (which includes the context length) reaches 50\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m beam_outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(inputs,max_length\u001b[39m=\u001b[39;49mmax_l,num_beams\u001b[39m=\u001b[39;49mnum_b,early_stopping\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     no_repeat_ngram_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     top_k\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, top_p\u001b[39m=\u001b[39;49m\u001b[39m0.95\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# return_dict_in_generate=True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgnode052/home2/aparna/ANLP-Poject/ANLP-Project/src/metric/bart_metric_ours%20copy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<copy_0.\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m> <levsim_0.\u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m> <cratio_0.\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m, tokenizer\u001b[39m.\u001b[39mdecode(beam_outputs[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)))\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/transformers/generation/utils.py:1752\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1746\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1747\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_beams,\n\u001b[1;32m   1748\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1749\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1750\u001b[0m     )\n\u001b[1;32m   1751\u001b[0m     \u001b[39m# 13. run beam search\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[1;32m   1753\u001b[0m         input_ids,\n\u001b[1;32m   1754\u001b[0m         beam_scorer,\n\u001b[1;32m   1755\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1756\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1757\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1758\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1759\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1760\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1761\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1762\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1763\u001b[0m     )\n\u001b[1;32m   1765\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mBEAM_SAMPLE:\n\u001b[1;32m   1766\u001b[0m     \u001b[39m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(generation_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/transformers/generation/utils.py:3091\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3087\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   3089\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> 3091\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   3092\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   3093\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   3094\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   3095\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   3096\u001b[0m )\n\u001b[1;32m   3098\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3099\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py:1577\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1572\u001b[0m     \u001b[39mif\u001b[39;00m decoder_input_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m decoder_inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1573\u001b[0m         decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1574\u001b[0m             labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1575\u001b[0m         )\n\u001b[0;32m-> 1577\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1578\u001b[0m     input_ids,\n\u001b[1;32m   1579\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1580\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1581\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m   1582\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1583\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1584\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1585\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1586\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1587\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1588\u001b[0m     decoder_inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1589\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1590\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1591\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1592\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1593\u001b[0m )\n\u001b[1;32m   1595\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(outputs[\u001b[39m0\u001b[39m])\n\u001b[1;32m   1596\u001b[0m lm_logits \u001b[39m=\u001b[39m lm_logits \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_logits_bias\u001b[39m.\u001b[39mto(lm_logits\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py:1463\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1457\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   1458\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1459\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1460\u001b[0m     )\n\u001b[1;32m   1462\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1463\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1464\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1465\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1466\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_outputs[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m   1467\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1468\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1469\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1470\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1471\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1472\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1473\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1474\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1475\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1476\u001b[0m )\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1479\u001b[0m     \u001b[39mreturn\u001b[39;00m decoder_outputs \u001b[39m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py:1316\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1304\u001b[0m         decoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m   1305\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         use_cache,\n\u001b[1;32m   1314\u001b[0m     )\n\u001b[1;32m   1315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1316\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m   1317\u001b[0m         hidden_states,\n\u001b[1;32m   1318\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1319\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1320\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1321\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1322\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49m(\n\u001b[1;32m   1323\u001b[0m             cross_attn_head_mask[idx] \u001b[39mif\u001b[39;49;00m cross_attn_head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m   1324\u001b[0m         ),\n\u001b[1;32m   1325\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1326\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1327\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1328\u001b[0m     )\n\u001b[1;32m   1329\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1331\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py:655\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[39m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m    654\u001b[0m cross_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 655\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_attn(\n\u001b[1;32m    656\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    657\u001b[0m     key_value_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    658\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    659\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m    660\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mcross_attn_past_key_value,\n\u001b[1;32m    661\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    662\u001b[0m )\n\u001b[1;32m    663\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m    664\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/transformers/models/bart/modeling_bart.py:270\u001b[0m, in \u001b[0;36mBartAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    266\u001b[0m     attn_weights_reshaped \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    268\u001b[0m attn_probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(attn_weights, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m--> 270\u001b[0m attn_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbmm(attn_probs, value_states)\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m attn_output\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m (bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, tgt_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim):\n\u001b[1;32m    273\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    274\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`attn_output` should be of size \u001b[39m\u001b[39m{\u001b[39;00m(bsz\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\u001b[39m \u001b[39mtgt_len,\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\u001b[39m}\u001b[39;00m\u001b[39m, but is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mattn_output\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#get output for diffrent combination of copy and lev and cratio\n",
    "for i in range(1,10):\n",
    "    for j in range(1,10):\n",
    "        for k in range(1,10):\n",
    "            text = \"<copy_0.{}> <levsim_0.{}> <cratio_0.{}> Experts say China's air pollution exacts a tremendous toll on human health.\".format(i,j,k)\n",
    "            # encode the text into tensor of integers using the appropriate tokenizer\n",
    "            inputs = tokenizer.encode( text, return_tensors=\"pt\", max_length=512, truncation=True).to('cuda:1')\n",
    "                \n",
    "                    # generate text until the output length (which includes the context length) reaches 50\n",
    "            beam_outputs = model.generate(inputs,max_length=max_l,num_beams=num_b,early_stopping=True,\n",
    "                no_repeat_ngram_size=3,\n",
    "                num_return_sequences=10,\n",
    "                top_k=4, top_p=0.95\n",
    "                # return_dict_in_generate=True,\n",
    "            )\n",
    "       \n",
    "            print(\"{} {}\".format(f\"<copy_0.{i}> <levsim_0.{j}> <cratio_0.{k}>\", tokenizer.decode(beam_outputs[0], skip_special_tokens=True)))\n",
    "                \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<copy_0.1> <levsim_0.1> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.1> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.3> The ship was built in 2010.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.5> It was found in portugal in 2010.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.8> The ship was found in portugal in 2010.\n",
      "<copy_0.1> <levsim_0.2> <cratio_0.9> The ship was found in portugal in 2010.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.1> Since 2010, the ship has been discovered.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.3> Since 2010, the project has uncovered documents.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.4> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.5> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.6> The project has uncovered documents in portugal.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.8> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.3> <cratio_0.9> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.1> The ship was found in portugal in 2010.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.4> The ship was found in portugal in 2010.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.5> The ship was found in portugal in 2010.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.6> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.7> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.8> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.4> <cratio_0.9> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.5> <cratio_0.1> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.1> <levsim_0.5> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.1> <levsim_0.5> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.1> <levsim_0.5> <cratio_0.4> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.1> <levsim_0.5> <cratio_0.5> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.1> <levsim_0.5> <cratio_0.6> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.5> <cratio_0.7> Since 2010, project researchers have found documents that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.5> <cratio_0.8> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.5> <cratio_0.9> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.6> <cratio_0.1> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.6> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.1> <levsim_0.6> <cratio_0.3> The project has uncovered documents in portugal.\n",
      "<copy_0.1> <levsim_0.6> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.6> <cratio_0.5> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.6> <cratio_0.6> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.6> <cratio_0.7> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.6> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.6> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.7> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.7> <cratio_0.2> Since 2010, the ship has been discovered.\n",
      "<copy_0.1> <levsim_0.7> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.7> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.7> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.7> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.7> <cratio_0.7> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.7> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.7> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.8> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.8> <cratio_0.2> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.8> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.8> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.8> <cratio_0.5> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.8> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.8> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.8> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.1> <levsim_0.8> <cratio_0.9> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.1> <levsim_0.9> <cratio_0.1> Since 2010, project researchers have uncovered documents in portugal that reveal who owned the ship.\n",
      "<copy_0.1> <levsim_0.9> <cratio_0.2> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.9> <cratio_0.3> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.9> <cratio_0.4> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.1> <levsim_0.9> <cratio_0.5> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.1> <levsim_0.9> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.1> <levsim_0.9> <cratio_0.7> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.1> <levsim_0.9> <cratio_0.8> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.1> <levsim_0.9> <cratio_0.9> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.2> <levsim_0.1> <cratio_0.1> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.1> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.2> <levsim_0.1> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.1> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.1> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.1> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.1> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.1> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.1> <cratio_0.9> Since 2010, project researchers have found documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.2> <levsim_0.2> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.2> <levsim_0.2> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.2> <levsim_0.2> <cratio_0.3> The ship was built in 2010.\n",
      "<copy_0.2> <levsim_0.2> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.2> <levsim_0.2> <cratio_0.5> It was discovered in 2010.\n",
      "<copy_0.2> <levsim_0.2> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.2> <levsim_0.2> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.2> <levsim_0.2> <cratio_0.8> The ship was found in portugal in 2010.\n",
      "<copy_0.2> <levsim_0.2> <cratio_0.9> The ship was found in portugal in 2010.\n",
      "<copy_0.2> <levsim_0.3> <cratio_0.1> It was found in portugal in 2010.\n",
      "<copy_0.2> <levsim_0.3> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.2> <levsim_0.3> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.2> <levsim_0.3> <cratio_0.4> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.3> <cratio_0.5> Since 2010, the ship has been discovered.\n",
      "<copy_0.2> <levsim_0.3> <cratio_0.6> Since 2010, the project has uncovered documents.\n",
      "<copy_0.2> <levsim_0.3> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.3> <cratio_0.8> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.3> <cratio_0.9> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.4> <cratio_0.1> The ship was found in portugal in 2010.\n",
      "<copy_0.2> <levsim_0.4> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.2> <levsim_0.4> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.2> <levsim_0.4> <cratio_0.4> The ship was found in portugal in 2010.\n",
      "<copy_0.2> <levsim_0.4> <cratio_0.5> The ship was found in portugal in 2010.\n",
      "<copy_0.2> <levsim_0.4> <cratio_0.6> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.2> <levsim_0.4> <cratio_0.7> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.4> <cratio_0.8> The ship was found in portugal in 2010.\n",
      "<SEP> In 2010, the ship was discovered.\n",
      "<copy_0.2> <levsim_0.4> <cratio_0.9> The ship was found in portugal in 2010.\n",
      "<SEP> In 2010, the ship was discovered.\n",
      "<copy_0.2> <levsim_0.5> <cratio_0.1> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.2> <levsim_0.5> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.2> <levsim_0.5> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.2> <levsim_0.5> <cratio_0.4> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.5> <cratio_0.5> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.2> <levsim_0.5> <cratio_0.6> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.5> <cratio_0.7> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.5> <cratio_0.8> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.5> <cratio_0.9> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.6> <cratio_0.1> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.6> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.2> <levsim_0.6> <cratio_0.3> Since 2010, the project has uncovered documents.\n",
      "<copy_0.2> <levsim_0.6> <cratio_0.4> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.6> <cratio_0.5> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.6> <cratio_0.6> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.6> <cratio_0.7> Since 2010, project researchers have found documents that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.6> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.6> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.7> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.7> <cratio_0.2> It was found in portugal in 2010.\n",
      "<copy_0.2> <levsim_0.7> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.7> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.7> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.7> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.7> <cratio_0.7> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.7> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.7> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.8> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.8> <cratio_0.2> Since 2010, the ship has been discovered.\n",
      "<copy_0.2> <levsim_0.8> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.8> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.8> <cratio_0.5> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.8> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.8> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.8> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.2> <levsim_0.8> <cratio_0.9> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.2> <levsim_0.9> <cratio_0.1> Since 2010, project researchers have uncovered documents in portugal that reveal who owned the ship.\n",
      "<copy_0.2> <levsim_0.9> <cratio_0.2> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.9> <cratio_0.3> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.9> <cratio_0.4> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.2> <levsim_0.9> <cratio_0.5> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.2> <levsim_0.9> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.2> <levsim_0.9> <cratio_0.7> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.2> <levsim_0.9> <cratio_0.8> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.2> <levsim_0.9> <cratio_0.9> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.3> <levsim_0.1> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.1> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.3> <levsim_0.1> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.1> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.1> <cratio_0.5> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.1> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.1> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.1> <cratio_0.8> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.1> <cratio_0.9> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.2> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.2> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.3> <levsim_0.2> <cratio_0.3> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.2> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.2> <cratio_0.5> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.2> <cratio_0.6> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.2> <cratio_0.7> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.2> <cratio_0.8> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.2> <cratio_0.9> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.3> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.3> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.3> <levsim_0.3> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.3> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.3> <cratio_0.5> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.3> <cratio_0.6> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.3> <cratio_0.7> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.3> <cratio_0.8> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.3> <cratio_0.9> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.4> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.4> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.3> <levsim_0.4> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.4> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.4> <cratio_0.5> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.4> <cratio_0.6> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.4> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.4> <cratio_0.8> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.4> <cratio_0.9> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.5> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.5> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.3> <levsim_0.5> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.5> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.5> <cratio_0.5> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.5> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.5> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.5> <cratio_0.8> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.5> <cratio_0.9> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.6> <cratio_0.1> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.6> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.6> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.6> <cratio_0.4> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.6> <cratio_0.5> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.6> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.6> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.6> <cratio_0.8> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.6> <cratio_0.9> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.7> <cratio_0.1> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.7> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.7> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.7> <cratio_0.4> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.7> <cratio_0.5> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.7> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.7> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.3> <levsim_0.7> <cratio_0.8> The project has uncovered documents in portugal.\n",
      "<copy_0.3> <levsim_0.7> <cratio_0.9> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.3> <levsim_0.8> <cratio_0.1> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.8> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.3> <levsim_0.8> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.3> <levsim_0.8> <cratio_0.4> It was discovered in 2010.\n",
      "<copy_0.3> <levsim_0.8> <cratio_0.5> Since 2010, the ship has been discovered.\n",
      "<copy_0.3> <levsim_0.8> <cratio_0.6> The project has uncovered documents in portugal.\n",
      "<copy_0.3> <levsim_0.8> <cratio_0.7> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.3> <levsim_0.8> <cratio_0.8> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.3> <levsim_0.8> <cratio_0.9> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.3> <levsim_0.9> <cratio_0.1> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.3> <levsim_0.9> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.3> <levsim_0.9> <cratio_0.3> Since 2010, project researchers have uncovered documents.\n",
      "<copy_0.3> <levsim_0.9> <cratio_0.4> Since 2010, project researchers have uncovered the ship.\n",
      "<copy_0.3> <levsim_0.9> <cratio_0.5> Since 2010, project researchers have uncovered the ship.\n",
      "<copy_0.3> <levsim_0.9> <cratio_0.6> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.3> <levsim_0.9> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.3> <levsim_0.9> <cratio_0.8> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.3> <levsim_0.9> <cratio_0.9> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.1> <cratio_0.1> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.4> <levsim_0.1> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.1> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.4> <levsim_0.1> <cratio_0.4> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.1> <cratio_0.5> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.1> <cratio_0.6> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.1> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.1> <cratio_0.8> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.1> <cratio_0.9> Since 2010, project researchers have found documents that show who owned the ship.\n",
      "<copy_0.4> <levsim_0.2> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.2> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.4> <levsim_0.2> <cratio_0.3> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.2> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.2> <cratio_0.5> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.2> <cratio_0.6> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.2> <cratio_0.7> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.2> <cratio_0.8> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.2> <cratio_0.9> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.3> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.3> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.4> <levsim_0.3> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.4> <levsim_0.3> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.3> <cratio_0.5> It was discovered in 2010.\n",
      "<copy_0.4> <levsim_0.3> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.3> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.3> <cratio_0.8> It was discovered in 2010.\n",
      "<copy_0.4> <levsim_0.3> <cratio_0.9> It was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.4> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.4> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.4> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.4> <levsim_0.4> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.4> <cratio_0.5> It was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.4> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.4> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.4> <cratio_0.8> The ship was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.4> <cratio_0.9> The ship was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.5> <cratio_0.1> It has been found in portugal since 2010.\n",
      "<copy_0.4> <levsim_0.5> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.5> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.4> <levsim_0.5> <cratio_0.4> It was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.5> <cratio_0.5> The ship was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.5> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.5> <cratio_0.7> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.4> <levsim_0.5> <cratio_0.8> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.4> <levsim_0.5> <cratio_0.9> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.4> <levsim_0.6> <cratio_0.1> It was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.6> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.6> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.4> <levsim_0.6> <cratio_0.4> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.6> <cratio_0.5> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.6> <cratio_0.6> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.6> <cratio_0.7> The project has uncovered documents in portugal that show who owned the ship.\n",
      "<copy_0.4> <levsim_0.6> <cratio_0.8> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.6> <cratio_0.9> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.4> <levsim_0.7> <cratio_0.1> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.7> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.7> <cratio_0.3> Since 2010, the project has uncovered documents.\n",
      "<copy_0.4> <levsim_0.7> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.7> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.7> <cratio_0.6> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.7> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.7> <cratio_0.8> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.7> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.4> <levsim_0.8> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.8> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.4> <levsim_0.8> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.8> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.8> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.8> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.8> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.8> <cratio_0.8> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.8> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.4> <levsim_0.9> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.9> <cratio_0.2> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.9> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.9> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.9> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.9> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.9> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.9> <cratio_0.8> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.4> <levsim_0.9> <cratio_0.9> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.5> <levsim_0.1> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.1> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.5> <levsim_0.1> <cratio_0.3> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.1> <cratio_0.4> It was discovered in 2010.\n",
      "<copy_0.5> <levsim_0.1> <cratio_0.5> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.1> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.1> <cratio_0.7> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.1> <cratio_0.8> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.1> <cratio_0.9> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.5> <levsim_0.2> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.2> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.5> <levsim_0.2> <cratio_0.3> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.2> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.2> <cratio_0.5> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.2> <cratio_0.6> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.2> <cratio_0.7> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.2> <cratio_0.8> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.2> <cratio_0.9> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.3> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.3> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.5> <levsim_0.3> <cratio_0.3> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.3> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.3> <cratio_0.5> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.3> <cratio_0.6> It was discovered in 2010.\n",
      "<copy_0.5> <levsim_0.3> <cratio_0.7> It was discovered in 2010.\n",
      "<copy_0.5> <levsim_0.3> <cratio_0.8> It was discovered in 2010.\n",
      "<copy_0.5> <levsim_0.3> <cratio_0.9> It was discovered in 2010.\n",
      "<copy_0.5> <levsim_0.4> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.4> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.5> <levsim_0.4> <cratio_0.3> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.4> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.4> <cratio_0.5> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.4> <cratio_0.6> It was discovered in 2010.\n",
      "<copy_0.5> <levsim_0.4> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.4> <cratio_0.8> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.4> <cratio_0.9> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.5> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.5> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.5> <cratio_0.3> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.5> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.5> <cratio_0.5> It was discovered in 2010.\n",
      "<copy_0.5> <levsim_0.5> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.5> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.5> <cratio_0.8> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.5> <cratio_0.9> The ship was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.6> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.6> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.6> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.5> <levsim_0.6> <cratio_0.4> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.6> <cratio_0.5> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.6> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.6> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.6> <cratio_0.8> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.6> <cratio_0.9> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.5> <levsim_0.7> <cratio_0.1> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.7> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.7> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.5> <levsim_0.7> <cratio_0.4> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.7> <cratio_0.5> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.7> <cratio_0.6> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.7> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.7> <cratio_0.8> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.7> <cratio_0.9> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.8> <cratio_0.1> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.8> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.8> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.5> <levsim_0.8> <cratio_0.4> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.8> <cratio_0.5> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.8> <cratio_0.6> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.8> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.8> <cratio_0.8> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.8> <cratio_0.9> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.9> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.9> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.5> <levsim_0.9> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.9> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.9> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.9> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.9> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.9> <cratio_0.8> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.5> <levsim_0.9> <cratio_0.9> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.6> <levsim_0.1> <cratio_0.1> In 2010, the ship was found in portugal.\n",
      "<copy_0.6> <levsim_0.1> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.1> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.6> <levsim_0.1> <cratio_0.4> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.1> <cratio_0.5> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.1> <cratio_0.6> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.1> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.1> <cratio_0.8> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.1> <cratio_0.9> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.6> <levsim_0.2> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.2> <cratio_0.2> It was built in 2010.\n",
      "<copy_0.6> <levsim_0.2> <cratio_0.3> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.2> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.2> <cratio_0.5> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.2> <cratio_0.6> It was discovered in 2010.\n",
      "<copy_0.6> <levsim_0.2> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.2> <cratio_0.8> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.2> <cratio_0.9> It was discovered in 2010.\n",
      "<copy_0.6> <levsim_0.3> <cratio_0.1> It was discovered in 2010.\n",
      "<copy_0.6> <levsim_0.3> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.3> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.6> <levsim_0.3> <cratio_0.4> It was discovered in 2010.\n",
      "<copy_0.6> <levsim_0.3> <cratio_0.5> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.3> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.3> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.3> <cratio_0.8> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.3> <cratio_0.9> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.4> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.4> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.4> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.6> <levsim_0.4> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.4> <cratio_0.5> It was discovered in 2010.\n",
      "<copy_0.6> <levsim_0.4> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.4> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.4> <cratio_0.8> The ship was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.4> <cratio_0.9> The ship was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.5> <cratio_0.1> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.5> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.5> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.6> <levsim_0.5> <cratio_0.4> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.5> <cratio_0.5> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.5> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.5> <cratio_0.7> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.6> <levsim_0.5> <cratio_0.8> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.6> <levsim_0.5> <cratio_0.9> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.6> <levsim_0.6> <cratio_0.1> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.6> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.6> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.6> <cratio_0.4> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.6> <cratio_0.5> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.6> <cratio_0.6> The project has uncovered documents in portugal that show who owned the ship.\n",
      "<copy_0.6> <levsim_0.6> <cratio_0.7> The project has uncovered documents in portugal that show who owned the ship.\n",
      "<copy_0.6> <levsim_0.6> <cratio_0.8> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.6> <levsim_0.6> <cratio_0.9> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.6> <levsim_0.7> <cratio_0.1> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.7> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.7> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.6> <levsim_0.7> <cratio_0.4> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.7> <cratio_0.5> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.7> <cratio_0.6> The project has uncovered documents in portugal that show who owned the ship.\n",
      "<copy_0.6> <levsim_0.7> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.7> <cratio_0.8> Since 2010, project researchers have found documents that show who owned the ship.\n",
      "<copy_0.6> <levsim_0.7> <cratio_0.9> Since 2010, researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.6> <levsim_0.8> <cratio_0.1> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.8> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.6> <levsim_0.8> <cratio_0.3> Since 2010, the project has uncovered documents.\n",
      "<copy_0.6> <levsim_0.8> <cratio_0.4> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.8> <cratio_0.5> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.8> <cratio_0.6> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.8> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.8> <cratio_0.8> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.8> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.6> <levsim_0.9> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.9> <cratio_0.2> Since 2010, the ship has been found.\n",
      "<copy_0.6> <levsim_0.9> <cratio_0.3> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.9> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.9> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.9> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.9> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.9> <cratio_0.8> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.6> <levsim_0.9> <cratio_0.9> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.1> <cratio_0.1> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.1> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.7> <levsim_0.1> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.1> <cratio_0.4> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.1> <cratio_0.5> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.1> <cratio_0.6> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.1> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.1> <cratio_0.8> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.1> <cratio_0.9> Since 2010, project researchers have found documents that show who owned the ship.\n",
      "<copy_0.7> <levsim_0.2> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.7> <levsim_0.2> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.7> <levsim_0.2> <cratio_0.3> The ship was built in 2010.\n",
      "<copy_0.7> <levsim_0.2> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.7> <levsim_0.2> <cratio_0.5> The ship was built in 2010.\n",
      "<copy_0.7> <levsim_0.2> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.2> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.2> <cratio_0.8> It was discovered in 2010.\n",
      "<copy_0.7> <levsim_0.2> <cratio_0.9> It was discovered in 2010.\n",
      "<copy_0.7> <levsim_0.3> <cratio_0.1> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.3> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.7> <levsim_0.3> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.7> <levsim_0.3> <cratio_0.4> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.3> <cratio_0.5> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.3> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.3> <cratio_0.7> The project has uncovered documents in portugal.\n",
      "<copy_0.7> <levsim_0.3> <cratio_0.8> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.3> <cratio_0.9> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.4> <cratio_0.1> The ship was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.4> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.7> <levsim_0.4> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.7> <levsim_0.4> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.7> <levsim_0.4> <cratio_0.5> The ship was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.4> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.4> <cratio_0.7> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.7> <levsim_0.4> <cratio_0.8> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.7> <levsim_0.4> <cratio_0.9> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.7> <levsim_0.5> <cratio_0.1> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.5> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.7> <levsim_0.5> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.5> <cratio_0.4> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.5> <cratio_0.5> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.7> <levsim_0.5> <cratio_0.6> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.7> <levsim_0.5> <cratio_0.7> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.7> <levsim_0.5> <cratio_0.8> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.7> <levsim_0.5> <cratio_0.9> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.7> <levsim_0.6> <cratio_0.1> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.6> <cratio_0.2> It was discovered in 2010.\n",
      "<copy_0.7> <levsim_0.6> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.6> <cratio_0.4> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.6> <cratio_0.5> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.6> <cratio_0.6> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.6> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.6> <cratio_0.8> Since 2010, project researchers have found documents that show who owned the ship.\n",
      "<copy_0.7> <levsim_0.6> <cratio_0.9> Since 2010, project researchers have found documents that show who owned the ship.\n",
      "<copy_0.7> <levsim_0.7> <cratio_0.1> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.7> <cratio_0.2> It was found in portugal in 2010.\n",
      "<copy_0.7> <levsim_0.7> <cratio_0.3> The project has uncovered documents in portugal.\n",
      "<copy_0.7> <levsim_0.7> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.7> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.7> <cratio_0.6> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.7> <cratio_0.7> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.7> <levsim_0.7> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.7> <levsim_0.7> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.7> <levsim_0.8> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.8> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.7> <levsim_0.8> <cratio_0.3> The project has uncovered documents in portugal.\n",
      "<copy_0.7> <levsim_0.8> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.8> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.8> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.8> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.8> <cratio_0.8> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.8> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.7> <levsim_0.9> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.9> <cratio_0.2> In 2010, project researchers discovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.9> <cratio_0.3> Since 2010, project researchers have uncovered documents.\n",
      "<copy_0.7> <levsim_0.9> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.9> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.9> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.9> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.9> <cratio_0.8> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.7> <levsim_0.9> <cratio_0.9> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.8> <levsim_0.1> <cratio_0.1> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.1> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.8> <levsim_0.1> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.1> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.1> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.1> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.1> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.1> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.1> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.2> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.8> <levsim_0.2> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.8> <levsim_0.2> <cratio_0.3> The ship was built in 2010.\n",
      "<copy_0.8> <levsim_0.2> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.8> <levsim_0.2> <cratio_0.5> It was discovered in 2010.\n",
      "<copy_0.8> <levsim_0.2> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.8> <levsim_0.2> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.8> <levsim_0.2> <cratio_0.8> It has been found in portugal since 2010.\n",
      "<copy_0.8> <levsim_0.2> <cratio_0.9> The ship was found in portugal in 2010.\n",
      "<copy_0.8> <levsim_0.3> <cratio_0.1> It was found in portugal in 2010.\n",
      "<copy_0.8> <levsim_0.3> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.8> <levsim_0.3> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.8> <levsim_0.3> <cratio_0.4> Since 2010, the ship has been found.\n",
      "<copy_0.8> <levsim_0.3> <cratio_0.5> Since 2010, the ship has been discovered.\n",
      "<copy_0.8> <levsim_0.3> <cratio_0.6> Since 2010, the project has uncovered documents.\n",
      "<copy_0.8> <levsim_0.3> <cratio_0.7> The project has uncovered documents in portugal.\n",
      "<copy_0.8> <levsim_0.3> <cratio_0.8> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.3> <cratio_0.9> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.4> <cratio_0.1> The ship was found in portugal in 2010.\n",
      "<copy_0.8> <levsim_0.4> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.8> <levsim_0.4> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.8> <levsim_0.4> <cratio_0.4> The ship was found in portugal in 2010.\n",
      "<copy_0.8> <levsim_0.4> <cratio_0.5> The ship was found in portugal in 2010.\n",
      "<copy_0.8> <levsim_0.4> <cratio_0.6> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.8> <levsim_0.4> <cratio_0.7> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.8> <levsim_0.4> <cratio_0.8> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.8> <levsim_0.4> <cratio_0.9> The ship was found in portugal in 2010.\n",
      "<SEP> In 2010, the ship was discovered.\n",
      "<copy_0.8> <levsim_0.5> <cratio_0.1> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.8> <levsim_0.5> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.8> <levsim_0.5> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.8> <levsim_0.5> <cratio_0.4> Since 2010, the ship has been discovered.\n",
      "<copy_0.8> <levsim_0.5> <cratio_0.5> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.8> <levsim_0.5> <cratio_0.6> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.8> <levsim_0.5> <cratio_0.7> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.5> <cratio_0.8> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.5> <cratio_0.9> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.6> <cratio_0.1> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.6> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.8> <levsim_0.6> <cratio_0.3> Since 2010, the project has uncovered documents.\n",
      "<copy_0.8> <levsim_0.6> <cratio_0.4> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.6> <cratio_0.5> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.6> <cratio_0.6> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.6> <cratio_0.7> Since 2010, project researchers have found documents that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.6> <cratio_0.8> Since 2010, researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.6> <cratio_0.9> Since 2010, researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.7> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.7> <cratio_0.2> It was found in portugal in 2010.\n",
      "<copy_0.8> <levsim_0.7> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.7> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.7> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.7> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.7> <cratio_0.7> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.7> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.7> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.8> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.8> <cratio_0.2> Since 2010, the ship has been discovered.\n",
      "<copy_0.8> <levsim_0.8> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.8> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.8> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.8> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.8> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.8> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.8> <cratio_0.9> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.8> <levsim_0.9> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.9> <cratio_0.2> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.9> <cratio_0.3> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.9> <cratio_0.4> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.8> <levsim_0.9> <cratio_0.5> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.8> <levsim_0.9> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.8> <levsim_0.9> <cratio_0.7> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.8> <levsim_0.9> <cratio_0.8> Since 2010, project researchers have uncovered documents in portugal that show who owned the ship.\n",
      "<copy_0.8> <levsim_0.9> <cratio_0.9> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.9> <levsim_0.1> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.1> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.9> <levsim_0.1> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.1> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.1> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.1> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.1> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.1> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.1> <cratio_0.9> Since 2010, project researchers have found documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.9> <levsim_0.2> <cratio_0.1> The ship was built in 2010.\n",
      "<copy_0.9> <levsim_0.2> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.9> <levsim_0.2> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.9> <levsim_0.2> <cratio_0.4> The ship was built in 2010.\n",
      "<copy_0.9> <levsim_0.2> <cratio_0.5> It was found in portugal in 2010.\n",
      "<copy_0.9> <levsim_0.2> <cratio_0.6> It was found in portugal in 2010.\n",
      "<copy_0.9> <levsim_0.2> <cratio_0.7> It was found in portugal in 2010.\n",
      "<copy_0.9> <levsim_0.2> <cratio_0.8> The ship was found in portugal in 2010.\n",
      "<copy_0.9> <levsim_0.2> <cratio_0.9> The ship was found in portugal in 2010.\n",
      "<copy_0.9> <levsim_0.3> <cratio_0.1> It was found in portugal in 2010.\n",
      "<copy_0.9> <levsim_0.3> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.9> <levsim_0.3> <cratio_0.3> It was discovered in 2010.\n",
      "<copy_0.9> <levsim_0.3> <cratio_0.4> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.3> <cratio_0.5> Since 2010, the ship has been discovered.\n",
      "<copy_0.9> <levsim_0.3> <cratio_0.6> Since 2010, the project has uncovered documents.\n",
      "<copy_0.9> <levsim_0.3> <cratio_0.7> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.3> <cratio_0.8> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.3> <cratio_0.9> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.4> <cratio_0.1> The ship was found in portugal in 2010.\n",
      "<copy_0.9> <levsim_0.4> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.9> <levsim_0.4> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.9> <levsim_0.4> <cratio_0.4> The ship was found in portugal in 2010.\n",
      "<copy_0.9> <levsim_0.4> <cratio_0.5> The ship was found in portugal in 2010.\n",
      "<copy_0.9> <levsim_0.4> <cratio_0.6> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.9> <levsim_0.4> <cratio_0.7> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.4> <cratio_0.8> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.4> <cratio_0.9> Since 2010, the ship has been found in portugal.\n",
      "<SEP> It was discovered in 2010.\n",
      "<copy_0.9> <levsim_0.5> <cratio_0.1> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.9> <levsim_0.5> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.9> <levsim_0.5> <cratio_0.3> It was found in portugal in 2010.\n",
      "<copy_0.9> <levsim_0.5> <cratio_0.4> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.9> <levsim_0.5> <cratio_0.5> Since 2010, the ship has been found in portugal.\n",
      "<copy_0.9> <levsim_0.5> <cratio_0.6> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.5> <cratio_0.7> Since 2010, researchers have found documents that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.5> <cratio_0.8> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.5> <cratio_0.9> Since 2010, the project has uncovered documents that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.6> <cratio_0.1> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.6> <cratio_0.2> The ship was built in 2010.\n",
      "<copy_0.9> <levsim_0.6> <cratio_0.3> Since 2010, the project has uncovered documents.\n",
      "<copy_0.9> <levsim_0.6> <cratio_0.4> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.6> <cratio_0.5> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.6> <cratio_0.6> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.6> <cratio_0.7> Since 2010, project researchers have found documents that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.6> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.6> <cratio_0.9> Since 2010, researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.7> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.7> <cratio_0.2> Since 2010, the ship has been discovered.\n",
      "<copy_0.9> <levsim_0.7> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.7> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.7> <cratio_0.5> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.7> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.7> <cratio_0.7> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.7> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.7> <cratio_0.9> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.8> <cratio_0.1> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.8> <cratio_0.2> Since 2010, researchers have discovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.8> <cratio_0.3> Since 2010, project researchers have discovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.8> <cratio_0.4> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.8> <cratio_0.5> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.8> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.8> <cratio_0.7> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.8> <cratio_0.8> Since 2010, project researchers have found documents in portugal that show who owned the ship.\n",
      "<copy_0.9> <levsim_0.8> <cratio_0.9> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.9> <levsim_0.9> <cratio_0.1> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.9> <levsim_0.9> <cratio_0.2> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.9> <cratio_0.3> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.9> <cratio_0.4> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.9> <levsim_0.9> <cratio_0.5> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.9> <levsim_0.9> <cratio_0.6> Since 2010, project researchers have uncovered who owned the ship.\n",
      "<copy_0.9> <levsim_0.9> <cratio_0.7> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.9> <levsim_0.9> <cratio_0.8> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n",
      "<copy_0.9> <levsim_0.9> <cratio_0.9> Since 2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\n"
     ]
    }
   ],
   "source": [
    "#get output for diffrent combination of copy and lev and cratio\n",
    "for i in range(1,10):\n",
    "    for j in range(1,10):\n",
    "        for k in range(1,10):\n",
    "            text = \"<copy_0.{}> <levsim_0.{}> <cratio_0.{}>Since,2010, project researchers have uncovered documents in portugal that have revealed who owned the ship.\".format(i,j,k)\n",
    "            # encode the text into tensor of integers using the appropriate tokenizer\n",
    "            inputs = tokenizer.encode( text, return_tensors=\"pt\", max_length=512, truncation=True).to('cuda:1')\n",
    "                \n",
    "                    # generate text until the output length (which includes the context length) reaches 50\n",
    "            beam_outputs = model.generate(inputs,max_length=max_l,num_beams=num_b,early_stopping=True,\n",
    "                no_repeat_ngram_size=3,\n",
    "                num_return_sequences=10,\n",
    "                top_k=4, top_p=0.95\n",
    "                # return_dict_in_generate=True,\n",
    "            )\n",
    "       \n",
    "            print(\"{} {}\".format(f\"<copy_0.{i}> <levsim_0.{j}> <cratio_0.{k}>\", tokenizer.decode(beam_outputs[0], skip_special_tokens=True)))\n",
    "                \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## controled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
