{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly import graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from tseval.feature_extraction import get_all_vectorizers\n",
    "from tseval.qats import (ASPECTS, get_qats_train_data, get_qats_test_data, row_vectorize, evaluate_scoring_method_on_qats,\n",
    "                         evaluate_regression_pipeline_on_qats, evaluate_classification_pipeline_on_qats, get_qats_results,\n",
    "                         pearsonr_with_confidence_interval)\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm  # Need this import to be last\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "red"
         },
         "name": "Bad",
         "type": "bar",
         "uid": "5e0b601c-e1da-11e8-8fa1-8f14a3942b01",
         "x": [
          "grammaticality",
          "meaning_preservation",
          "simplicity",
          "overall"
         ],
         "y": [
          67,
          98,
          104,
          174
         ]
        },
        {
         "marker": {
          "color": "orange"
         },
         "name": "OK",
         "type": "bar",
         "uid": "5e0b62ce-e1da-11e8-8fa1-8f14a3942b01",
         "x": [
          "grammaticality",
          "meaning_preservation",
          "simplicity",
          "overall"
         ],
         "y": [
          86,
          166,
          191,
          263
         ]
        },
        {
         "marker": {
          "color": "green"
         },
         "name": "Good",
         "type": "bar",
         "uid": "5e0b6378-e1da-11e8-8fa1-8f14a3942b01",
         "x": [
          "grammaticality",
          "meaning_preservation",
          "simplicity",
          "overall"
         ],
         "y": [
          478,
          367,
          336,
          194
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "barmode": "stack",
        "height": 410,
        "width": 460,
        "xaxis": {
         "autorange": true,
         "range": [
          -0.5,
          3.5
         ],
         "type": "category"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          0,
          664.2105263157895
         ],
         "type": "linear"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counters = defaultdict(dict)\n",
    "for aspect in ASPECTS:\n",
    "    counters[aspect]['train'] = Counter(get_qats_train_data(aspect)[1])\n",
    "    counters[aspect]['test'] = Counter(get_qats_test_data(aspect)[1])\n",
    "labels = [0, 50, 100]\n",
    "data = []\n",
    "for label in labels:\n",
    "    data.append(go.Bar(x=ASPECTS,\n",
    "                       y=[(counters[aspect]['train'] + counters[aspect]['test'])[label]\n",
    "                          for aspect in ASPECTS],\n",
    "                       marker={'color': {100: 'green', 50: 'orange', 0: 'red'}[label]},\n",
    "                       name={100: 'Good', 50: 'OK', 0: 'Bad'}[label]))\n",
    "layout = go.Layout(\n",
    "        barmode='stack',\n",
    "        autosize=False,\n",
    "        width=460,\n",
    "        height=410,\n",
    ")\n",
    "iplot(go.Figure(data=data, layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizers = [wrap_single_sentence_vectorizer(vec) for vec in get_sentence_feature_extractors()]\n",
    "vectorizers = get_all_vectorizers()\n",
    "\n",
    "def vectorize_sentence_pair(complex_sentence, simple_sentence):\n",
    "    return [vec(complex_sentence, simple_sentence) for vec in vectorizers]\n",
    "\n",
    "feature_extractor = row_vectorize(vectorize_sentence_pair)\n",
    "vectorizer_names = np.array([vectorizer.__name__ for vectorizer in vectorizers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6629ec0a62a420cadbfcf4761e0bb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=66), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fairseq language model...\n",
      "| dictionary: 267744 types\n",
      "Done.\n",
      "Loading FastText embeddings...\n",
      "Done.\n",
      "Loading NLGEval models...\n",
      "Done.\n",
      "Computing TERp features on all QATS sentence pairs.\n",
      "Done.\n",
      "Computing QuEst features on all QATS sentence pairs.\n",
      "Done.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0bc1ec86984e6792baf73b068d2336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=66), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec643724dc8240c891b9fc762f288277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=66), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32b1db2c6cf46bfa1cb2d1f35483377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=66), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 11min 31s, sys: 47 s, total: 12min 18s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "single_feature_dfs = {}\n",
    "metric_name = 'pearson'\n",
    "for aspect in ['grammaticality', 'meaning_preservation', 'simplicity', 'overall']:\n",
    "    df = pd.DataFrame(columns=['team', f'valid_{metric_name}', f'{metric_name}'])\n",
    "    for vectorizer in tqdm(vectorizers):\n",
    "        df = df.append(evaluate_scoring_method_on_qats(aspect, vectorizer), ignore_index=True)\n",
    "        df[f'valid_{metric_name}_abs'] = df[f'valid_{metric_name}'].abs()\n",
    "        single_feature_dfs[aspect] = df.sort_values(by=f'valid_{metric_name}_abs', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grammaticality\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>valid_pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>valid_conf_int_high</th>\n",
       "      <th>valid_conf_int_low</th>\n",
       "      <th>valid_p</th>\n",
       "      <th>valid_pearson_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nlgeval_METEOR</td>\n",
       "      <td>0.357566</td>\n",
       "      <td>0.388357</td>\n",
       "      <td>0.431363</td>\n",
       "      <td>0.279016</td>\n",
       "      <td>1.122385e-16</td>\n",
       "      <td>0.357566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>nltkBLEU_method2</td>\n",
       "      <td>0.329751</td>\n",
       "      <td>0.343791</td>\n",
       "      <td>0.405344</td>\n",
       "      <td>0.249680</td>\n",
       "      <td>2.835198e-14</td>\n",
       "      <td>0.329751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>nltkBLEU_method4</td>\n",
       "      <td>0.328759</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>0.404413</td>\n",
       "      <td>0.248636</td>\n",
       "      <td>3.419055e-14</td>\n",
       "      <td>0.328759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>nltkBLEU_method7</td>\n",
       "      <td>0.328638</td>\n",
       "      <td>0.344558</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>0.248509</td>\n",
       "      <td>3.497754e-14</td>\n",
       "      <td>0.328638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nltkBLEU_method3</td>\n",
       "      <td>0.324548</td>\n",
       "      <td>0.340045</td>\n",
       "      <td>0.400462</td>\n",
       "      <td>0.244208</td>\n",
       "      <td>7.511127e-14</td>\n",
       "      <td>0.324548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>nltkBLEU_method5</td>\n",
       "      <td>0.324099</td>\n",
       "      <td>0.346104</td>\n",
       "      <td>0.400041</td>\n",
       "      <td>0.243736</td>\n",
       "      <td>8.162851e-14</td>\n",
       "      <td>0.324099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>nltkBLEU_method6</td>\n",
       "      <td>0.322887</td>\n",
       "      <td>0.340999</td>\n",
       "      <td>0.398903</td>\n",
       "      <td>0.242463</td>\n",
       "      <td>1.021055e-13</td>\n",
       "      <td>0.322887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>nltkBLEU_method1</td>\n",
       "      <td>0.321963</td>\n",
       "      <td>0.339534</td>\n",
       "      <td>0.398036</td>\n",
       "      <td>0.241493</td>\n",
       "      <td>1.210143e-13</td>\n",
       "      <td>0.321963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nlgeval_Bleu_4</td>\n",
       "      <td>0.317196</td>\n",
       "      <td>0.338076</td>\n",
       "      <td>0.393559</td>\n",
       "      <td>0.236486</td>\n",
       "      <td>2.882516e-13</td>\n",
       "      <td>0.317196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>nltkBLEU_method0</td>\n",
       "      <td>0.317195</td>\n",
       "      <td>0.338076</td>\n",
       "      <td>0.393557</td>\n",
       "      <td>0.236485</td>\n",
       "      <td>2.883162e-13</td>\n",
       "      <td>0.317195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nlgeval_Bleu_3</td>\n",
       "      <td>0.311242</td>\n",
       "      <td>0.343624</td>\n",
       "      <td>0.387961</td>\n",
       "      <td>0.230240</td>\n",
       "      <td>8.340189e-13</td>\n",
       "      <td>0.311242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TERp_NumEr</td>\n",
       "      <td>-0.302586</td>\n",
       "      <td>-0.309523</td>\n",
       "      <td>-0.221171</td>\n",
       "      <td>-0.379813</td>\n",
       "      <td>3.746596e-12</td>\n",
       "      <td>0.302586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nlgeval_Bleu_2</td>\n",
       "      <td>0.300048</td>\n",
       "      <td>0.343265</td>\n",
       "      <td>0.377422</td>\n",
       "      <td>0.218514</td>\n",
       "      <td>5.766345e-12</td>\n",
       "      <td>0.300048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TERp_TERp</td>\n",
       "      <td>-0.295656</td>\n",
       "      <td>-0.321193</td>\n",
       "      <td>-0.213919</td>\n",
       "      <td>-0.373281</td>\n",
       "      <td>1.204086e-11</td>\n",
       "      <td>0.295656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>nlgeval_ROUGE_L</td>\n",
       "      <td>0.290315</td>\n",
       "      <td>0.285029</td>\n",
       "      <td>0.368241</td>\n",
       "      <td>0.208337</td>\n",
       "      <td>2.898676e-11</td>\n",
       "      <td>0.290315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>average_sentence_lm_prob</td>\n",
       "      <td>0.277946</td>\n",
       "      <td>0.342215</td>\n",
       "      <td>0.356554</td>\n",
       "      <td>0.195430</td>\n",
       "      <td>2.067436e-10</td>\n",
       "      <td>0.277946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TERp_Shft</td>\n",
       "      <td>-0.271831</td>\n",
       "      <td>-0.037470</td>\n",
       "      <td>-0.189061</td>\n",
       "      <td>-0.350767</td>\n",
       "      <td>5.270124e-10</td>\n",
       "      <td>0.271831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nlgeval_Bleu_1</td>\n",
       "      <td>0.271798</td>\n",
       "      <td>0.331889</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.189026</td>\n",
       "      <td>5.297044e-10</td>\n",
       "      <td>0.271798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>word_intersection</td>\n",
       "      <td>0.269590</td>\n",
       "      <td>0.302548</td>\n",
       "      <td>0.348643</td>\n",
       "      <td>0.186727</td>\n",
       "      <td>7.384201e-10</td>\n",
       "      <td>0.269590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TERp_Del</td>\n",
       "      <td>-0.268233</td>\n",
       "      <td>-0.351387</td>\n",
       "      <td>-0.185316</td>\n",
       "      <td>-0.347359</td>\n",
       "      <td>9.041940e-10</td>\n",
       "      <td>0.268233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>QuEst_nb_source_tokens</td>\n",
       "      <td>-0.247581</td>\n",
       "      <td>-0.074323</td>\n",
       "      <td>-0.163866</td>\n",
       "      <td>-0.327756</td>\n",
       "      <td>1.721178e-08</td>\n",
       "      <td>0.247581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TERp_NumWd</td>\n",
       "      <td>-0.245498</td>\n",
       "      <td>-0.068774</td>\n",
       "      <td>-0.161706</td>\n",
       "      <td>-0.325774</td>\n",
       "      <td>2.284417e-08</td>\n",
       "      <td>0.245498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>average_cosine</td>\n",
       "      <td>0.230536</td>\n",
       "      <td>0.250480</td>\n",
       "      <td>0.311524</td>\n",
       "      <td>0.146222</td>\n",
       "      <td>1.618593e-07</td>\n",
       "      <td>0.230536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hungarian_dot</td>\n",
       "      <td>0.229125</td>\n",
       "      <td>0.356787</td>\n",
       "      <td>0.310179</td>\n",
       "      <td>0.144764</td>\n",
       "      <td>1.933815e-07</td>\n",
       "      <td>0.229125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hungarian_cosine</td>\n",
       "      <td>0.228759</td>\n",
       "      <td>0.313029</td>\n",
       "      <td>0.309829</td>\n",
       "      <td>0.144386</td>\n",
       "      <td>2.024852e-07</td>\n",
       "      <td>0.228759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>characters_per_sentence_difference</td>\n",
       "      <td>-0.193717</td>\n",
       "      <td>-0.173745</td>\n",
       "      <td>-0.108292</td>\n",
       "      <td>-0.276302</td>\n",
       "      <td>1.164926e-05</td>\n",
       "      <td>0.193717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TERp_WdSh</td>\n",
       "      <td>-0.149219</td>\n",
       "      <td>0.028629</td>\n",
       "      <td>-0.062782</td>\n",
       "      <td>-0.233435</td>\n",
       "      <td>7.686886e-04</td>\n",
       "      <td>0.149219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>QuEst_nb_bigram_q1_freq</td>\n",
       "      <td>-0.143962</td>\n",
       "      <td>-0.030521</td>\n",
       "      <td>-0.057429</td>\n",
       "      <td>-0.228349</td>\n",
       "      <td>1.178427e-03</td>\n",
       "      <td>0.143962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>min_sentence_lm_prob</td>\n",
       "      <td>0.109998</td>\n",
       "      <td>-0.066391</td>\n",
       "      <td>0.195377</td>\n",
       "      <td>0.022963</td>\n",
       "      <td>1.338814e-02</td>\n",
       "      <td>0.109998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>QuEst_nb_source_words_in_corpus</td>\n",
       "      <td>-0.109438</td>\n",
       "      <td>-0.171685</td>\n",
       "      <td>-0.022397</td>\n",
       "      <td>-0.194832</td>\n",
       "      <td>1.387019e-02</td>\n",
       "      <td>0.109438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>QuEst_nb_target_tokens</td>\n",
       "      <td>-0.081512</td>\n",
       "      <td>0.194001</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>-0.167575</td>\n",
       "      <td>6.721179e-02</td>\n",
       "      <td>0.081512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count_words</td>\n",
       "      <td>-0.078174</td>\n",
       "      <td>0.203466</td>\n",
       "      <td>0.009144</td>\n",
       "      <td>-0.164308</td>\n",
       "      <td>7.924780e-02</td>\n",
       "      <td>0.078174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>count_characters</td>\n",
       "      <td>-0.077946</td>\n",
       "      <td>0.219643</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>-0.164085</td>\n",
       "      <td>8.013039e-02</td>\n",
       "      <td>0.077946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>QuEst_nb_unigram_q1_freq</td>\n",
       "      <td>-0.074265</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.013075</td>\n",
       "      <td>-0.160480</td>\n",
       "      <td>9.550048e-02</td>\n",
       "      <td>0.074265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count_syllables_in_sentence</td>\n",
       "      <td>-0.073546</td>\n",
       "      <td>0.205243</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>-0.159776</td>\n",
       "      <td>9.876060e-02</td>\n",
       "      <td>0.073546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TERp_Ins</td>\n",
       "      <td>-0.068386</td>\n",
       "      <td>0.028388</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>-0.154718</td>\n",
       "      <td>1.248380e-01</td>\n",
       "      <td>0.068386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sentence_fkgl</td>\n",
       "      <td>-0.066687</td>\n",
       "      <td>0.119168</td>\n",
       "      <td>0.020689</td>\n",
       "      <td>-0.153051</td>\n",
       "      <td>1.345105e-01</td>\n",
       "      <td>0.066687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_pos_in_freq_table</td>\n",
       "      <td>0.064177</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.150589</td>\n",
       "      <td>-0.023208</td>\n",
       "      <td>1.498344e-01</td>\n",
       "      <td>0.064177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>average_concreteness</td>\n",
       "      <td>-0.063470</td>\n",
       "      <td>-0.051124</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>-0.149895</td>\n",
       "      <td>1.543839e-01</td>\n",
       "      <td>0.063470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>QuEst_nb_bigram_q4_freq</td>\n",
       "      <td>-0.054977</td>\n",
       "      <td>-0.155231</td>\n",
       "      <td>0.032433</td>\n",
       "      <td>-0.141553</td>\n",
       "      <td>2.174515e-01</td>\n",
       "      <td>0.054977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>QuEst_nb_trigram_q4_freq</td>\n",
       "      <td>-0.045172</td>\n",
       "      <td>-0.213143</td>\n",
       "      <td>0.042249</td>\n",
       "      <td>-0.131907</td>\n",
       "      <td>3.110011e-01</td>\n",
       "      <td>0.045172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>count_words_per_sentence</td>\n",
       "      <td>-0.043462</td>\n",
       "      <td>0.276604</td>\n",
       "      <td>0.043960</td>\n",
       "      <td>-0.130223</td>\n",
       "      <td>3.296976e-01</td>\n",
       "      <td>0.043462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>count_characters_per_sentence</td>\n",
       "      <td>-0.042533</td>\n",
       "      <td>0.272582</td>\n",
       "      <td>0.044889</td>\n",
       "      <td>-0.129308</td>\n",
       "      <td>3.401465e-01</td>\n",
       "      <td>0.042533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_syllables_per_sentence</td>\n",
       "      <td>-0.038846</td>\n",
       "      <td>0.250960</td>\n",
       "      <td>0.048574</td>\n",
       "      <td>-0.125675</td>\n",
       "      <td>3.836904e-01</td>\n",
       "      <td>0.038846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sentence_fre</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>-0.012929</td>\n",
       "      <td>0.121854</td>\n",
       "      <td>-0.052444</td>\n",
       "      <td>4.329417e-01</td>\n",
       "      <td>0.034971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>QuEst_nb_translations_idf</td>\n",
       "      <td>-0.034111</td>\n",
       "      <td>0.121973</td>\n",
       "      <td>0.053303</td>\n",
       "      <td>-0.121005</td>\n",
       "      <td>4.443542e-01</td>\n",
       "      <td>0.034111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>QuEst_avg_source_token_length</td>\n",
       "      <td>0.028064</td>\n",
       "      <td>0.064607</td>\n",
       "      <td>0.115038</td>\n",
       "      <td>-0.059336</td>\n",
       "      <td>5.291976e-01</td>\n",
       "      <td>0.028064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>QuEst_nb_translations</td>\n",
       "      <td>-0.025286</td>\n",
       "      <td>-0.186774</td>\n",
       "      <td>0.062106</td>\n",
       "      <td>-0.112293</td>\n",
       "      <td>5.707782e-01</td>\n",
       "      <td>0.025286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>QuEst_nb_target_punct</td>\n",
       "      <td>-0.023814</td>\n",
       "      <td>-0.050601</td>\n",
       "      <td>0.063573</td>\n",
       "      <td>-0.110839</td>\n",
       "      <td>5.934047e-01</td>\n",
       "      <td>0.023814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count_sentences</td>\n",
       "      <td>-0.016496</td>\n",
       "      <td>-0.182081</td>\n",
       "      <td>0.070861</td>\n",
       "      <td>-0.103602</td>\n",
       "      <td>7.115314e-01</td>\n",
       "      <td>0.016496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>count_syllables_per_word</td>\n",
       "      <td>0.012632</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.099777</td>\n",
       "      <td>-0.074706</td>\n",
       "      <td>7.770451e-01</td>\n",
       "      <td>0.012632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>QuEst_nb_trigram_q1_freq</td>\n",
       "      <td>-0.011649</td>\n",
       "      <td>-0.056216</td>\n",
       "      <td>0.075683</td>\n",
       "      <td>-0.098804</td>\n",
       "      <td>7.939781e-01</td>\n",
       "      <td>0.011649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_characters_per_word</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.026699</td>\n",
       "      <td>0.095974</td>\n",
       "      <td>-0.078523</td>\n",
       "      <td>8.437513e-01</td>\n",
       "      <td>0.008792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average_pos_in_freq_table</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>0.051255</td>\n",
       "      <td>0.086568</td>\n",
       "      <td>-0.087942</td>\n",
       "      <td>9.876153e-01</td>\n",
       "      <td>0.000692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>nlgeval_CIDEr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TERp_Stem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TERp_Syn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TERp_Phrase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>QuEst_lm_prob_source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>QuEst_lm_prob_target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  team  valid_pearson   pearson  \\\n",
       "27                      nlgeval_METEOR       0.357566  0.388357   \n",
       "32                    nltkBLEU_method2       0.329751  0.343791   \n",
       "34                    nltkBLEU_method4       0.328759  0.337544   \n",
       "37                    nltkBLEU_method7       0.328638  0.344558   \n",
       "33                    nltkBLEU_method3       0.324548  0.340045   \n",
       "35                    nltkBLEU_method5       0.324099  0.346104   \n",
       "36                    nltkBLEU_method6       0.322887  0.340999   \n",
       "31                    nltkBLEU_method1       0.321963  0.339534   \n",
       "26                      nlgeval_Bleu_4       0.317196  0.338076   \n",
       "30                    nltkBLEU_method0       0.317195  0.338076   \n",
       "25                      nlgeval_Bleu_3       0.311242  0.343624   \n",
       "46                          TERp_NumEr      -0.302586 -0.309523   \n",
       "24                      nlgeval_Bleu_2       0.300048  0.343265   \n",
       "48                           TERp_TERp      -0.295656 -0.321193   \n",
       "28                     nlgeval_ROUGE_L       0.290315  0.285029   \n",
       "15            average_sentence_lm_prob       0.277946  0.342215   \n",
       "44                           TERp_Shft      -0.271831 -0.037470   \n",
       "23                      nlgeval_Bleu_1       0.271798  0.331889   \n",
       "17                   word_intersection       0.269590  0.302548   \n",
       "39                            TERp_Del      -0.268233 -0.351387   \n",
       "49              QuEst_nb_source_tokens      -0.247581 -0.074323   \n",
       "47                          TERp_NumWd      -0.245498 -0.068774   \n",
       "20                      average_cosine       0.230536  0.250480   \n",
       "21                       hungarian_dot       0.229125  0.356787   \n",
       "22                    hungarian_cosine       0.228759  0.313029   \n",
       "18  characters_per_sentence_difference      -0.193717 -0.173745   \n",
       "45                           TERp_WdSh      -0.149219  0.028629   \n",
       "59             QuEst_nb_bigram_q1_freq      -0.143962 -0.030521   \n",
       "16                min_sentence_lm_prob       0.109998 -0.066391   \n",
       "63     QuEst_nb_source_words_in_corpus      -0.109438 -0.171685   \n",
       "..                                 ...            ...       ...   \n",
       "50              QuEst_nb_target_tokens      -0.081512  0.194001   \n",
       "0                          count_words      -0.078174  0.203466   \n",
       "1                     count_characters      -0.077946  0.219643   \n",
       "57            QuEst_nb_unigram_q1_freq      -0.074265  0.004102   \n",
       "3          count_syllables_in_sentence      -0.073546  0.205243   \n",
       "38                            TERp_Ins      -0.068386  0.028388   \n",
       "14                       sentence_fkgl      -0.066687  0.119168   \n",
       "9                max_pos_in_freq_table       0.064177  0.003808   \n",
       "12                average_concreteness      -0.063470 -0.051124   \n",
       "60             QuEst_nb_bigram_q4_freq      -0.054977 -0.155231   \n",
       "62            QuEst_nb_trigram_q4_freq      -0.045172 -0.213143   \n",
       "4             count_words_per_sentence      -0.043462  0.276604   \n",
       "5        count_characters_per_sentence      -0.042533  0.272582   \n",
       "6         count_syllables_per_sentence      -0.038846  0.250960   \n",
       "13                        sentence_fre       0.034971 -0.012929   \n",
       "56           QuEst_nb_translations_idf      -0.034111  0.121973   \n",
       "51       QuEst_avg_source_token_length       0.028064  0.064607   \n",
       "55               QuEst_nb_translations      -0.025286 -0.186774   \n",
       "65               QuEst_nb_target_punct      -0.023814 -0.050601   \n",
       "2                      count_sentences      -0.016496 -0.182081   \n",
       "8             count_syllables_per_word       0.012632  0.019520   \n",
       "61            QuEst_nb_trigram_q1_freq      -0.011649 -0.056216   \n",
       "7            count_characters_per_word       0.008792  0.026699   \n",
       "10           average_pos_in_freq_table      -0.000692  0.051255   \n",
       "29                       nlgeval_CIDEr            NaN       NaN   \n",
       "41                           TERp_Stem            NaN       NaN   \n",
       "42                            TERp_Syn            NaN       NaN   \n",
       "43                         TERp_Phrase            NaN       NaN   \n",
       "52                QuEst_lm_prob_source            NaN       NaN   \n",
       "53                QuEst_lm_prob_target            NaN       NaN   \n",
       "\n",
       "    valid_conf_int_high  valid_conf_int_low       valid_p  valid_pearson_abs  \n",
       "27             0.431363            0.279016  1.122385e-16           0.357566  \n",
       "32             0.405344            0.249680  2.835198e-14           0.329751  \n",
       "34             0.404413            0.248636  3.419055e-14           0.328759  \n",
       "37             0.404300            0.248509  3.497754e-14           0.328638  \n",
       "33             0.400462            0.244208  7.511127e-14           0.324548  \n",
       "35             0.400041            0.243736  8.162851e-14           0.324099  \n",
       "36             0.398903            0.242463  1.021055e-13           0.322887  \n",
       "31             0.398036            0.241493  1.210143e-13           0.321963  \n",
       "26             0.393559            0.236486  2.882516e-13           0.317196  \n",
       "30             0.393557            0.236485  2.883162e-13           0.317195  \n",
       "25             0.387961            0.230240  8.340189e-13           0.311242  \n",
       "46            -0.221171           -0.379813  3.746596e-12           0.302586  \n",
       "24             0.377422            0.218514  5.766345e-12           0.300048  \n",
       "48            -0.213919           -0.373281  1.204086e-11           0.295656  \n",
       "28             0.368241            0.208337  2.898676e-11           0.290315  \n",
       "15             0.356554            0.195430  2.067436e-10           0.277946  \n",
       "44            -0.189061           -0.350767  5.270124e-10           0.271831  \n",
       "23             0.350735            0.189026  5.297044e-10           0.271798  \n",
       "17             0.348643            0.186727  7.384201e-10           0.269590  \n",
       "39            -0.185316           -0.347359  9.041940e-10           0.268233  \n",
       "49            -0.163866           -0.327756  1.721178e-08           0.247581  \n",
       "47            -0.161706           -0.325774  2.284417e-08           0.245498  \n",
       "20             0.311524            0.146222  1.618593e-07           0.230536  \n",
       "21             0.310179            0.144764  1.933815e-07           0.229125  \n",
       "22             0.309829            0.144386  2.024852e-07           0.228759  \n",
       "18            -0.108292           -0.276302  1.164926e-05           0.193717  \n",
       "45            -0.062782           -0.233435  7.686886e-04           0.149219  \n",
       "59            -0.057429           -0.228349  1.178427e-03           0.143962  \n",
       "16             0.195377            0.022963  1.338814e-02           0.109998  \n",
       "63            -0.022397           -0.194832  1.387019e-02           0.109438  \n",
       "..                  ...                 ...           ...                ...  \n",
       "50             0.005784           -0.167575  6.721179e-02           0.081512  \n",
       "0              0.009144           -0.164308  7.924780e-02           0.078174  \n",
       "1              0.009373           -0.164085  8.013039e-02           0.077946  \n",
       "57             0.013075           -0.160480  9.550048e-02           0.074265  \n",
       "3              0.013797           -0.159776  9.876060e-02           0.073546  \n",
       "38             0.018982           -0.154718  1.248380e-01           0.068386  \n",
       "14             0.020689           -0.153051  1.345105e-01           0.066687  \n",
       "9              0.150589           -0.023208  1.498344e-01           0.064177  \n",
       "12             0.023917           -0.149895  1.543839e-01           0.063470  \n",
       "60             0.032433           -0.141553  2.174515e-01           0.054977  \n",
       "62             0.042249           -0.131907  3.110011e-01           0.045172  \n",
       "4              0.043960           -0.130223  3.296976e-01           0.043462  \n",
       "5              0.044889           -0.129308  3.401465e-01           0.042533  \n",
       "6              0.048574           -0.125675  3.836904e-01           0.038846  \n",
       "13             0.121854           -0.052444  4.329417e-01           0.034971  \n",
       "56             0.053303           -0.121005  4.443542e-01           0.034111  \n",
       "51             0.115038           -0.059336  5.291976e-01           0.028064  \n",
       "55             0.062106           -0.112293  5.707782e-01           0.025286  \n",
       "65             0.063573           -0.110839  5.934047e-01           0.023814  \n",
       "2              0.070861           -0.103602  7.115314e-01           0.016496  \n",
       "8              0.099777           -0.074706  7.770451e-01           0.012632  \n",
       "61             0.075683           -0.098804  7.939781e-01           0.011649  \n",
       "7              0.095974           -0.078523  8.437513e-01           0.008792  \n",
       "10             0.086568           -0.087942  9.876153e-01           0.000692  \n",
       "29                  NaN                 NaN  1.000000e+00                NaN  \n",
       "41                  NaN                 NaN  1.000000e+00                NaN  \n",
       "42                  NaN                 NaN  1.000000e+00                NaN  \n",
       "43                  NaN                 NaN  1.000000e+00                NaN  \n",
       "52                  NaN                 NaN  1.000000e+00                NaN  \n",
       "53                  NaN                 NaN  1.000000e+00                NaN  \n",
       "\n",
       "[66 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('grammaticality')\n",
    "single_feature_dfs['grammaticality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaning_preservation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>valid_pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>valid_conf_int_high</th>\n",
       "      <th>valid_conf_int_low</th>\n",
       "      <th>valid_p</th>\n",
       "      <th>valid_pearson_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>nltkBLEU_method7</td>\n",
       "      <td>0.588836</td>\n",
       "      <td>0.522980</td>\n",
       "      <td>0.643052</td>\n",
       "      <td>0.528748</td>\n",
       "      <td>1.885627e-48</td>\n",
       "      <td>0.588836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>nltkBLEU_method2</td>\n",
       "      <td>0.587551</td>\n",
       "      <td>0.520681</td>\n",
       "      <td>0.641898</td>\n",
       "      <td>0.527331</td>\n",
       "      <td>3.379901e-48</td>\n",
       "      <td>0.587551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>nltkBLEU_method4</td>\n",
       "      <td>0.586188</td>\n",
       "      <td>0.516174</td>\n",
       "      <td>0.640674</td>\n",
       "      <td>0.525828</td>\n",
       "      <td>6.257325e-48</td>\n",
       "      <td>0.586188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>nltkBLEU_method5</td>\n",
       "      <td>0.583989</td>\n",
       "      <td>0.518289</td>\n",
       "      <td>0.638699</td>\n",
       "      <td>0.523405</td>\n",
       "      <td>1.680190e-47</td>\n",
       "      <td>0.583989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nltkBLEU_method3</td>\n",
       "      <td>0.581627</td>\n",
       "      <td>0.511795</td>\n",
       "      <td>0.636576</td>\n",
       "      <td>0.520802</td>\n",
       "      <td>4.815431e-47</td>\n",
       "      <td>0.581627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>nltkBLEU_method6</td>\n",
       "      <td>0.579019</td>\n",
       "      <td>0.512754</td>\n",
       "      <td>0.634231</td>\n",
       "      <td>0.517931</td>\n",
       "      <td>1.524150e-46</td>\n",
       "      <td>0.579019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>nltkBLEU_method1</td>\n",
       "      <td>0.578284</td>\n",
       "      <td>0.510670</td>\n",
       "      <td>0.633570</td>\n",
       "      <td>0.517121</td>\n",
       "      <td>2.105299e-46</td>\n",
       "      <td>0.578284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nlgeval_Bleu_3</td>\n",
       "      <td>0.574913</td>\n",
       "      <td>0.519681</td>\n",
       "      <td>0.630537</td>\n",
       "      <td>0.513412</td>\n",
       "      <td>9.159703e-46</td>\n",
       "      <td>0.574913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nlgeval_METEOR</td>\n",
       "      <td>0.574645</td>\n",
       "      <td>0.582689</td>\n",
       "      <td>0.630296</td>\n",
       "      <td>0.513118</td>\n",
       "      <td>1.028769e-45</td>\n",
       "      <td>0.574645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nlgeval_Bleu_2</td>\n",
       "      <td>0.572326</td>\n",
       "      <td>0.522042</td>\n",
       "      <td>0.628210</td>\n",
       "      <td>0.510568</td>\n",
       "      <td>2.797788e-45</td>\n",
       "      <td>0.572326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nlgeval_Bleu_4</td>\n",
       "      <td>0.571856</td>\n",
       "      <td>0.508691</td>\n",
       "      <td>0.627786</td>\n",
       "      <td>0.510051</td>\n",
       "      <td>3.424731e-45</td>\n",
       "      <td>0.571856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>nltkBLEU_method0</td>\n",
       "      <td>0.571854</td>\n",
       "      <td>0.508690</td>\n",
       "      <td>0.627784</td>\n",
       "      <td>0.510049</td>\n",
       "      <td>3.427292e-45</td>\n",
       "      <td>0.571854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>word_intersection</td>\n",
       "      <td>0.550394</td>\n",
       "      <td>0.501574</td>\n",
       "      <td>0.608430</td>\n",
       "      <td>0.486504</td>\n",
       "      <td>2.464327e-41</td>\n",
       "      <td>0.550394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nlgeval_Bleu_1</td>\n",
       "      <td>0.549643</td>\n",
       "      <td>0.523669</td>\n",
       "      <td>0.607751</td>\n",
       "      <td>0.485681</td>\n",
       "      <td>3.323943e-41</td>\n",
       "      <td>0.549643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>nlgeval_ROUGE_L</td>\n",
       "      <td>0.546917</td>\n",
       "      <td>0.472783</td>\n",
       "      <td>0.605287</td>\n",
       "      <td>0.482697</td>\n",
       "      <td>9.787660e-41</td>\n",
       "      <td>0.546917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TERp_TERp</td>\n",
       "      <td>-0.540798</td>\n",
       "      <td>-0.484857</td>\n",
       "      <td>-0.476005</td>\n",
       "      <td>-0.599753</td>\n",
       "      <td>1.066043e-39</td>\n",
       "      <td>0.540798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TERp_NumEr</td>\n",
       "      <td>-0.528643</td>\n",
       "      <td>-0.488232</td>\n",
       "      <td>-0.462732</td>\n",
       "      <td>-0.588741</td>\n",
       "      <td>1.061888e-37</td>\n",
       "      <td>0.528643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TERp_Del</td>\n",
       "      <td>-0.499968</td>\n",
       "      <td>-0.521907</td>\n",
       "      <td>-0.431538</td>\n",
       "      <td>-0.562676</td>\n",
       "      <td>2.704401e-33</td>\n",
       "      <td>0.499968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hungarian_cosine</td>\n",
       "      <td>0.491421</td>\n",
       "      <td>0.521263</td>\n",
       "      <td>0.554883</td>\n",
       "      <td>0.422272</td>\n",
       "      <td>4.639851e-32</td>\n",
       "      <td>0.491421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hungarian_dot</td>\n",
       "      <td>0.448457</td>\n",
       "      <td>0.482534</td>\n",
       "      <td>0.515539</td>\n",
       "      <td>0.375912</td>\n",
       "      <td>2.348606e-26</td>\n",
       "      <td>0.448457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>average_cosine</td>\n",
       "      <td>0.435330</td>\n",
       "      <td>0.341948</td>\n",
       "      <td>0.503461</td>\n",
       "      <td>0.361818</td>\n",
       "      <td>9.084706e-25</td>\n",
       "      <td>0.435330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>characters_per_sentence_difference</td>\n",
       "      <td>-0.393841</td>\n",
       "      <td>-0.424026</td>\n",
       "      <td>-0.317496</td>\n",
       "      <td>-0.465112</td>\n",
       "      <td>3.477202e-20</td>\n",
       "      <td>0.393841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>average_sentence_lm_prob</td>\n",
       "      <td>0.393022</td>\n",
       "      <td>0.358612</td>\n",
       "      <td>0.464353</td>\n",
       "      <td>0.316625</td>\n",
       "      <td>4.220386e-20</td>\n",
       "      <td>0.393022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>average_concreteness</td>\n",
       "      <td>-0.279329</td>\n",
       "      <td>-0.058816</td>\n",
       "      <td>-0.196872</td>\n",
       "      <td>-0.357861</td>\n",
       "      <td>1.667737e-10</td>\n",
       "      <td>0.279329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>QuEst_nb_source_tokens</td>\n",
       "      <td>-0.276634</td>\n",
       "      <td>-0.131891</td>\n",
       "      <td>-0.194063</td>\n",
       "      <td>-0.355313</td>\n",
       "      <td>2.531952e-10</td>\n",
       "      <td>0.276634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TERp_NumWd</td>\n",
       "      <td>-0.267304</td>\n",
       "      <td>-0.129187</td>\n",
       "      <td>-0.184349</td>\n",
       "      <td>-0.346478</td>\n",
       "      <td>1.038172e-09</td>\n",
       "      <td>0.267304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TERp_Sub</td>\n",
       "      <td>-0.199247</td>\n",
       "      <td>0.037551</td>\n",
       "      <td>-0.113973</td>\n",
       "      <td>-0.281606</td>\n",
       "      <td>6.429784e-06</td>\n",
       "      <td>0.199247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>min_concreteness</td>\n",
       "      <td>-0.194511</td>\n",
       "      <td>-0.069427</td>\n",
       "      <td>-0.109108</td>\n",
       "      <td>-0.277064</td>\n",
       "      <td>1.070674e-05</td>\n",
       "      <td>0.194511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TERp_Shft</td>\n",
       "      <td>-0.193195</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>-0.107756</td>\n",
       "      <td>-0.275801</td>\n",
       "      <td>1.231085e-05</td>\n",
       "      <td>0.193195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count_sentences</td>\n",
       "      <td>-0.168994</td>\n",
       "      <td>-0.133562</td>\n",
       "      <td>-0.082962</td>\n",
       "      <td>-0.252525</td>\n",
       "      <td>1.357815e-04</td>\n",
       "      <td>0.168994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average_pos_in_freq_table</td>\n",
       "      <td>-0.137807</td>\n",
       "      <td>-0.097339</td>\n",
       "      <td>-0.051167</td>\n",
       "      <td>-0.222388</td>\n",
       "      <td>1.909377e-03</td>\n",
       "      <td>0.137807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>QuEst_nb_bigram_q1_freq</td>\n",
       "      <td>-0.133831</td>\n",
       "      <td>-0.068606</td>\n",
       "      <td>-0.047126</td>\n",
       "      <td>-0.218534</td>\n",
       "      <td>2.581823e-03</td>\n",
       "      <td>0.133831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>QuEst_nb_target_punct</td>\n",
       "      <td>0.108326</td>\n",
       "      <td>0.117109</td>\n",
       "      <td>0.193750</td>\n",
       "      <td>0.021272</td>\n",
       "      <td>1.487251e-02</td>\n",
       "      <td>0.108326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_pos_in_freq_table</td>\n",
       "      <td>0.097438</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.183136</td>\n",
       "      <td>0.010271</td>\n",
       "      <td>2.856465e-02</td>\n",
       "      <td>0.097438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>average_dot</td>\n",
       "      <td>0.088357</td>\n",
       "      <td>0.038198</td>\n",
       "      <td>0.174268</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>4.719650e-02</td>\n",
       "      <td>0.088357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sentence_fre</td>\n",
       "      <td>0.079191</td>\n",
       "      <td>0.065960</td>\n",
       "      <td>0.165304</td>\n",
       "      <td>-0.008120</td>\n",
       "      <td>7.540617e-02</td>\n",
       "      <td>0.079191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>min_sentence_lm_prob</td>\n",
       "      <td>0.075645</td>\n",
       "      <td>-0.105702</td>\n",
       "      <td>0.161832</td>\n",
       "      <td>-0.011687</td>\n",
       "      <td>8.948399e-02</td>\n",
       "      <td>0.075645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count_words</td>\n",
       "      <td>0.071441</td>\n",
       "      <td>0.273249</td>\n",
       "      <td>0.157713</td>\n",
       "      <td>-0.015913</td>\n",
       "      <td>1.088213e-01</td>\n",
       "      <td>0.071441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_characters_per_word</td>\n",
       "      <td>-0.068566</td>\n",
       "      <td>-0.098305</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-0.154895</td>\n",
       "      <td>1.238458e-01</td>\n",
       "      <td>0.068566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>count_syllables_per_word</td>\n",
       "      <td>-0.063884</td>\n",
       "      <td>-0.094908</td>\n",
       "      <td>0.023502</td>\n",
       "      <td>-0.150301</td>\n",
       "      <td>1.517100e-01</td>\n",
       "      <td>0.063884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>QuEst_nb_target_tokens</td>\n",
       "      <td>0.062424</td>\n",
       "      <td>0.262939</td>\n",
       "      <td>0.148868</td>\n",
       "      <td>-0.024967</td>\n",
       "      <td>1.613056e-01</td>\n",
       "      <td>0.062424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>QuEst_nb_trigram_q1_freq</td>\n",
       "      <td>0.061886</td>\n",
       "      <td>0.087380</td>\n",
       "      <td>0.148340</td>\n",
       "      <td>-0.025507</td>\n",
       "      <td>1.649540e-01</td>\n",
       "      <td>0.061886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>count_characters</td>\n",
       "      <td>0.056307</td>\n",
       "      <td>0.264943</td>\n",
       "      <td>0.142861</td>\n",
       "      <td>-0.031100</td>\n",
       "      <td>2.065108e-01</td>\n",
       "      <td>0.056307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>QuEst_nb_bigram_q4_freq</td>\n",
       "      <td>-0.049757</td>\n",
       "      <td>-0.073470</td>\n",
       "      <td>0.037661</td>\n",
       "      <td>-0.136420</td>\n",
       "      <td>2.643910e-01</td>\n",
       "      <td>0.049757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>QuEst_avg_source_token_length</td>\n",
       "      <td>-0.048408</td>\n",
       "      <td>-0.052871</td>\n",
       "      <td>0.039011</td>\n",
       "      <td>-0.135093</td>\n",
       "      <td>2.775737e-01</td>\n",
       "      <td>0.048408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>QuEst_nb_trigram_q4_freq</td>\n",
       "      <td>0.041156</td>\n",
       "      <td>-0.111021</td>\n",
       "      <td>0.127951</td>\n",
       "      <td>-0.046265</td>\n",
       "      <td>3.560289e-01</td>\n",
       "      <td>0.041156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count_syllables_in_sentence</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.250373</td>\n",
       "      <td>0.127893</td>\n",
       "      <td>-0.046325</td>\n",
       "      <td>3.567211e-01</td>\n",
       "      <td>0.041097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TERp_Ins</td>\n",
       "      <td>-0.037457</td>\n",
       "      <td>0.018826</td>\n",
       "      <td>0.049961</td>\n",
       "      <td>-0.124306</td>\n",
       "      <td>4.009309e-01</td>\n",
       "      <td>0.037457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>QuEst_nb_source_punct</td>\n",
       "      <td>-0.035424</td>\n",
       "      <td>-0.088713</td>\n",
       "      <td>0.051991</td>\n",
       "      <td>-0.122301</td>\n",
       "      <td>4.269971e-01</td>\n",
       "      <td>0.035424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>QuEst_nb_translations_idf</td>\n",
       "      <td>-0.031822</td>\n",
       "      <td>0.082812</td>\n",
       "      <td>0.055587</td>\n",
       "      <td>-0.118748</td>\n",
       "      <td>4.755203e-01</td>\n",
       "      <td>0.031822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>QuEst_nb_translations</td>\n",
       "      <td>-0.023205</td>\n",
       "      <td>-0.159136</td>\n",
       "      <td>0.064180</td>\n",
       "      <td>-0.110237</td>\n",
       "      <td>6.028870e-01</td>\n",
       "      <td>0.023205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>QuEst_nb_unigram_q1_freq</td>\n",
       "      <td>-0.020409</td>\n",
       "      <td>-0.042506</td>\n",
       "      <td>0.066966</td>\n",
       "      <td>-0.107472</td>\n",
       "      <td>6.472833e-01</td>\n",
       "      <td>0.020409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sentence_fkgl</td>\n",
       "      <td>-0.020307</td>\n",
       "      <td>0.084985</td>\n",
       "      <td>0.067067</td>\n",
       "      <td>-0.107372</td>\n",
       "      <td>6.489202e-01</td>\n",
       "      <td>0.020307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>QuEst_type_token_ratio</td>\n",
       "      <td>-0.017184</td>\n",
       "      <td>0.111872</td>\n",
       "      <td>0.070176</td>\n",
       "      <td>-0.104283</td>\n",
       "      <td>7.000620e-01</td>\n",
       "      <td>0.017184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>nlgeval_CIDEr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TERp_Stem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TERp_Syn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TERp_Phrase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>QuEst_lm_prob_source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>QuEst_lm_prob_target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  team  valid_pearson   pearson  \\\n",
       "37                    nltkBLEU_method7       0.588836  0.522980   \n",
       "32                    nltkBLEU_method2       0.587551  0.520681   \n",
       "34                    nltkBLEU_method4       0.586188  0.516174   \n",
       "35                    nltkBLEU_method5       0.583989  0.518289   \n",
       "33                    nltkBLEU_method3       0.581627  0.511795   \n",
       "36                    nltkBLEU_method6       0.579019  0.512754   \n",
       "31                    nltkBLEU_method1       0.578284  0.510670   \n",
       "25                      nlgeval_Bleu_3       0.574913  0.519681   \n",
       "27                      nlgeval_METEOR       0.574645  0.582689   \n",
       "24                      nlgeval_Bleu_2       0.572326  0.522042   \n",
       "26                      nlgeval_Bleu_4       0.571856  0.508691   \n",
       "30                    nltkBLEU_method0       0.571854  0.508690   \n",
       "17                   word_intersection       0.550394  0.501574   \n",
       "23                      nlgeval_Bleu_1       0.549643  0.523669   \n",
       "28                     nlgeval_ROUGE_L       0.546917  0.472783   \n",
       "48                           TERp_TERp      -0.540798 -0.484857   \n",
       "46                          TERp_NumEr      -0.528643 -0.488232   \n",
       "39                            TERp_Del      -0.499968 -0.521907   \n",
       "22                    hungarian_cosine       0.491421  0.521263   \n",
       "21                       hungarian_dot       0.448457  0.482534   \n",
       "20                      average_cosine       0.435330  0.341948   \n",
       "18  characters_per_sentence_difference      -0.393841 -0.424026   \n",
       "15            average_sentence_lm_prob       0.393022  0.358612   \n",
       "12                average_concreteness      -0.279329 -0.058816   \n",
       "49              QuEst_nb_source_tokens      -0.276634 -0.131891   \n",
       "47                          TERp_NumWd      -0.267304 -0.129187   \n",
       "40                            TERp_Sub      -0.199247  0.037551   \n",
       "11                    min_concreteness      -0.194511 -0.069427   \n",
       "44                           TERp_Shft      -0.193195  0.002126   \n",
       "2                      count_sentences      -0.168994 -0.133562   \n",
       "..                                 ...            ...       ...   \n",
       "10           average_pos_in_freq_table      -0.137807 -0.097339   \n",
       "59             QuEst_nb_bigram_q1_freq      -0.133831 -0.068606   \n",
       "65               QuEst_nb_target_punct       0.108326  0.117109   \n",
       "9                max_pos_in_freq_table       0.097438  0.008824   \n",
       "19                         average_dot       0.088357  0.038198   \n",
       "13                        sentence_fre       0.079191  0.065960   \n",
       "16                min_sentence_lm_prob       0.075645 -0.105702   \n",
       "0                          count_words       0.071441  0.273249   \n",
       "7            count_characters_per_word      -0.068566 -0.098305   \n",
       "8             count_syllables_per_word      -0.063884 -0.094908   \n",
       "50              QuEst_nb_target_tokens       0.062424  0.262939   \n",
       "61            QuEst_nb_trigram_q1_freq       0.061886  0.087380   \n",
       "1                     count_characters       0.056307  0.264943   \n",
       "60             QuEst_nb_bigram_q4_freq      -0.049757 -0.073470   \n",
       "51       QuEst_avg_source_token_length      -0.048408 -0.052871   \n",
       "62            QuEst_nb_trigram_q4_freq       0.041156 -0.111021   \n",
       "3          count_syllables_in_sentence       0.041097  0.250373   \n",
       "38                            TERp_Ins      -0.037457  0.018826   \n",
       "64               QuEst_nb_source_punct      -0.035424 -0.088713   \n",
       "56           QuEst_nb_translations_idf      -0.031822  0.082812   \n",
       "55               QuEst_nb_translations      -0.023205 -0.159136   \n",
       "57            QuEst_nb_unigram_q1_freq      -0.020409 -0.042506   \n",
       "14                       sentence_fkgl      -0.020307  0.084985   \n",
       "54              QuEst_type_token_ratio      -0.017184  0.111872   \n",
       "29                       nlgeval_CIDEr            NaN       NaN   \n",
       "41                           TERp_Stem            NaN       NaN   \n",
       "42                            TERp_Syn            NaN       NaN   \n",
       "43                         TERp_Phrase            NaN       NaN   \n",
       "52                QuEst_lm_prob_source            NaN       NaN   \n",
       "53                QuEst_lm_prob_target            NaN       NaN   \n",
       "\n",
       "    valid_conf_int_high  valid_conf_int_low       valid_p  valid_pearson_abs  \n",
       "37             0.643052            0.528748  1.885627e-48           0.588836  \n",
       "32             0.641898            0.527331  3.379901e-48           0.587551  \n",
       "34             0.640674            0.525828  6.257325e-48           0.586188  \n",
       "35             0.638699            0.523405  1.680190e-47           0.583989  \n",
       "33             0.636576            0.520802  4.815431e-47           0.581627  \n",
       "36             0.634231            0.517931  1.524150e-46           0.579019  \n",
       "31             0.633570            0.517121  2.105299e-46           0.578284  \n",
       "25             0.630537            0.513412  9.159703e-46           0.574913  \n",
       "27             0.630296            0.513118  1.028769e-45           0.574645  \n",
       "24             0.628210            0.510568  2.797788e-45           0.572326  \n",
       "26             0.627786            0.510051  3.424731e-45           0.571856  \n",
       "30             0.627784            0.510049  3.427292e-45           0.571854  \n",
       "17             0.608430            0.486504  2.464327e-41           0.550394  \n",
       "23             0.607751            0.485681  3.323943e-41           0.549643  \n",
       "28             0.605287            0.482697  9.787660e-41           0.546917  \n",
       "48            -0.476005           -0.599753  1.066043e-39           0.540798  \n",
       "46            -0.462732           -0.588741  1.061888e-37           0.528643  \n",
       "39            -0.431538           -0.562676  2.704401e-33           0.499968  \n",
       "22             0.554883            0.422272  4.639851e-32           0.491421  \n",
       "21             0.515539            0.375912  2.348606e-26           0.448457  \n",
       "20             0.503461            0.361818  9.084706e-25           0.435330  \n",
       "18            -0.317496           -0.465112  3.477202e-20           0.393841  \n",
       "15             0.464353            0.316625  4.220386e-20           0.393022  \n",
       "12            -0.196872           -0.357861  1.667737e-10           0.279329  \n",
       "49            -0.194063           -0.355313  2.531952e-10           0.276634  \n",
       "47            -0.184349           -0.346478  1.038172e-09           0.267304  \n",
       "40            -0.113973           -0.281606  6.429784e-06           0.199247  \n",
       "11            -0.109108           -0.277064  1.070674e-05           0.194511  \n",
       "44            -0.107756           -0.275801  1.231085e-05           0.193195  \n",
       "2             -0.082962           -0.252525  1.357815e-04           0.168994  \n",
       "..                  ...                 ...           ...                ...  \n",
       "10            -0.051167           -0.222388  1.909377e-03           0.137807  \n",
       "59            -0.047126           -0.218534  2.581823e-03           0.133831  \n",
       "65             0.193750            0.021272  1.487251e-02           0.108326  \n",
       "9              0.183136            0.010271  2.856465e-02           0.097438  \n",
       "19             0.174268            0.001110  4.719650e-02           0.088357  \n",
       "13             0.165304           -0.008120  7.540617e-02           0.079191  \n",
       "16             0.161832           -0.011687  8.948399e-02           0.075645  \n",
       "0              0.157713           -0.015913  1.088213e-01           0.071441  \n",
       "7              0.018801           -0.154895  1.238458e-01           0.068566  \n",
       "8              0.023502           -0.150301  1.517100e-01           0.063884  \n",
       "50             0.148868           -0.024967  1.613056e-01           0.062424  \n",
       "61             0.148340           -0.025507  1.649540e-01           0.061886  \n",
       "1              0.142861           -0.031100  2.065108e-01           0.056307  \n",
       "60             0.037661           -0.136420  2.643910e-01           0.049757  \n",
       "51             0.039011           -0.135093  2.775737e-01           0.048408  \n",
       "62             0.127951           -0.046265  3.560289e-01           0.041156  \n",
       "3              0.127893           -0.046325  3.567211e-01           0.041097  \n",
       "38             0.049961           -0.124306  4.009309e-01           0.037457  \n",
       "64             0.051991           -0.122301  4.269971e-01           0.035424  \n",
       "56             0.055587           -0.118748  4.755203e-01           0.031822  \n",
       "55             0.064180           -0.110237  6.028870e-01           0.023205  \n",
       "57             0.066966           -0.107472  6.472833e-01           0.020409  \n",
       "14             0.067067           -0.107372  6.489202e-01           0.020307  \n",
       "54             0.070176           -0.104283  7.000620e-01           0.017184  \n",
       "29                  NaN                 NaN  1.000000e+00                NaN  \n",
       "41                  NaN                 NaN  1.000000e+00                NaN  \n",
       "42                  NaN                 NaN  1.000000e+00                NaN  \n",
       "43                  NaN                 NaN  1.000000e+00                NaN  \n",
       "52                  NaN                 NaN  1.000000e+00                NaN  \n",
       "53                  NaN                 NaN  1.000000e+00                NaN  \n",
       "\n",
       "[66 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('meaning_preservation')\n",
    "single_feature_dfs['meaning_preservation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simplicity\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>valid_pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>valid_conf_int_high</th>\n",
       "      <th>valid_conf_int_low</th>\n",
       "      <th>valid_p</th>\n",
       "      <th>valid_pearson_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>count_characters_per_sentence</td>\n",
       "      <td>-0.524111</td>\n",
       "      <td>-0.454583</td>\n",
       "      <td>-0.457792</td>\n",
       "      <td>-0.584630</td>\n",
       "      <td>5.631013e-37</td>\n",
       "      <td>0.524111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_syllables_per_sentence</td>\n",
       "      <td>-0.518966</td>\n",
       "      <td>-0.485575</td>\n",
       "      <td>-0.452187</td>\n",
       "      <td>-0.579959</td>\n",
       "      <td>3.631159e-36</td>\n",
       "      <td>0.518966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>count_words_per_sentence</td>\n",
       "      <td>-0.511017</td>\n",
       "      <td>-0.385900</td>\n",
       "      <td>-0.443539</td>\n",
       "      <td>-0.572735</td>\n",
       "      <td>6.077295e-35</td>\n",
       "      <td>0.511017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>count_characters</td>\n",
       "      <td>-0.477266</td>\n",
       "      <td>-0.371695</td>\n",
       "      <td>-0.406958</td>\n",
       "      <td>-0.541952</td>\n",
       "      <td>4.322839e-30</td>\n",
       "      <td>0.477266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>QuEst_nb_target_tokens</td>\n",
       "      <td>-0.471573</td>\n",
       "      <td>-0.287381</td>\n",
       "      <td>-0.400810</td>\n",
       "      <td>-0.536742</td>\n",
       "      <td>2.525412e-29</td>\n",
       "      <td>0.471573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count_words</td>\n",
       "      <td>-0.469456</td>\n",
       "      <td>-0.288663</td>\n",
       "      <td>-0.398526</td>\n",
       "      <td>-0.534804</td>\n",
       "      <td>4.826552e-29</td>\n",
       "      <td>0.469456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count_syllables_in_sentence</td>\n",
       "      <td>-0.459571</td>\n",
       "      <td>-0.416363</td>\n",
       "      <td>-0.387870</td>\n",
       "      <td>-0.525744</td>\n",
       "      <td>9.371226e-28</td>\n",
       "      <td>0.459571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>QuEst_nb_target_punct</td>\n",
       "      <td>-0.416411</td>\n",
       "      <td>-0.311810</td>\n",
       "      <td>-0.341567</td>\n",
       "      <td>-0.486008</td>\n",
       "      <td>1.340936e-22</td>\n",
       "      <td>0.416411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TERp_NumWd</td>\n",
       "      <td>-0.381278</td>\n",
       "      <td>-0.215241</td>\n",
       "      <td>-0.304141</td>\n",
       "      <td>-0.453448</td>\n",
       "      <td>6.406164e-19</td>\n",
       "      <td>0.381278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>QuEst_nb_source_tokens</td>\n",
       "      <td>-0.376916</td>\n",
       "      <td>-0.211450</td>\n",
       "      <td>-0.299512</td>\n",
       "      <td>-0.449392</td>\n",
       "      <td>1.711243e-18</td>\n",
       "      <td>0.376916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sentence_fkgl</td>\n",
       "      <td>-0.362965</td>\n",
       "      <td>-0.368157</td>\n",
       "      <td>-0.284728</td>\n",
       "      <td>-0.436399</td>\n",
       "      <td>3.593629e-17</td>\n",
       "      <td>0.362965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>QuEst_nb_source_punct</td>\n",
       "      <td>-0.340770</td>\n",
       "      <td>-0.179594</td>\n",
       "      <td>-0.261284</td>\n",
       "      <td>-0.415666</td>\n",
       "      <td>3.384714e-15</td>\n",
       "      <td>0.340770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TERp_Shft</td>\n",
       "      <td>-0.265712</td>\n",
       "      <td>0.191080</td>\n",
       "      <td>-0.182692</td>\n",
       "      <td>-0.344969</td>\n",
       "      <td>1.313733e-09</td>\n",
       "      <td>0.265712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>QuEst_type_token_ratio</td>\n",
       "      <td>-0.224085</td>\n",
       "      <td>-0.025446</td>\n",
       "      <td>-0.139558</td>\n",
       "      <td>-0.305369</td>\n",
       "      <td>3.617834e-07</td>\n",
       "      <td>0.224085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>average_concreteness</td>\n",
       "      <td>0.208423</td>\n",
       "      <td>0.321305</td>\n",
       "      <td>0.290397</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>2.311359e-06</td>\n",
       "      <td>0.208423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>QuEst_nb_translations_idf</td>\n",
       "      <td>-0.181507</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>-0.095769</td>\n",
       "      <td>-0.264572</td>\n",
       "      <td>4.080177e-05</td>\n",
       "      <td>0.181507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>min_sentence_lm_prob</td>\n",
       "      <td>0.168595</td>\n",
       "      <td>0.153428</td>\n",
       "      <td>0.252141</td>\n",
       "      <td>0.082555</td>\n",
       "      <td>1.408869e-04</td>\n",
       "      <td>0.168595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sentence_fre</td>\n",
       "      <td>0.163489</td>\n",
       "      <td>0.272006</td>\n",
       "      <td>0.247217</td>\n",
       "      <td>0.077337</td>\n",
       "      <td>2.245167e-04</td>\n",
       "      <td>0.163489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>word_intersection</td>\n",
       "      <td>-0.154207</td>\n",
       "      <td>-0.219330</td>\n",
       "      <td>-0.067866</td>\n",
       "      <td>-0.238257</td>\n",
       "      <td>5.058928e-04</td>\n",
       "      <td>0.154207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>average_dot</td>\n",
       "      <td>0.151732</td>\n",
       "      <td>-0.034563</td>\n",
       "      <td>0.235865</td>\n",
       "      <td>0.065342</td>\n",
       "      <td>6.236009e-04</td>\n",
       "      <td>0.151732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>QuEst_nb_unigram_q1_freq</td>\n",
       "      <td>-0.144093</td>\n",
       "      <td>-0.112853</td>\n",
       "      <td>-0.057562</td>\n",
       "      <td>-0.228476</td>\n",
       "      <td>1.166141e-03</td>\n",
       "      <td>0.144093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count_sentences</td>\n",
       "      <td>0.141845</td>\n",
       "      <td>0.195161</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>0.055275</td>\n",
       "      <td>1.394173e-03</td>\n",
       "      <td>0.141845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nlgeval_Bleu_1</td>\n",
       "      <td>-0.140303</td>\n",
       "      <td>-0.198159</td>\n",
       "      <td>-0.053706</td>\n",
       "      <td>-0.224806</td>\n",
       "      <td>1.573596e-03</td>\n",
       "      <td>0.140303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>min_concreteness</td>\n",
       "      <td>0.138411</td>\n",
       "      <td>0.155254</td>\n",
       "      <td>0.222973</td>\n",
       "      <td>0.051782</td>\n",
       "      <td>1.822580e-03</td>\n",
       "      <td>0.138411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>characters_per_sentence_difference</td>\n",
       "      <td>0.137533</td>\n",
       "      <td>0.177087</td>\n",
       "      <td>0.222123</td>\n",
       "      <td>0.050889</td>\n",
       "      <td>1.949940e-03</td>\n",
       "      <td>0.137533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nlgeval_Bleu_2</td>\n",
       "      <td>-0.128974</td>\n",
       "      <td>-0.228452</td>\n",
       "      <td>-0.042194</td>\n",
       "      <td>-0.213823</td>\n",
       "      <td>3.692683e-03</td>\n",
       "      <td>0.128974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nlgeval_Bleu_3</td>\n",
       "      <td>-0.124757</td>\n",
       "      <td>-0.251035</td>\n",
       "      <td>-0.037914</td>\n",
       "      <td>-0.209729</td>\n",
       "      <td>4.991416e-03</td>\n",
       "      <td>0.124757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>nltkBLEU_method0</td>\n",
       "      <td>-0.124227</td>\n",
       "      <td>-0.271181</td>\n",
       "      <td>-0.037377</td>\n",
       "      <td>-0.209214</td>\n",
       "      <td>5.180691e-03</td>\n",
       "      <td>0.124227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nlgeval_Bleu_4</td>\n",
       "      <td>-0.124227</td>\n",
       "      <td>-0.271181</td>\n",
       "      <td>-0.037377</td>\n",
       "      <td>-0.209214</td>\n",
       "      <td>5.180818e-03</td>\n",
       "      <td>0.124227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>nltkBLEU_method7</td>\n",
       "      <td>-0.123828</td>\n",
       "      <td>-0.266596</td>\n",
       "      <td>-0.036972</td>\n",
       "      <td>-0.208826</td>\n",
       "      <td>5.327791e-03</td>\n",
       "      <td>0.123828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TERp_WdSh</td>\n",
       "      <td>-0.118101</td>\n",
       "      <td>0.199431</td>\n",
       "      <td>-0.031167</td>\n",
       "      <td>-0.203262</td>\n",
       "      <td>7.890439e-03</td>\n",
       "      <td>0.118101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>average_cosine</td>\n",
       "      <td>-0.116497</td>\n",
       "      <td>-0.198720</td>\n",
       "      <td>-0.029542</td>\n",
       "      <td>-0.201702</td>\n",
       "      <td>8.783112e-03</td>\n",
       "      <td>0.116497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>nltkBLEU_method2</td>\n",
       "      <td>-0.116096</td>\n",
       "      <td>-0.265814</td>\n",
       "      <td>-0.029136</td>\n",
       "      <td>-0.201311</td>\n",
       "      <td>9.019984e-03</td>\n",
       "      <td>0.116096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hungarian_cosine</td>\n",
       "      <td>-0.115354</td>\n",
       "      <td>-0.070964</td>\n",
       "      <td>-0.028384</td>\n",
       "      <td>-0.200590</td>\n",
       "      <td>9.473028e-03</td>\n",
       "      <td>0.115354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TERp_TERp</td>\n",
       "      <td>0.113017</td>\n",
       "      <td>0.243660</td>\n",
       "      <td>0.198317</td>\n",
       "      <td>0.026019</td>\n",
       "      <td>1.103466e-02</td>\n",
       "      <td>0.113017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average_pos_in_freq_table</td>\n",
       "      <td>0.106498</td>\n",
       "      <td>-0.050834</td>\n",
       "      <td>0.191969</td>\n",
       "      <td>0.019423</td>\n",
       "      <td>1.666026e-02</td>\n",
       "      <td>0.106498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_pos_in_freq_table</td>\n",
       "      <td>-0.091360</td>\n",
       "      <td>0.044396</td>\n",
       "      <td>-0.004138</td>\n",
       "      <td>-0.177202</td>\n",
       "      <td>4.014370e-02</td>\n",
       "      <td>0.091360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hungarian_dot</td>\n",
       "      <td>-0.080643</td>\n",
       "      <td>-0.116291</td>\n",
       "      <td>0.006659</td>\n",
       "      <td>-0.166725</td>\n",
       "      <td>7.019041e-02</td>\n",
       "      <td>0.080643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>QuEst_nb_trigram_q1_freq</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.157084</td>\n",
       "      <td>-0.016557</td>\n",
       "      <td>1.120421e-01</td>\n",
       "      <td>0.070800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nlgeval_METEOR</td>\n",
       "      <td>-0.068208</td>\n",
       "      <td>-0.266317</td>\n",
       "      <td>0.019161</td>\n",
       "      <td>-0.154544</td>\n",
       "      <td>1.258238e-01</td>\n",
       "      <td>0.068208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TERp_Del</td>\n",
       "      <td>0.066703</td>\n",
       "      <td>0.138293</td>\n",
       "      <td>0.153067</td>\n",
       "      <td>-0.020673</td>\n",
       "      <td>1.344176e-01</td>\n",
       "      <td>0.066703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TERp_Ins</td>\n",
       "      <td>-0.054067</td>\n",
       "      <td>0.178275</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>-0.140659</td>\n",
       "      <td>2.251748e-01</td>\n",
       "      <td>0.054067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>QuEst_nb_source_words_in_corpus</td>\n",
       "      <td>0.047568</td>\n",
       "      <td>-0.093148</td>\n",
       "      <td>0.134266</td>\n",
       "      <td>-0.039853</td>\n",
       "      <td>2.860123e-01</td>\n",
       "      <td>0.047568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>QuEst_nb_translations</td>\n",
       "      <td>-0.043303</td>\n",
       "      <td>0.065850</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>-0.130067</td>\n",
       "      <td>3.314671e-01</td>\n",
       "      <td>0.043303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TERp_NumEr</td>\n",
       "      <td>0.040503</td>\n",
       "      <td>0.220390</td>\n",
       "      <td>0.127308</td>\n",
       "      <td>-0.046918</td>\n",
       "      <td>3.637202e-01</td>\n",
       "      <td>0.040503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TERp_Sub</td>\n",
       "      <td>0.038828</td>\n",
       "      <td>0.182242</td>\n",
       "      <td>0.125657</td>\n",
       "      <td>-0.048592</td>\n",
       "      <td>3.839140e-01</td>\n",
       "      <td>0.038828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>QuEst_nb_unigram_q4_freq</td>\n",
       "      <td>0.032675</td>\n",
       "      <td>0.039421</td>\n",
       "      <td>0.119589</td>\n",
       "      <td>-0.054736</td>\n",
       "      <td>4.637734e-01</td>\n",
       "      <td>0.032675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>count_syllables_per_word</td>\n",
       "      <td>0.022822</td>\n",
       "      <td>-0.190666</td>\n",
       "      <td>0.109858</td>\n",
       "      <td>-0.064562</td>\n",
       "      <td>6.088946e-01</td>\n",
       "      <td>0.022822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>QuEst_nb_trigram_q4_freq</td>\n",
       "      <td>-0.017043</td>\n",
       "      <td>-0.049712</td>\n",
       "      <td>0.070316</td>\n",
       "      <td>-0.104143</td>\n",
       "      <td>7.024031e-01</td>\n",
       "      <td>0.017043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>QuEst_avg_source_token_length</td>\n",
       "      <td>0.015474</td>\n",
       "      <td>-0.256323</td>\n",
       "      <td>0.102591</td>\n",
       "      <td>-0.071878</td>\n",
       "      <td>7.286699e-01</td>\n",
       "      <td>0.015474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>QuEst_nb_bigram_q1_freq</td>\n",
       "      <td>-0.010150</td>\n",
       "      <td>-0.294421</td>\n",
       "      <td>0.077173</td>\n",
       "      <td>-0.097319</td>\n",
       "      <td>8.200111e-01</td>\n",
       "      <td>0.010150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>QuEst_nb_bigram_q4_freq</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.029161</td>\n",
       "      <td>0.095127</td>\n",
       "      <td>-0.079372</td>\n",
       "      <td>8.587692e-01</td>\n",
       "      <td>0.007938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>average_sentence_lm_prob</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.083226</td>\n",
       "      <td>0.090235</td>\n",
       "      <td>-0.084273</td>\n",
       "      <td>9.463151e-01</td>\n",
       "      <td>0.003004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_characters_per_word</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>-0.168727</td>\n",
       "      <td>0.087783</td>\n",
       "      <td>-0.086727</td>\n",
       "      <td>9.904858e-01</td>\n",
       "      <td>0.000532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>nlgeval_CIDEr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TERp_Stem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TERp_Syn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TERp_Phrase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>QuEst_lm_prob_source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>QuEst_lm_prob_target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  team  valid_pearson   pearson  \\\n",
       "5        count_characters_per_sentence      -0.524111 -0.454583   \n",
       "6         count_syllables_per_sentence      -0.518966 -0.485575   \n",
       "4             count_words_per_sentence      -0.511017 -0.385900   \n",
       "1                     count_characters      -0.477266 -0.371695   \n",
       "50              QuEst_nb_target_tokens      -0.471573 -0.287381   \n",
       "0                          count_words      -0.469456 -0.288663   \n",
       "3          count_syllables_in_sentence      -0.459571 -0.416363   \n",
       "65               QuEst_nb_target_punct      -0.416411 -0.311810   \n",
       "47                          TERp_NumWd      -0.381278 -0.215241   \n",
       "49              QuEst_nb_source_tokens      -0.376916 -0.211450   \n",
       "14                       sentence_fkgl      -0.362965 -0.368157   \n",
       "64               QuEst_nb_source_punct      -0.340770 -0.179594   \n",
       "44                           TERp_Shft      -0.265712  0.191080   \n",
       "54              QuEst_type_token_ratio      -0.224085 -0.025446   \n",
       "12                average_concreteness       0.208423  0.321305   \n",
       "56           QuEst_nb_translations_idf      -0.181507  0.004039   \n",
       "16                min_sentence_lm_prob       0.168595  0.153428   \n",
       "13                        sentence_fre       0.163489  0.272006   \n",
       "17                   word_intersection      -0.154207 -0.219330   \n",
       "19                         average_dot       0.151732 -0.034563   \n",
       "57            QuEst_nb_unigram_q1_freq      -0.144093 -0.112853   \n",
       "2                      count_sentences       0.141845  0.195161   \n",
       "23                      nlgeval_Bleu_1      -0.140303 -0.198159   \n",
       "11                    min_concreteness       0.138411  0.155254   \n",
       "18  characters_per_sentence_difference       0.137533  0.177087   \n",
       "24                      nlgeval_Bleu_2      -0.128974 -0.228452   \n",
       "25                      nlgeval_Bleu_3      -0.124757 -0.251035   \n",
       "30                    nltkBLEU_method0      -0.124227 -0.271181   \n",
       "26                      nlgeval_Bleu_4      -0.124227 -0.271181   \n",
       "37                    nltkBLEU_method7      -0.123828 -0.266596   \n",
       "..                                 ...            ...       ...   \n",
       "45                           TERp_WdSh      -0.118101  0.199431   \n",
       "20                      average_cosine      -0.116497 -0.198720   \n",
       "32                    nltkBLEU_method2      -0.116096 -0.265814   \n",
       "22                    hungarian_cosine      -0.115354 -0.070964   \n",
       "48                           TERp_TERp       0.113017  0.243660   \n",
       "10           average_pos_in_freq_table       0.106498 -0.050834   \n",
       "9                max_pos_in_freq_table      -0.091360  0.044396   \n",
       "21                       hungarian_dot      -0.080643 -0.116291   \n",
       "61            QuEst_nb_trigram_q1_freq       0.070800  0.004975   \n",
       "27                      nlgeval_METEOR      -0.068208 -0.266317   \n",
       "39                            TERp_Del       0.066703  0.138293   \n",
       "38                            TERp_Ins      -0.054067  0.178275   \n",
       "63     QuEst_nb_source_words_in_corpus       0.047568 -0.093148   \n",
       "55               QuEst_nb_translations      -0.043303  0.065850   \n",
       "46                          TERp_NumEr       0.040503  0.220390   \n",
       "40                            TERp_Sub       0.038828  0.182242   \n",
       "58            QuEst_nb_unigram_q4_freq       0.032675  0.039421   \n",
       "8             count_syllables_per_word       0.022822 -0.190666   \n",
       "62            QuEst_nb_trigram_q4_freq      -0.017043 -0.049712   \n",
       "51       QuEst_avg_source_token_length       0.015474 -0.256323   \n",
       "59             QuEst_nb_bigram_q1_freq      -0.010150 -0.294421   \n",
       "60             QuEst_nb_bigram_q4_freq       0.007938  0.029161   \n",
       "15            average_sentence_lm_prob       0.003004  0.083226   \n",
       "7            count_characters_per_word       0.000532 -0.168727   \n",
       "29                       nlgeval_CIDEr            NaN       NaN   \n",
       "41                           TERp_Stem            NaN       NaN   \n",
       "42                            TERp_Syn            NaN       NaN   \n",
       "43                         TERp_Phrase            NaN       NaN   \n",
       "52                QuEst_lm_prob_source            NaN       NaN   \n",
       "53                QuEst_lm_prob_target            NaN       NaN   \n",
       "\n",
       "    valid_conf_int_high  valid_conf_int_low       valid_p  valid_pearson_abs  \n",
       "5             -0.457792           -0.584630  5.631013e-37           0.524111  \n",
       "6             -0.452187           -0.579959  3.631159e-36           0.518966  \n",
       "4             -0.443539           -0.572735  6.077295e-35           0.511017  \n",
       "1             -0.406958           -0.541952  4.322839e-30           0.477266  \n",
       "50            -0.400810           -0.536742  2.525412e-29           0.471573  \n",
       "0             -0.398526           -0.534804  4.826552e-29           0.469456  \n",
       "3             -0.387870           -0.525744  9.371226e-28           0.459571  \n",
       "65            -0.341567           -0.486008  1.340936e-22           0.416411  \n",
       "47            -0.304141           -0.453448  6.406164e-19           0.381278  \n",
       "49            -0.299512           -0.449392  1.711243e-18           0.376916  \n",
       "14            -0.284728           -0.436399  3.593629e-17           0.362965  \n",
       "64            -0.261284           -0.415666  3.384714e-15           0.340770  \n",
       "44            -0.182692           -0.344969  1.313733e-09           0.265712  \n",
       "54            -0.139558           -0.305369  3.617834e-07           0.224085  \n",
       "12             0.290397            0.123413  2.311359e-06           0.208423  \n",
       "56            -0.095769           -0.264572  4.080177e-05           0.181507  \n",
       "16             0.252141            0.082555  1.408869e-04           0.168595  \n",
       "13             0.247217            0.077337  2.245167e-04           0.163489  \n",
       "17            -0.067866           -0.238257  5.058928e-04           0.154207  \n",
       "19             0.235865            0.065342  6.236009e-04           0.151732  \n",
       "57            -0.057562           -0.228476  1.166141e-03           0.144093  \n",
       "2              0.226300            0.055275  1.394173e-03           0.141845  \n",
       "23            -0.053706           -0.224806  1.573596e-03           0.140303  \n",
       "11             0.222973            0.051782  1.822580e-03           0.138411  \n",
       "18             0.222123            0.050889  1.949940e-03           0.137533  \n",
       "24            -0.042194           -0.213823  3.692683e-03           0.128974  \n",
       "25            -0.037914           -0.209729  4.991416e-03           0.124757  \n",
       "30            -0.037377           -0.209214  5.180691e-03           0.124227  \n",
       "26            -0.037377           -0.209214  5.180818e-03           0.124227  \n",
       "37            -0.036972           -0.208826  5.327791e-03           0.123828  \n",
       "..                  ...                 ...           ...                ...  \n",
       "45            -0.031167           -0.203262  7.890439e-03           0.118101  \n",
       "20            -0.029542           -0.201702  8.783112e-03           0.116497  \n",
       "32            -0.029136           -0.201311  9.019984e-03           0.116096  \n",
       "22            -0.028384           -0.200590  9.473028e-03           0.115354  \n",
       "48             0.198317            0.026019  1.103466e-02           0.113017  \n",
       "10             0.191969            0.019423  1.666026e-02           0.106498  \n",
       "9             -0.004138           -0.177202  4.014370e-02           0.091360  \n",
       "21             0.006659           -0.166725  7.019041e-02           0.080643  \n",
       "61             0.157084           -0.016557  1.120421e-01           0.070800  \n",
       "27             0.019161           -0.154544  1.258238e-01           0.068208  \n",
       "39             0.153067           -0.020673  1.344176e-01           0.066703  \n",
       "38             0.033345           -0.140659  2.251748e-01           0.054067  \n",
       "63             0.134266           -0.039853  2.860123e-01           0.047568  \n",
       "55             0.044118           -0.130067  3.314671e-01           0.043303  \n",
       "46             0.127308           -0.046918  3.637202e-01           0.040503  \n",
       "40             0.125657           -0.048592  3.839140e-01           0.038828  \n",
       "58             0.119589           -0.054736  4.637734e-01           0.032675  \n",
       "8              0.109858           -0.064562  6.088946e-01           0.022822  \n",
       "62             0.070316           -0.104143  7.024031e-01           0.017043  \n",
       "51             0.102591           -0.071878  7.286699e-01           0.015474  \n",
       "59             0.077173           -0.097319  8.200111e-01           0.010150  \n",
       "60             0.095127           -0.079372  8.587692e-01           0.007938  \n",
       "15             0.090235           -0.084273  9.463151e-01           0.003004  \n",
       "7              0.087783           -0.086727  9.904858e-01           0.000532  \n",
       "29                  NaN                 NaN  1.000000e+00                NaN  \n",
       "41                  NaN                 NaN  1.000000e+00                NaN  \n",
       "42                  NaN                 NaN  1.000000e+00                NaN  \n",
       "43                  NaN                 NaN  1.000000e+00                NaN  \n",
       "52                  NaN                 NaN  1.000000e+00                NaN  \n",
       "53                  NaN                 NaN  1.000000e+00                NaN  \n",
       "\n",
       "[66 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('simplicity')\n",
    "single_feature_dfs['simplicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>valid_pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>valid_conf_int_high</th>\n",
       "      <th>valid_conf_int_low</th>\n",
       "      <th>valid_p</th>\n",
       "      <th>valid_pearson_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>QuEst_nb_source_tokens</td>\n",
       "      <td>-0.433590</td>\n",
       "      <td>-0.215692</td>\n",
       "      <td>-0.359953</td>\n",
       "      <td>-0.501858</td>\n",
       "      <td>1.457161e-24</td>\n",
       "      <td>0.433590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TERp_NumWd</td>\n",
       "      <td>-0.432297</td>\n",
       "      <td>-0.219897</td>\n",
       "      <td>-0.358567</td>\n",
       "      <td>-0.500667</td>\n",
       "      <td>2.066743e-24</td>\n",
       "      <td>0.432297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>count_characters</td>\n",
       "      <td>-0.306712</td>\n",
       "      <td>-0.077350</td>\n",
       "      <td>-0.225491</td>\n",
       "      <td>-0.383698</td>\n",
       "      <td>1.842269e-12</td>\n",
       "      <td>0.306712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count_syllables_in_sentence</td>\n",
       "      <td>-0.306259</td>\n",
       "      <td>-0.130305</td>\n",
       "      <td>-0.225017</td>\n",
       "      <td>-0.383272</td>\n",
       "      <td>1.992580e-12</td>\n",
       "      <td>0.306259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>QuEst_nb_target_tokens</td>\n",
       "      <td>-0.294076</td>\n",
       "      <td>-0.019842</td>\n",
       "      <td>-0.212268</td>\n",
       "      <td>-0.371791</td>\n",
       "      <td>1.564298e-11</td>\n",
       "      <td>0.294076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count_words</td>\n",
       "      <td>-0.289823</td>\n",
       "      <td>-0.017346</td>\n",
       "      <td>-0.207823</td>\n",
       "      <td>-0.367777</td>\n",
       "      <td>3.140102e-11</td>\n",
       "      <td>0.289823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nlgeval_METEOR</td>\n",
       "      <td>0.281753</td>\n",
       "      <td>0.148445</td>\n",
       "      <td>0.360154</td>\n",
       "      <td>0.199401</td>\n",
       "      <td>1.140887e-10</td>\n",
       "      <td>0.281753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sentence_fkgl</td>\n",
       "      <td>-0.279873</td>\n",
       "      <td>-0.244636</td>\n",
       "      <td>-0.197440</td>\n",
       "      <td>-0.358377</td>\n",
       "      <td>1.531859e-10</td>\n",
       "      <td>0.279873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_syllables_per_sentence</td>\n",
       "      <td>-0.274673</td>\n",
       "      <td>-0.178439</td>\n",
       "      <td>-0.192020</td>\n",
       "      <td>-0.353457</td>\n",
       "      <td>3.421647e-10</td>\n",
       "      <td>0.274673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TERp_NumEr</td>\n",
       "      <td>-0.273803</td>\n",
       "      <td>-0.144755</td>\n",
       "      <td>-0.191113</td>\n",
       "      <td>-0.352633</td>\n",
       "      <td>3.907637e-10</td>\n",
       "      <td>0.273803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>count_characters_per_sentence</td>\n",
       "      <td>-0.272428</td>\n",
       "      <td>-0.132553</td>\n",
       "      <td>-0.189682</td>\n",
       "      <td>-0.351332</td>\n",
       "      <td>4.815175e-10</td>\n",
       "      <td>0.272428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>count_words_per_sentence</td>\n",
       "      <td>-0.259926</td>\n",
       "      <td>-0.068805</td>\n",
       "      <td>-0.176678</td>\n",
       "      <td>-0.339482</td>\n",
       "      <td>3.050702e-09</td>\n",
       "      <td>0.259926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>QuEst_nb_source_punct</td>\n",
       "      <td>-0.254104</td>\n",
       "      <td>-0.198211</td>\n",
       "      <td>-0.170632</td>\n",
       "      <td>-0.333955</td>\n",
       "      <td>6.977925e-09</td>\n",
       "      <td>0.254104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TERp_Del</td>\n",
       "      <td>-0.252379</td>\n",
       "      <td>-0.228529</td>\n",
       "      <td>-0.168842</td>\n",
       "      <td>-0.332316</td>\n",
       "      <td>8.881269e-09</td>\n",
       "      <td>0.252379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>nltkBLEU_method2</td>\n",
       "      <td>0.251620</td>\n",
       "      <td>0.108835</td>\n",
       "      <td>0.331595</td>\n",
       "      <td>0.168055</td>\n",
       "      <td>9.870581e-09</td>\n",
       "      <td>0.251620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TERp_Shft</td>\n",
       "      <td>-0.249593</td>\n",
       "      <td>0.066614</td>\n",
       "      <td>-0.165952</td>\n",
       "      <td>-0.329669</td>\n",
       "      <td>1.306365e-08</td>\n",
       "      <td>0.249593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>nltkBLEU_method7</td>\n",
       "      <td>0.248560</td>\n",
       "      <td>0.106866</td>\n",
       "      <td>0.328687</td>\n",
       "      <td>0.164881</td>\n",
       "      <td>1.505475e-08</td>\n",
       "      <td>0.248560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>nltkBLEU_method4</td>\n",
       "      <td>0.246016</td>\n",
       "      <td>0.098010</td>\n",
       "      <td>0.326267</td>\n",
       "      <td>0.162244</td>\n",
       "      <td>2.129551e-08</td>\n",
       "      <td>0.246016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>nltkBLEU_method5</td>\n",
       "      <td>0.245278</td>\n",
       "      <td>0.106195</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>0.161479</td>\n",
       "      <td>2.353266e-08</td>\n",
       "      <td>0.245278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nlgeval_Bleu_2</td>\n",
       "      <td>0.243770</td>\n",
       "      <td>0.147924</td>\n",
       "      <td>0.324130</td>\n",
       "      <td>0.159916</td>\n",
       "      <td>2.883226e-08</td>\n",
       "      <td>0.243770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nltkBLEU_method3</td>\n",
       "      <td>0.243082</td>\n",
       "      <td>0.097686</td>\n",
       "      <td>0.323477</td>\n",
       "      <td>0.159204</td>\n",
       "      <td>3.161396e-08</td>\n",
       "      <td>0.243082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nlgeval_Bleu_3</td>\n",
       "      <td>0.241503</td>\n",
       "      <td>0.124547</td>\n",
       "      <td>0.321973</td>\n",
       "      <td>0.157568</td>\n",
       "      <td>3.902809e-08</td>\n",
       "      <td>0.241503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>nltkBLEU_method6</td>\n",
       "      <td>0.241473</td>\n",
       "      <td>0.100920</td>\n",
       "      <td>0.321945</td>\n",
       "      <td>0.157537</td>\n",
       "      <td>3.918263e-08</td>\n",
       "      <td>0.241473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>nltkBLEU_method1</td>\n",
       "      <td>0.240262</td>\n",
       "      <td>0.097708</td>\n",
       "      <td>0.320792</td>\n",
       "      <td>0.156284</td>\n",
       "      <td>4.600114e-08</td>\n",
       "      <td>0.240262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nlgeval_Bleu_4</td>\n",
       "      <td>0.234982</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>0.315763</td>\n",
       "      <td>0.150820</td>\n",
       "      <td>9.168966e-08</td>\n",
       "      <td>0.234982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>nltkBLEU_method0</td>\n",
       "      <td>0.234981</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>0.315762</td>\n",
       "      <td>0.150818</td>\n",
       "      <td>9.170677e-08</td>\n",
       "      <td>0.234981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>nlgeval_ROUGE_L</td>\n",
       "      <td>0.230987</td>\n",
       "      <td>0.120953</td>\n",
       "      <td>0.311955</td>\n",
       "      <td>0.146689</td>\n",
       "      <td>1.528570e-07</td>\n",
       "      <td>0.230987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TERp_TERp</td>\n",
       "      <td>-0.230689</td>\n",
       "      <td>-0.119249</td>\n",
       "      <td>-0.146380</td>\n",
       "      <td>-0.311670</td>\n",
       "      <td>1.587551e-07</td>\n",
       "      <td>0.230689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nlgeval_Bleu_1</td>\n",
       "      <td>0.230603</td>\n",
       "      <td>0.171252</td>\n",
       "      <td>0.311589</td>\n",
       "      <td>0.146292</td>\n",
       "      <td>1.604822e-07</td>\n",
       "      <td>0.230603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>average_sentence_lm_prob</td>\n",
       "      <td>0.224107</td>\n",
       "      <td>0.300975</td>\n",
       "      <td>0.305390</td>\n",
       "      <td>0.139581</td>\n",
       "      <td>3.607954e-07</td>\n",
       "      <td>0.224107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>characters_per_sentence_difference</td>\n",
       "      <td>-0.168902</td>\n",
       "      <td>-0.131820</td>\n",
       "      <td>-0.082868</td>\n",
       "      <td>-0.252436</td>\n",
       "      <td>1.369479e-04</td>\n",
       "      <td>0.168902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>average_cosine</td>\n",
       "      <td>0.167519</td>\n",
       "      <td>0.097594</td>\n",
       "      <td>0.251103</td>\n",
       "      <td>0.081454</td>\n",
       "      <td>1.556070e-04</td>\n",
       "      <td>0.167519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>QuEst_nb_translations_idf</td>\n",
       "      <td>-0.153654</td>\n",
       "      <td>-0.056064</td>\n",
       "      <td>-0.067301</td>\n",
       "      <td>-0.237722</td>\n",
       "      <td>5.302754e-04</td>\n",
       "      <td>0.153654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>min_sentence_lm_prob</td>\n",
       "      <td>0.149811</td>\n",
       "      <td>0.099907</td>\n",
       "      <td>0.234008</td>\n",
       "      <td>0.063385</td>\n",
       "      <td>7.319343e-04</td>\n",
       "      <td>0.149811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>QuEst_nb_trigram_q1_freq</td>\n",
       "      <td>0.141561</td>\n",
       "      <td>0.081723</td>\n",
       "      <td>0.226024</td>\n",
       "      <td>0.054985</td>\n",
       "      <td>1.425760e-03</td>\n",
       "      <td>0.141561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>average_dot</td>\n",
       "      <td>0.136549</td>\n",
       "      <td>0.026993</td>\n",
       "      <td>0.221169</td>\n",
       "      <td>0.049889</td>\n",
       "      <td>2.102357e-03</td>\n",
       "      <td>0.136549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TERp_WdSh</td>\n",
       "      <td>-0.136227</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>-0.049561</td>\n",
       "      <td>-0.220857</td>\n",
       "      <td>2.154638e-03</td>\n",
       "      <td>0.136227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>QuEst_nb_unigram_q1_freq</td>\n",
       "      <td>-0.104801</td>\n",
       "      <td>-0.136007</td>\n",
       "      <td>-0.017708</td>\n",
       "      <td>-0.190315</td>\n",
       "      <td>1.848505e-02</td>\n",
       "      <td>0.104801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>QuEst_nb_bigram_q1_freq</td>\n",
       "      <td>-0.089535</td>\n",
       "      <td>-0.162964</td>\n",
       "      <td>-0.002298</td>\n",
       "      <td>-0.175419</td>\n",
       "      <td>4.431533e-02</td>\n",
       "      <td>0.089535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>QuEst_nb_source_words_in_corpus</td>\n",
       "      <td>-0.079001</td>\n",
       "      <td>-0.137022</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>-0.165117</td>\n",
       "      <td>7.611415e-02</td>\n",
       "      <td>0.079001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>QuEst_nb_unigram_q4_freq</td>\n",
       "      <td>-0.073683</td>\n",
       "      <td>-0.014605</td>\n",
       "      <td>0.013660</td>\n",
       "      <td>-0.159910</td>\n",
       "      <td>9.813422e-02</td>\n",
       "      <td>0.073683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>average_concreteness</td>\n",
       "      <td>-0.060692</td>\n",
       "      <td>0.180340</td>\n",
       "      <td>0.026705</td>\n",
       "      <td>-0.147167</td>\n",
       "      <td>1.732773e-01</td>\n",
       "      <td>0.060692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_characters_per_word</td>\n",
       "      <td>-0.055357</td>\n",
       "      <td>-0.193792</td>\n",
       "      <td>0.032053</td>\n",
       "      <td>-0.141926</td>\n",
       "      <td>2.142906e-01</td>\n",
       "      <td>0.055357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TERp_Sub</td>\n",
       "      <td>-0.054518</td>\n",
       "      <td>0.177429</td>\n",
       "      <td>0.032894</td>\n",
       "      <td>-0.141102</td>\n",
       "      <td>2.213260e-01</td>\n",
       "      <td>0.054518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TERp_Ins</td>\n",
       "      <td>-0.042451</td>\n",
       "      <td>0.164182</td>\n",
       "      <td>0.044971</td>\n",
       "      <td>-0.129227</td>\n",
       "      <td>3.410809e-01</td>\n",
       "      <td>0.042451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average_pos_in_freq_table</td>\n",
       "      <td>-0.036714</td>\n",
       "      <td>-0.143021</td>\n",
       "      <td>0.050704</td>\n",
       "      <td>-0.123573</td>\n",
       "      <td>4.103539e-01</td>\n",
       "      <td>0.036714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>count_syllables_per_word</td>\n",
       "      <td>-0.034498</td>\n",
       "      <td>-0.231303</td>\n",
       "      <td>0.052916</td>\n",
       "      <td>-0.121388</td>\n",
       "      <td>4.391924e-01</td>\n",
       "      <td>0.034498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>QuEst_nb_translations</td>\n",
       "      <td>-0.030304</td>\n",
       "      <td>-0.067589</td>\n",
       "      <td>0.057102</td>\n",
       "      <td>-0.117249</td>\n",
       "      <td>4.968490e-01</td>\n",
       "      <td>0.030304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>QuEst_avg_source_token_length</td>\n",
       "      <td>-0.029199</td>\n",
       "      <td>-0.175513</td>\n",
       "      <td>0.058204</td>\n",
       "      <td>-0.116158</td>\n",
       "      <td>5.126724e-01</td>\n",
       "      <td>0.029199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>min_concreteness</td>\n",
       "      <td>-0.029136</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.058267</td>\n",
       "      <td>-0.116096</td>\n",
       "      <td>5.135889e-01</td>\n",
       "      <td>0.029136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>QuEst_nb_bigram_q4_freq</td>\n",
       "      <td>-0.022028</td>\n",
       "      <td>0.024482</td>\n",
       "      <td>0.065352</td>\n",
       "      <td>-0.109074</td>\n",
       "      <td>6.214060e-01</td>\n",
       "      <td>0.022028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count_sentences</td>\n",
       "      <td>-0.019013</td>\n",
       "      <td>0.061744</td>\n",
       "      <td>0.068355</td>\n",
       "      <td>-0.106092</td>\n",
       "      <td>6.699310e-01</td>\n",
       "      <td>0.019013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>QuEst_nb_trigram_q4_freq</td>\n",
       "      <td>0.015982</td>\n",
       "      <td>-0.056768</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>-0.071373</td>\n",
       "      <td>7.201337e-01</td>\n",
       "      <td>0.015982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max_pos_in_freq_table</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>0.043533</td>\n",
       "      <td>0.092252</td>\n",
       "      <td>-0.082253</td>\n",
       "      <td>9.100832e-01</td>\n",
       "      <td>0.005038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>nlgeval_CIDEr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TERp_Stem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TERp_Syn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TERp_Phrase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>QuEst_lm_prob_source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>QuEst_lm_prob_target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  team  valid_pearson   pearson  \\\n",
       "49              QuEst_nb_source_tokens      -0.433590 -0.215692   \n",
       "47                          TERp_NumWd      -0.432297 -0.219897   \n",
       "1                     count_characters      -0.306712 -0.077350   \n",
       "3          count_syllables_in_sentence      -0.306259 -0.130305   \n",
       "50              QuEst_nb_target_tokens      -0.294076 -0.019842   \n",
       "0                          count_words      -0.289823 -0.017346   \n",
       "27                      nlgeval_METEOR       0.281753  0.148445   \n",
       "14                       sentence_fkgl      -0.279873 -0.244636   \n",
       "6         count_syllables_per_sentence      -0.274673 -0.178439   \n",
       "46                          TERp_NumEr      -0.273803 -0.144755   \n",
       "5        count_characters_per_sentence      -0.272428 -0.132553   \n",
       "4             count_words_per_sentence      -0.259926 -0.068805   \n",
       "64               QuEst_nb_source_punct      -0.254104 -0.198211   \n",
       "39                            TERp_Del      -0.252379 -0.228529   \n",
       "32                    nltkBLEU_method2       0.251620  0.108835   \n",
       "44                           TERp_Shft      -0.249593  0.066614   \n",
       "37                    nltkBLEU_method7       0.248560  0.106866   \n",
       "34                    nltkBLEU_method4       0.246016  0.098010   \n",
       "35                    nltkBLEU_method5       0.245278  0.106195   \n",
       "24                      nlgeval_Bleu_2       0.243770  0.147924   \n",
       "33                    nltkBLEU_method3       0.243082  0.097686   \n",
       "25                      nlgeval_Bleu_3       0.241503  0.124547   \n",
       "36                    nltkBLEU_method6       0.241473  0.100920   \n",
       "31                    nltkBLEU_method1       0.240262  0.097708   \n",
       "26                      nlgeval_Bleu_4       0.234982  0.097778   \n",
       "30                    nltkBLEU_method0       0.234981  0.097778   \n",
       "28                     nlgeval_ROUGE_L       0.230987  0.120953   \n",
       "48                           TERp_TERp      -0.230689 -0.119249   \n",
       "23                      nlgeval_Bleu_1       0.230603  0.171252   \n",
       "15            average_sentence_lm_prob       0.224107  0.300975   \n",
       "..                                 ...            ...       ...   \n",
       "18  characters_per_sentence_difference      -0.168902 -0.131820   \n",
       "20                      average_cosine       0.167519  0.097594   \n",
       "56           QuEst_nb_translations_idf      -0.153654 -0.056064   \n",
       "16                min_sentence_lm_prob       0.149811  0.099907   \n",
       "61            QuEst_nb_trigram_q1_freq       0.141561  0.081723   \n",
       "19                         average_dot       0.136549  0.026993   \n",
       "45                           TERp_WdSh      -0.136227  0.083946   \n",
       "57            QuEst_nb_unigram_q1_freq      -0.104801 -0.136007   \n",
       "59             QuEst_nb_bigram_q1_freq      -0.089535 -0.162964   \n",
       "63     QuEst_nb_source_words_in_corpus      -0.079001 -0.137022   \n",
       "58            QuEst_nb_unigram_q4_freq      -0.073683 -0.014605   \n",
       "12                average_concreteness      -0.060692  0.180340   \n",
       "7            count_characters_per_word      -0.055357 -0.193792   \n",
       "40                            TERp_Sub      -0.054518  0.177429   \n",
       "38                            TERp_Ins      -0.042451  0.164182   \n",
       "10           average_pos_in_freq_table      -0.036714 -0.143021   \n",
       "8             count_syllables_per_word      -0.034498 -0.231303   \n",
       "55               QuEst_nb_translations      -0.030304 -0.067589   \n",
       "51       QuEst_avg_source_token_length      -0.029199 -0.175513   \n",
       "11                    min_concreteness      -0.029136  0.000901   \n",
       "60             QuEst_nb_bigram_q4_freq      -0.022028  0.024482   \n",
       "2                      count_sentences      -0.019013  0.061744   \n",
       "62            QuEst_nb_trigram_q4_freq       0.015982 -0.056768   \n",
       "9                max_pos_in_freq_table       0.005038  0.043533   \n",
       "29                       nlgeval_CIDEr            NaN       NaN   \n",
       "41                           TERp_Stem            NaN       NaN   \n",
       "42                            TERp_Syn            NaN       NaN   \n",
       "43                         TERp_Phrase            NaN       NaN   \n",
       "52                QuEst_lm_prob_source            NaN       NaN   \n",
       "53                QuEst_lm_prob_target            NaN       NaN   \n",
       "\n",
       "    valid_conf_int_high  valid_conf_int_low       valid_p  valid_pearson_abs  \n",
       "49            -0.359953           -0.501858  1.457161e-24           0.433590  \n",
       "47            -0.358567           -0.500667  2.066743e-24           0.432297  \n",
       "1             -0.225491           -0.383698  1.842269e-12           0.306712  \n",
       "3             -0.225017           -0.383272  1.992580e-12           0.306259  \n",
       "50            -0.212268           -0.371791  1.564298e-11           0.294076  \n",
       "0             -0.207823           -0.367777  3.140102e-11           0.289823  \n",
       "27             0.360154            0.199401  1.140887e-10           0.281753  \n",
       "14            -0.197440           -0.358377  1.531859e-10           0.279873  \n",
       "6             -0.192020           -0.353457  3.421647e-10           0.274673  \n",
       "46            -0.191113           -0.352633  3.907637e-10           0.273803  \n",
       "5             -0.189682           -0.351332  4.815175e-10           0.272428  \n",
       "4             -0.176678           -0.339482  3.050702e-09           0.259926  \n",
       "64            -0.170632           -0.333955  6.977925e-09           0.254104  \n",
       "39            -0.168842           -0.332316  8.881269e-09           0.252379  \n",
       "32             0.331595            0.168055  9.870581e-09           0.251620  \n",
       "44            -0.165952           -0.329669  1.306365e-08           0.249593  \n",
       "37             0.328687            0.164881  1.505475e-08           0.248560  \n",
       "34             0.326267            0.162244  2.129551e-08           0.246016  \n",
       "35             0.325565            0.161479  2.353266e-08           0.245278  \n",
       "24             0.324130            0.159916  2.883226e-08           0.243770  \n",
       "33             0.323477            0.159204  3.161396e-08           0.243082  \n",
       "25             0.321973            0.157568  3.902809e-08           0.241503  \n",
       "36             0.321945            0.157537  3.918263e-08           0.241473  \n",
       "31             0.320792            0.156284  4.600114e-08           0.240262  \n",
       "26             0.315763            0.150820  9.168966e-08           0.234982  \n",
       "30             0.315762            0.150818  9.170677e-08           0.234981  \n",
       "28             0.311955            0.146689  1.528570e-07           0.230987  \n",
       "48            -0.146380           -0.311670  1.587551e-07           0.230689  \n",
       "23             0.311589            0.146292  1.604822e-07           0.230603  \n",
       "15             0.305390            0.139581  3.607954e-07           0.224107  \n",
       "..                  ...                 ...           ...                ...  \n",
       "18            -0.082868           -0.252436  1.369479e-04           0.168902  \n",
       "20             0.251103            0.081454  1.556070e-04           0.167519  \n",
       "56            -0.067301           -0.237722  5.302754e-04           0.153654  \n",
       "16             0.234008            0.063385  7.319343e-04           0.149811  \n",
       "61             0.226024            0.054985  1.425760e-03           0.141561  \n",
       "19             0.221169            0.049889  2.102357e-03           0.136549  \n",
       "45            -0.049561           -0.220857  2.154638e-03           0.136227  \n",
       "57            -0.017708           -0.190315  1.848505e-02           0.104801  \n",
       "59            -0.002298           -0.175419  4.431533e-02           0.089535  \n",
       "63             0.008312           -0.165117  7.611415e-02           0.079001  \n",
       "58             0.013660           -0.159910  9.813422e-02           0.073683  \n",
       "12             0.026705           -0.147167  1.732773e-01           0.060692  \n",
       "7              0.032053           -0.141926  2.142906e-01           0.055357  \n",
       "40             0.032894           -0.141102  2.213260e-01           0.054518  \n",
       "38             0.044971           -0.129227  3.410809e-01           0.042451  \n",
       "10             0.050704           -0.123573  4.103539e-01           0.036714  \n",
       "8              0.052916           -0.121388  4.391924e-01           0.034498  \n",
       "55             0.057102           -0.117249  4.968490e-01           0.030304  \n",
       "51             0.058204           -0.116158  5.126724e-01           0.029199  \n",
       "11             0.058267           -0.116096  5.135889e-01           0.029136  \n",
       "60             0.065352           -0.109074  6.214060e-01           0.022028  \n",
       "2              0.068355           -0.106092  6.699310e-01           0.019013  \n",
       "62             0.103093           -0.071373  7.201337e-01           0.015982  \n",
       "9              0.092252           -0.082253  9.100832e-01           0.005038  \n",
       "29                  NaN                 NaN  1.000000e+00                NaN  \n",
       "41                  NaN                 NaN  1.000000e+00                NaN  \n",
       "42                  NaN                 NaN  1.000000e+00                NaN  \n",
       "43                  NaN                 NaN  1.000000e+00                NaN  \n",
       "52                  NaN                 NaN  1.000000e+00                NaN  \n",
       "53                  NaN                 NaN  1.000000e+00                NaN  \n",
       "\n",
       "[66 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('overall')\n",
    "single_feature_dfs['overall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, ensemble, linear_model, neighbors, svm, neural_network\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn import decomposition\n",
    "\n",
    "\n",
    "def get_sklearn_classifiers(probability=False):\n",
    "    return [\n",
    "        tree.DecisionTreeClassifier(max_depth=5),\n",
    "        ensemble.RandomForestClassifier(random_state=42),\n",
    "        ensemble.AdaBoostClassifier(random_state=42),\n",
    "        ensemble.GradientBoostingClassifier(random_state=42),\n",
    "        linear_model.LogisticRegression(),\n",
    "        neighbors.KNeighborsClassifier(3),\n",
    "        svm.SVC(kernel=\"linear\", C=0.025),\n",
    "        neural_network.MLPClassifier(alpha=1),\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_sklearn_regressors():\n",
    "    return [\n",
    "        linear_model.LinearRegression(),\n",
    "        linear_model.Lasso(),\n",
    "        ensemble.AdaBoostRegressor(),\n",
    "        ensemble.GradientBoostingRegressor(),\n",
    "        ensemble.RandomForestRegressor(),\n",
    "        linear_model.Ridge(),\n",
    "        svm.LinearSVR(),\n",
    "        ensemble.BaggingRegressor(),\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_regression_df_and_pipelines(aspects):\n",
    "    metric_name = 'pearson'\n",
    "    df = pd.DataFrame(columns=['team', f'valid_{metric_name}', f'{metric_name}'])\n",
    "    pipelines = []\n",
    "    for model in tqdm(get_sklearn_regressors()):\n",
    "        method_name = model.__class__.__name__\n",
    "        print(method_name)\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('feature_extraction', FunctionTransformer(feature_extractor)),\n",
    "            ('feature_scaling', StandardScaler()),\n",
    "            #('feature_skewing', FeatureSkewer()),\n",
    "            #('feature_selection', SelectFromModel(LinearRegression())),\n",
    "            ('dimensionality_reduction', decomposition.PCA(n_components=25)),\n",
    "            ('prediction', model),\n",
    "        ])\n",
    "        pipelines.append(pipeline)\n",
    "        df = df.append(evaluate_regression_pipeline_on_qats(aspect, pipeline, method_name), ignore_index=True)\n",
    "    df = df.sort_values(by=f'valid_{metric_name}', ascending=False)\n",
    "    return df, pipelines\n",
    "\n",
    "\n",
    "def get_classification_df_and_pipelines(aspect):\n",
    "    metric_name = 'weighted_f_score'\n",
    "    df = pd.DataFrame(columns=['team', f'valid_{metric_name}', f'{metric_name}'])\n",
    "    pipelines = []\n",
    "    for model in tqdm(get_sklearn_classifiers()):\n",
    "        method_name = model.__class__.__name__\n",
    "        print(method_name)\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('feature_extraction', FunctionTransformer(feature_extractor)),\n",
    "            ('feature_scaling', StandardScaler()),\n",
    "            #('feature_skewing', FeatureSkewer()),\n",
    "            #('feature_selection', SelectFromModel(LinearRegression())),\n",
    "            ('dimensionality_reduction', decomposition.PCA(n_components=25)),\n",
    "            ('prediction', model),\n",
    "        ])\n",
    "        pipelines.append(pipeline)\n",
    "        df = df.append(evaluate_classification_pipeline_on_qats(aspect, pipeline, method_name), ignore_index=True)\n",
    "    df = df.sort_values(by=f'valid_{metric_name}', ascending=False)\n",
    "    return df, pipelines\n",
    "\n",
    "\n",
    "def analyse_results(df, pipelines, metric_name):\n",
    "    argmax = int(df[f'valid_{metric_name}'].idxmax())\n",
    "    if 'feature_selection' in pipelines[argmax].named_steps:\n",
    "        print('Selected features: ', get_selected_features(pipelines[argmax], vectorizer_names))\n",
    "    if 'dimensionality_reduction' in pipelines[argmax].named_steps:\n",
    "        pca = pipelines[argmax].named_steps['dimensionality_reduction']\n",
    "        vectorizer_names[np.argsort(pca.components_[0])]\n",
    "        print('PCA explained variance: ', pca.explained_variance_ratio_)\n",
    "\n",
    "    data = [go.Scatter(x=df[f'valid_{metric_name}'].values, y=df[metric_name].values, mode='markers', marker={'size': 5})]\n",
    "    layout = go.Layout(title='test = f(validation)')\n",
    "    iplot(go.Figure(data=data, layout=layout))\n",
    "\n",
    "    print('Ranking')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_latex(df, caption=None, label=None):\n",
    "    df = df.copy()\n",
    "    latex_str = '\\n'.join([\n",
    "        r'\\begin{table*}',\n",
    "        df.to_latex(index=False, float_format='%.2f'),\n",
    "        r'\\caption{' + caption + '}' if caption is not None else '',\n",
    "        r'\\label{' + label + '}' if label is not None else '',\n",
    "        r'\\end{table*}',\n",
    "    ])\n",
    "    return latex_str\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1891fbc997644e4a83cf12375b83a1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ea16fa1a5d4817b36072753942d1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Lasso\n",
      "AdaBoostRegressor\n",
      "GradientBoostingRegressor\n",
      "RandomForestRegressor\n",
      "Ridge\n",
      "LinearSVR\n",
      "BaggingRegressor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d51b23644642059c6530f23b709fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Lasso\n",
      "AdaBoostRegressor\n",
      "GradientBoostingRegressor\n",
      "RandomForestRegressor\n",
      "Ridge\n",
      "LinearSVR\n",
      "BaggingRegressor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1794f41cc7449f9e3f800cbee19404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Lasso\n",
      "AdaBoostRegressor\n",
      "GradientBoostingRegressor\n",
      "RandomForestRegressor\n",
      "Ridge\n",
      "LinearSVR\n",
      "BaggingRegressor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f761df78334d9391ba3730fc9ff7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Lasso\n",
      "AdaBoostRegressor\n",
      "GradientBoostingRegressor\n",
      "RandomForestRegressor\n",
      "Ridge\n",
      "LinearSVR\n",
      "BaggingRegressor\n",
      "\n",
      "CPU times: user 1h 36min 44s, sys: 6min 44s, total: 1h 43min 29s\n",
      "Wall time: 12min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regression_results = {}\n",
    "for aspect in tqdm(['grammaticality', 'meaning_preservation', 'simplicity', 'overall']):\n",
    "    regression_results[aspect] = get_regression_df_and_pipelines(aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA explained variance:  [0.37227626 0.15087662 0.09159073 0.04679639 0.041848   0.0314406\n",
      " 0.02637758 0.02401313 0.02124521 0.02087028 0.0185782  0.01700259\n",
      " 0.01555948 0.0135297  0.01252479 0.01095355 0.01033294 0.00980717\n",
      " 0.00788858 0.00741996 0.00664606 0.00536601 0.00491738 0.00439922\n",
      " 0.00373379]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "size": 5
         },
         "mode": "markers",
         "type": "scatter",
         "uid": "662b157e-e1dc-11e8-8fa1-8f14a3942b01",
         "x": [
          0.23478030776376344,
          0.22151214553419538,
          0.22079326893462792,
          0.22064527757841484,
          0.1965637702562419,
          0.15907400089524176,
          0.15331527100473827,
          0.06362440247809607
         ],
         "y": [
          0.13617830736823022,
          0.32718541723197736,
          0.33879177283655854,
          0.33869094819749024,
          0.32146841145901517,
          0.3034851515514747,
          0.21198023722626502,
          0.06463077956201414
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "title": "test = f(validation)",
        "xaxis": {
         "autorange": true,
         "range": [
          0.05078170832271991,
          0.2476230019191396
         ],
         "type": "linear"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          0.045378714036399356,
          0.35804383836217335
         ],
         "type": "linear"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>valid_pearson</th>\n",
       "      <th>pearson</th>\n",
       "      <th>valid_conf_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.234780</td>\n",
       "      <td>0.136178</td>\n",
       "      <td>0.143852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.221512</td>\n",
       "      <td>0.327185</td>\n",
       "      <td>0.136472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.220793</td>\n",
       "      <td>0.338792</td>\n",
       "      <td>0.123523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.220645</td>\n",
       "      <td>0.338691</td>\n",
       "      <td>0.123364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>0.196564</td>\n",
       "      <td>0.321468</td>\n",
       "      <td>0.114759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.159074</td>\n",
       "      <td>0.303485</td>\n",
       "      <td>0.159531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.153315</td>\n",
       "      <td>0.211980</td>\n",
       "      <td>0.147935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVR</td>\n",
       "      <td>0.063624</td>\n",
       "      <td>0.064631</td>\n",
       "      <td>0.164817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        team  valid_pearson   pearson  valid_conf_int\n",
       "3  GradientBoostingRegressor  0.234780       0.136178  0.143852      \n",
       "1  Lasso                      0.221512       0.327185  0.136472      \n",
       "5  Ridge                      0.220793       0.338792  0.123523      \n",
       "0  LinearRegression           0.220645       0.338691  0.123364      \n",
       "7  BaggingRegressor           0.196564       0.321468  0.114759      \n",
       "2  AdaBoostRegressor          0.159074       0.303485  0.159531      \n",
       "4  RandomForestRegressor      0.153315       0.211980  0.147935      \n",
       "6  LinearSVR                  0.063624       0.064631  0.164817      "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect = 'grammaticality'\n",
    "analyse_results(*regression_results[aspect], 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grammaticality</th>\n",
       "      <th>meaning_preservation</th>\n",
       "      <th>simplicity</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482   OSVCML1</td>\n",
       "      <td>0.588   IIT-Meteor</td>\n",
       "      <td>0.487   **Ridge**</td>\n",
       "      <td>0.423   **Ridge**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.384   METEOR</td>\n",
       "      <td>0.585   OSVCML</td>\n",
       "      <td>0.457   **LinearSVR**</td>\n",
       "      <td>0.423   **LinearRegression**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344   BLEU</td>\n",
       "      <td>0.575   **Ridge**</td>\n",
       "      <td>0.382   OSVCML1</td>\n",
       "      <td>0.343   OSVCML2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.340   OSVCML</td>\n",
       "      <td>0.573   OSVCML2</td>\n",
       "      <td>0.376   OSVCML2</td>\n",
       "      <td>0.334   OSVCML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.327   **Lasso**</td>\n",
       "      <td>0.555   **Lasso**</td>\n",
       "      <td>0.339   OSVCML</td>\n",
       "      <td>0.232   SimpleNets-RNN2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.323   TER</td>\n",
       "      <td>0.533   BLEU</td>\n",
       "      <td>0.320   SimpleNets-MLP</td>\n",
       "      <td>0.230   OSVCML1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.308   SimpleNets-MLP</td>\n",
       "      <td>0.527   METEOR</td>\n",
       "      <td>0.307   SimpleNets-RNN3</td>\n",
       "      <td>0.205   UoLGP-emb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.308   WER</td>\n",
       "      <td>0.513   TER</td>\n",
       "      <td>0.240   SimpleNets-RNN2</td>\n",
       "      <td>0.198   SimpleNets-MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.256   UoLGP-emb</td>\n",
       "      <td>0.495   WER</td>\n",
       "      <td>0.123   UoLGP-combo</td>\n",
       "      <td>0.196   METEOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.256   UoLGP-combo</td>\n",
       "      <td>0.482   OSVCML1</td>\n",
       "      <td>0.120   UoLGP-emb</td>\n",
       "      <td>0.189   UoLGP-combo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.208   UoLGP-quest</td>\n",
       "      <td>0.465   SimpleNets-MLP</td>\n",
       "      <td>0.086   UoLGP-quest</td>\n",
       "      <td>0.144   UoLGP-quest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.136   **GradientBoostingRegressor**</td>\n",
       "      <td>0.285   UoLGP-quest</td>\n",
       "      <td>0.052   IIT-S</td>\n",
       "      <td>0.130   TER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.064   SimpleNets-RNN3</td>\n",
       "      <td>0.262   SimpleNets-RNN2</td>\n",
       "      <td>-0.169   METEOR</td>\n",
       "      <td>0.112   SimpleNets-RNN3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.056   SimpleNets-RNN2</td>\n",
       "      <td>0.262   SimpleNets-RNN3</td>\n",
       "      <td>-0.242   TER</td>\n",
       "      <td>0.111   WER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250   UoLGP-combo</td>\n",
       "      <td>-0.260   WER</td>\n",
       "      <td>0.107   BLEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.188   UoLGP-emb</td>\n",
       "      <td>-0.267   BLEU</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           grammaticality     meaning_preservation  \\\n",
       "0   0.482   OSVCML1                        0.588   IIT-Meteor        \n",
       "1   0.384   METEOR                         0.585   OSVCML            \n",
       "2   0.344   BLEU                           0.575   **Ridge**         \n",
       "3   0.340   OSVCML                         0.573   OSVCML2           \n",
       "4   0.327   **Lasso**                      0.555   **Lasso**         \n",
       "5   0.323   TER                            0.533   BLEU              \n",
       "6   0.308   SimpleNets-MLP                 0.527   METEOR            \n",
       "7   0.308   WER                            0.513   TER               \n",
       "8   0.256   UoLGP-emb                      0.495   WER               \n",
       "9   0.256   UoLGP-combo                    0.482   OSVCML1           \n",
       "10  0.208   UoLGP-quest                    0.465   SimpleNets-MLP    \n",
       "11  0.136   **GradientBoostingRegressor**  0.285   UoLGP-quest       \n",
       "12  0.064   SimpleNets-RNN3                0.262   SimpleNets-RNN2   \n",
       "13  0.056   SimpleNets-RNN2                0.262   SimpleNets-RNN3   \n",
       "14  NaN                                    0.250   UoLGP-combo       \n",
       "15  NaN                                    0.188   UoLGP-emb         \n",
       "\n",
       "                 simplicity                       overall  \n",
       "0   0.487   **Ridge**        0.423   **Ridge**             \n",
       "1   0.457   **LinearSVR**    0.423   **LinearRegression**  \n",
       "2   0.382   OSVCML1          0.343   OSVCML2               \n",
       "3   0.376   OSVCML2          0.334   OSVCML                \n",
       "4   0.339   OSVCML           0.232   SimpleNets-RNN2       \n",
       "5   0.320   SimpleNets-MLP   0.230   OSVCML1               \n",
       "6   0.307   SimpleNets-RNN3  0.205   UoLGP-emb             \n",
       "7   0.240   SimpleNets-RNN2  0.198   SimpleNets-MLP        \n",
       "8   0.123   UoLGP-combo      0.196   METEOR                \n",
       "9   0.120   UoLGP-emb        0.189   UoLGP-combo           \n",
       "10  0.086   UoLGP-quest      0.144   UoLGP-quest           \n",
       "11  0.052   IIT-S            0.130   TER                   \n",
       "12  -0.169   METEOR          0.112   SimpleNets-RNN3       \n",
       "13  -0.242   TER             0.111   WER                   \n",
       "14  -0.260   WER             0.107   BLEU                  \n",
       "15  -0.267   BLEU            NaN                           "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our methods in the QATS leaderboard\n",
    "metric = 'pearson'\n",
    "result_dfs = {aspect: df for aspect, (df, _) in regression_results.items()}\n",
    "dfs = []\n",
    "for aspect in ['grammaticality', 'meaning_preservation', 'simplicity', 'overall']:\n",
    "    df_leaderboard = get_qats_results(aspect=aspect)[['team', metric]].dropna()\n",
    "    df_ours = result_dfs[aspect][['team', metric]].head(2)  # Take our two best methods\n",
    "    df_ours['team'] = df_ours['team'].apply(lambda team: f'**{team}**')  # Make our methods stand out\n",
    "    df_leaderboard = df_leaderboard.append(df_ours, ignore_index=True)\n",
    "    df_leaderboard = df_leaderboard.sort_values(by=metric, ascending=False).reset_index()\n",
    "    df_leaderboard[aspect] = df_leaderboard[metric].map(lambda x: f'{x:.3f}   ') + df_leaderboard['team']\n",
    "    dfs.append(df_leaderboard[aspect])\n",
    "df_leaderboard = pd.concat(dfs, axis=1)\n",
    "df_leaderboard\n",
    "#print(to_latex(df_leaderboard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval of the Lasso model on the test set\n",
      "Score ~ 0.33 +- 0.17\n",
      "Confidence interval: 0.16 < 0.33 < 0.47\n"
     ]
    }
   ],
   "source": [
    "df, pipelines = regression_results['grammaticality']\n",
    "[lasso_pipeline] = [pipeline for pipeline in pipelines if pipeline.named_steps['prediction'].__class__.__name__ == 'Lasso']\n",
    "test_sentences, test_labels = get_qats_test_data('grammaticality')\n",
    "pred_labels = lasso_pipeline.predict(test_sentences)\n",
    "score, p_value, conf_int_low, conf_int_high = pearsonr_with_confidence_interval(test_labels, pred_labels)\n",
    "uncertainty = np.max([score - conf_int_low, conf_int_high - score])\n",
    "print('Confidence interval of the Lasso model on the test set')\n",
    "print(f'Score ~ {score:.2f} +- {uncertainty:.2f}')\n",
    "print(f'Confidence interval: {conf_int_low:.2f} < {score:.2f} < {conf_int_high:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c5190e1457411795145ab78df55269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae2768ab5694db0ad2ce2adcd2d2d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n",
      "GradientBoostingClassifier\n",
      "LogisticRegression\n",
      "KNeighborsClassifier\n",
      "SVC\n",
      "MLPClassifier\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d47b88925c4087b6c9a7ec8fd53ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n",
      "GradientBoostingClassifier\n",
      "LogisticRegression\n",
      "KNeighborsClassifier\n",
      "SVC\n",
      "MLPClassifier\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bc2921b81b48d795202d74de7f50fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n",
      "GradientBoostingClassifier\n",
      "LogisticRegression\n",
      "KNeighborsClassifier\n",
      "SVC\n",
      "MLPClassifier\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213557f5dbf94643838866428fe043c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n",
      "GradientBoostingClassifier\n",
      "LogisticRegression\n",
      "KNeighborsClassifier\n",
      "SVC\n",
      "MLPClassifier\n",
      "\n",
      "CPU times: user 1h 54min 7s, sys: 7min 45s, total: 2h 1min 52s\n",
      "Wall time: 13min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classification_results = {}\n",
    "for aspect in tqdm(['grammaticality', 'meaning_preservation', 'simplicity', 'overall']):\n",
    "    classification_results[aspect] = get_classification_df_and_pipelines(aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA explained variance:  [0.37227626 0.15087662 0.09159073 0.04679639 0.041848   0.0314406\n",
      " 0.02637758 0.02401313 0.02124521 0.02087028 0.0185782  0.01700259\n",
      " 0.01555948 0.0135297  0.01252479 0.01095355 0.01033294 0.00980717\n",
      " 0.00788858 0.00741996 0.00664606 0.00536601 0.00491738 0.00439922\n",
      " 0.00373379]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "size": 5
         },
         "mode": "markers",
         "type": "scatter",
         "uid": "50cb57be-e1de-11e8-8fa1-8f14a3942b01",
         "x": [
          0.6721377537591133,
          0.6706496549732229,
          0.6497489155932156,
          0.6466403167193878,
          0.6426125121992493,
          0.6365097331450004,
          0.6275384508618991,
          0.6205026008750287
         ],
         "y": [
          0.7043454790823213,
          0.6759796449237443,
          0.7164221778343289,
          0.6845330380214102,
          0.6589446589446589,
          0.6421726421726421,
          0.6911411521130191,
          0.6276910820162794
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "title": "test = f(validation)",
        "xaxis": {
         "autorange": true,
         "range": [
          0.6166281539194908,
          0.6760122007146513
         ],
         "type": "linear"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          0.6214602289308515,
          0.7226530309197569
         ],
         "type": "linear"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>valid_weighted_f_score</th>\n",
       "      <th>weighted_f_score</th>\n",
       "      <th>valid_conf_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.672138</td>\n",
       "      <td>0.704345</td>\n",
       "      <td>0.044422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.670650</td>\n",
       "      <td>0.675980</td>\n",
       "      <td>0.031226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.649749</td>\n",
       "      <td>0.716422</td>\n",
       "      <td>0.054547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.646640</td>\n",
       "      <td>0.684533</td>\n",
       "      <td>0.041006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.642613</td>\n",
       "      <td>0.658945</td>\n",
       "      <td>0.019637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.636510</td>\n",
       "      <td>0.642173</td>\n",
       "      <td>0.056255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.627538</td>\n",
       "      <td>0.691141</td>\n",
       "      <td>0.075061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.620503</td>\n",
       "      <td>0.627691</td>\n",
       "      <td>0.047610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         team  valid_weighted_f_score  weighted_f_score  \\\n",
       "4  LogisticRegression          0.672138                0.704345           \n",
       "3  GradientBoostingClassifier  0.670650                0.675980           \n",
       "7  MLPClassifier               0.649749                0.716422           \n",
       "1  RandomForestClassifier      0.646640                0.684533           \n",
       "6  SVC                         0.642613                0.658945           \n",
       "0  DecisionTreeClassifier      0.636510                0.642173           \n",
       "5  KNeighborsClassifier        0.627538                0.691141           \n",
       "2  AdaBoostClassifier          0.620503                0.627691           \n",
       "\n",
       "   valid_conf_int  \n",
       "4  0.044422        \n",
       "3  0.031226        \n",
       "7  0.054547        \n",
       "1  0.041006        \n",
       "6  0.019637        \n",
       "0  0.056255        \n",
       "5  0.075061        \n",
       "2  0.047610        "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect = 'grammaticality'\n",
    "analyse_results(*classification_results[aspect], 'weighted_f_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grammaticality</th>\n",
       "      <th>meaning_preservation</th>\n",
       "      <th>simplicity</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.84   SMH-RandForest</td>\n",
       "      <td>70.14   **SVC**</td>\n",
       "      <td>61.60   **SVC**</td>\n",
       "      <td>49.61   **LogisticRegression**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.64   SMH-IBk</td>\n",
       "      <td>68.07   SMH-Logistic</td>\n",
       "      <td>56.95   **AdaBoostClassifier**</td>\n",
       "      <td>48.57   SMH-RandForest-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.43   **LogisticRegression**</td>\n",
       "      <td>65.60   MS-RandForest</td>\n",
       "      <td>56.42   SMH-RandForest-b</td>\n",
       "      <td>48.20   UoW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.96   SMH-RandForest-b</td>\n",
       "      <td>64.40   SMH-RandForest</td>\n",
       "      <td>53.02   SMH-RandForest</td>\n",
       "      <td>47.54   SMH-Logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.09   BLEU</td>\n",
       "      <td>63.74   TER</td>\n",
       "      <td>51.12   SMH-IBk</td>\n",
       "      <td>46.06   SimpleNets-RNN2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68.82   SimpleNets-MLP</td>\n",
       "      <td>63.54   SimpleNets-MLP</td>\n",
       "      <td>49.96   SimpleNets-RNN3</td>\n",
       "      <td>45.71   **AdaBoostClassifier**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68.36   TER</td>\n",
       "      <td>62.82   BLEU</td>\n",
       "      <td>49.81   SimpleNets-MLP</td>\n",
       "      <td>44.50   SMH-RandForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67.60   **GradientBoostingClassifier**</td>\n",
       "      <td>62.72   MT-baseline</td>\n",
       "      <td>48.31   MT-baseline</td>\n",
       "      <td>40.94   METEOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67.53   MS-RandForest</td>\n",
       "      <td>62.69   IIT-Meteor</td>\n",
       "      <td>47.84   MS-IBk-b</td>\n",
       "      <td>40.75   SimpleNets-RNN3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67.50   IIT-LM</td>\n",
       "      <td>61.71   MS-IBk-b</td>\n",
       "      <td>47.82   MS-RandForest</td>\n",
       "      <td>39.85   MS-RandForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>66.79   WER</td>\n",
       "      <td>61.50   MS-IBk</td>\n",
       "      <td>47.47   SimpleNets-RNN2</td>\n",
       "      <td>39.80   DeepIndiBow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>66.75   MS-RandForest-b</td>\n",
       "      <td>60.12   METEOR</td>\n",
       "      <td>43.46   IIT-S</td>\n",
       "      <td>39.30   IIT-Metrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65.89   DeepIndiBow</td>\n",
       "      <td>59.95   **GradientBoostingClassifier**</td>\n",
       "      <td>42.57   DeepIndiBow</td>\n",
       "      <td>38.27   MS-IBk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>65.89   DeepBow</td>\n",
       "      <td>59.69   SMH-RandForest-b</td>\n",
       "      <td>40.92   UoW</td>\n",
       "      <td>38.16   MS-IBk-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>65.89   MT-baseline</td>\n",
       "      <td>59.06   WER</td>\n",
       "      <td>39.68   Majority-class</td>\n",
       "      <td>38.03   DeepBow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>65.89   Majority-class</td>\n",
       "      <td>58.83   UoW</td>\n",
       "      <td>38.10   MS-IBk</td>\n",
       "      <td>37.49   MT-baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65.72   METEOR</td>\n",
       "      <td>51.29   SimpleNets-RNN2</td>\n",
       "      <td>35.58   DeepBow</td>\n",
       "      <td>34.08   TER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>65.50   SimpleNets-RNN2</td>\n",
       "      <td>51.00   CLaC-RF</td>\n",
       "      <td>34.88   CLaC-RF-0.5</td>\n",
       "      <td>34.06   CLaC-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>65.11   SimpleNets-RNN3</td>\n",
       "      <td>46.64   SimpleNets-RNN3</td>\n",
       "      <td>34.66   CLaC-RF-0.6</td>\n",
       "      <td>33.69   SimpleNets-MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64.39   CLaC-RF-Perp</td>\n",
       "      <td>46.30   DeepBow</td>\n",
       "      <td>34.48   WER</td>\n",
       "      <td>33.04   IIT-Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>62.00   MS-IBk</td>\n",
       "      <td>42.53   DeepIndiBow</td>\n",
       "      <td>34.30   CLaC-RF-0.7</td>\n",
       "      <td>32.92   BLEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>46.32   UoW</td>\n",
       "      <td>42.51   Majority-class</td>\n",
       "      <td>33.52   TER</td>\n",
       "      <td>32.88   CLaC-0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.34   METEOR</td>\n",
       "      <td>32.20   CLaC-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00   BLEU</td>\n",
       "      <td>31.28   WER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.53   Majority-class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            grammaticality  \\\n",
       "0   71.84   SMH-RandForest                   \n",
       "1   71.64   SMH-IBk                          \n",
       "2   70.43   **LogisticRegression**           \n",
       "3   69.96   SMH-RandForest-b                 \n",
       "4   69.09   BLEU                             \n",
       "5   68.82   SimpleNets-MLP                   \n",
       "6   68.36   TER                              \n",
       "7   67.60   **GradientBoostingClassifier**   \n",
       "8   67.53   MS-RandForest                    \n",
       "9   67.50   IIT-LM                           \n",
       "10  66.79   WER                              \n",
       "11  66.75   MS-RandForest-b                  \n",
       "12  65.89   DeepIndiBow                      \n",
       "13  65.89   DeepBow                          \n",
       "14  65.89   MT-baseline                      \n",
       "15  65.89   Majority-class                   \n",
       "16  65.72   METEOR                           \n",
       "17  65.50   SimpleNets-RNN2                  \n",
       "18  65.11   SimpleNets-RNN3                  \n",
       "19  64.39   CLaC-RF-Perp                     \n",
       "20  62.00   MS-IBk                           \n",
       "21  46.32   UoW                              \n",
       "22  NaN                                      \n",
       "23  NaN                                      \n",
       "24  NaN                                      \n",
       "\n",
       "                      meaning_preservation                      simplicity  \\\n",
       "0   70.14   **SVC**                         61.60   **SVC**                  \n",
       "1   68.07   SMH-Logistic                    56.95   **AdaBoostClassifier**   \n",
       "2   65.60   MS-RandForest                   56.42   SMH-RandForest-b         \n",
       "3   64.40   SMH-RandForest                  53.02   SMH-RandForest           \n",
       "4   63.74   TER                             51.12   SMH-IBk                  \n",
       "5   63.54   SimpleNets-MLP                  49.96   SimpleNets-RNN3          \n",
       "6   62.82   BLEU                            49.81   SimpleNets-MLP           \n",
       "7   62.72   MT-baseline                     48.31   MT-baseline              \n",
       "8   62.69   IIT-Meteor                      47.84   MS-IBk-b                 \n",
       "9   61.71   MS-IBk-b                        47.82   MS-RandForest            \n",
       "10  61.50   MS-IBk                          47.47   SimpleNets-RNN2          \n",
       "11  60.12   METEOR                          43.46   IIT-S                    \n",
       "12  59.95   **GradientBoostingClassifier**  42.57   DeepIndiBow              \n",
       "13  59.69   SMH-RandForest-b                40.92   UoW                      \n",
       "14  59.06   WER                             39.68   Majority-class           \n",
       "15  58.83   UoW                             38.10   MS-IBk                   \n",
       "16  51.29   SimpleNets-RNN2                 35.58   DeepBow                  \n",
       "17  51.00   CLaC-RF                         34.88   CLaC-RF-0.5              \n",
       "18  46.64   SimpleNets-RNN3                 34.66   CLaC-RF-0.6              \n",
       "19  46.30   DeepBow                         34.48   WER                      \n",
       "20  42.53   DeepIndiBow                     34.30   CLaC-RF-0.7              \n",
       "21  42.51   Majority-class                  33.52   TER                      \n",
       "22  NaN                                     33.34   METEOR                   \n",
       "23  NaN                                     33.00   BLEU                     \n",
       "24  NaN                                     NaN                              \n",
       "\n",
       "                           overall  \n",
       "0   49.61   **LogisticRegression**  \n",
       "1   48.57   SMH-RandForest-b        \n",
       "2   48.20   UoW                     \n",
       "3   47.54   SMH-Logistic            \n",
       "4   46.06   SimpleNets-RNN2         \n",
       "5   45.71   **AdaBoostClassifier**  \n",
       "6   44.50   SMH-RandForest          \n",
       "7   40.94   METEOR                  \n",
       "8   40.75   SimpleNets-RNN3         \n",
       "9   39.85   MS-RandForest           \n",
       "10  39.80   DeepIndiBow             \n",
       "11  39.30   IIT-Metrics             \n",
       "12  38.27   MS-IBk                  \n",
       "13  38.16   MS-IBk-b                \n",
       "14  38.03   DeepBow                 \n",
       "15  37.49   MT-baseline             \n",
       "16  34.08   TER                     \n",
       "17  34.06   CLaC-0.5                \n",
       "18  33.69   SimpleNets-MLP          \n",
       "19  33.04   IIT-Default             \n",
       "20  32.92   BLEU                    \n",
       "21  32.88   CLaC-0.7                \n",
       "22  32.20   CLaC-0.6                \n",
       "23  31.28   WER                     \n",
       "24  26.53   Majority-class          "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our methods in the QATS leaderboard\n",
    "metric = 'weighted_f_score'\n",
    "result_dfs = {aspect: df for aspect, (df, _) in classification_results.items()}\n",
    "dfs = []\n",
    "for aspect in ['grammaticality', 'meaning_preservation', 'simplicity', 'overall']:\n",
    "    df_leaderboard = get_qats_results(aspect=aspect)[['team', metric]].dropna()\n",
    "    df_ours = result_dfs[aspect][['team', metric]].head(2)  # Take our two best methods\n",
    "    df_ours[metric] = df_ours[metric] * 100\n",
    "    df_ours['team'] = df_ours['team'].apply(lambda team: f'**{team}**')  # Make our methods stand out\n",
    "    df_leaderboard = df_leaderboard.append(df_ours, ignore_index=True)\n",
    "    df_leaderboard = df_leaderboard.sort_values(by=metric, ascending=False).reset_index()\n",
    "    df_leaderboard[aspect] = df_leaderboard[metric].map(lambda x: f'{x:.2f}   ') + df_leaderboard['team']\n",
    "    dfs.append(df_leaderboard[aspect])\n",
    "df_leaderboard = pd.concat(dfs, axis=1)\n",
    "df_leaderboard\n",
    "#print(to_latex(df_leaderboard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latex tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Features description\n",
      "\\begin{table*}\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "               Short name &                                                         Description \\\\\n",
      "\\midrule\n",
      " NBSourcePunct &  Number of punctuation tokens in source (QuEst) \\\\\n",
      " NBSourceWords &  Number of source words (QuEst) \\\\\n",
      " NBOutputPunt &  Number of punctuation tokens in output (QuEst) \\\\\n",
      " TypeTokenRatio &  Type token ratio (QuEst) \\\\\n",
      " TERp\\_Del &  Number of deletions (TERp component) \\\\\n",
      " TERp\\_NumEr &  Number of total errors (TERp component) \\\\\n",
      " TERp\\_Sub &  Number of substitutions (TERp component) \\\\\n",
      " TERp &  TERp MT metric \\\\\n",
      " AvgConcreteness &  Average word concreteness (Brysbaert list) \\\\\n",
      " AvgCosineSim &  Cosine similarity between source and output word embeddings \\\\\n",
      " NBOutputChars &  Number of characters in the output sentence \\\\\n",
      " NBOutputCharsPerWord &  Average number of characters per word in the output \\\\\n",
      " NBOutputSyllables &  Number of syllables in the output \\\\\n",
      " NBOutputSyllablesPerWord &  Average number of syllables per word in the output \\\\\n",
      " NBOutputWords &  Number of words in the output \\\\\n",
      " NBOutputCharsPerSent &  Average number of characters per sentence in the output \\\\\n",
      " NBOutputWordsPerSent &  Average number of words per sentence in the output \\\\\n",
      " NBOutputSyllablesPerSent &  Average number of syllables per sentence in the output \\\\\n",
      " AvgLMProbsOutput &  Average probabilities of output words (Language Model) \\\\\n",
      " MinLMProbsOutput &  Min probability of output words (Language Model) \\\\\n",
      " MaxPosInFreqTable &  Maximum position of output words in the frequency table \\\\\n",
      " MinConcreteness &  Minimum word concreteness according to Brysbaert concreteness list \\\\\n",
      " BLEU\\_1gram &  BLEU MT metric with unigrams only \\\\\n",
      " BLEU\\_2gram &  BLEU MT metric up to bigrams \\\\\n",
      " BLEU\\_3gram &  BLEU MT metric up to trigrams \\\\\n",
      " BLEU\\_4gram &  BLEU MT metric up to 4-grams \\\\\n",
      " METEOR &  METEOR MT metric \\\\\n",
      " ROUGE &  ROUGE summarization metric \\\\\n",
      " BLEUSmoothed &  BLEU MT metric with smoothing (method 7 from nltk) \\\\\n",
      " outputFKGL &  Flesch-Kincaid Grade Level \\\\\n",
      " outputFRE &  Flesch Reading Ease \\\\\n",
      " WordsInCommon &  Percentage of words in common between source and output \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "# Method name, Short name, Description\n",
    "method_short_desc = '''\n",
    "Method name, Short name, Description\n",
    "QuEst_nb_source_punct, NBSourcePunct, Number of punctuation tokens in source (QuEst)\n",
    "QuEst_nb_source_tokens, NBSourceWords, Number of source words (QuEst)\n",
    "QuEst_nb_target_punct, NBOutputPunt, Number of punctuation tokens in output (QuEst)\n",
    "QuEst_type_token_ratio, TypeTokenRatio, Type token ratio (QuEst)\n",
    "TERp_Del, TERp_Del, Number of deletions (TERp component)\n",
    "TERp_NumEr, TERp_NumEr, Number of total errors (TERp component)\n",
    "TERp_Sub, TERp_Sub, Number of substitutions (TERp component)\n",
    "TERp_TERp, TERp, TERp MT metric\n",
    "average_concreteness, AvgConcreteness, Average word concreteness (Brysbaert list)\n",
    "average_cosine, AvgCosineSim, Cosine similarity between source and output word embeddings\n",
    "count_characters, NBOutputChars, Number of characters in the output sentence\n",
    "count_characters_per_word, NBOutputCharsPerWord, Average number of characters per word in the output\n",
    "count_syllables_in_sentence, NBOutputSyllables, Number of syllables in the output\n",
    "count_syllables_per_word, NBOutputSyllablesPerWord, Average number of syllables per word in the output\n",
    "count_words, NBOutputWords, Number of words in the output\n",
    "count_characters_per_sentence, NBOutputCharsPerSent, Average number of characters per sentence in the output\n",
    "count_words_per_sentence, NBOutputWordsPerSent, Average number of words per sentence in the output\n",
    "count_syllables_per_sentence, NBOutputSyllablesPerSent, Average number of syllables per sentence in the output\n",
    "average_sentence_lm_prob, AvgLMProbsOutput, Average probabilities of output words (Language Model)\n",
    "min_sentence_lm_prob, MinLMProbsOutput, Min probability of output words (Language Model)\n",
    "max_pos_in_freq_table, MaxPosInFreqTable, Maximum position of output words in the frequency table\n",
    "min_concreteness, MinConcreteness, Minimum word concreteness according to Brysbaert concreteness list\n",
    "nlgeval_Bleu_1, BLEU_1gram, BLEU MT metric with unigrams only\n",
    "nlgeval_Bleu_2, BLEU_2gram, BLEU MT metric up to bigrams\n",
    "nlgeval_Bleu_3, BLEU_3gram, BLEU MT metric up to trigrams\n",
    "nlgeval_Bleu_4, BLEU_4gram, BLEU MT metric up to 4-grams\n",
    "nlgeval_METEOR, METEOR, METEOR MT metric\n",
    "nlgeval_ROUGE_L, ROUGE, ROUGE summarization metric\n",
    "nltkBLEU_method7, BLEUSmoothed, BLEU MT metric with smoothing (method 7 from nltk)\n",
    "sentence_fkgl, outputFKGL, Flesch-Kincaid Grade Level\n",
    "sentence_fre, outputFRE, Flesch Reading Ease\n",
    "word_intersection, WordsInCommon, Percentage of words in common between source and output\n",
    "'''.replace(', ', ',')\n",
    "df_desc = pd.read_csv(StringIO(method_short_desc))\n",
    "print('% Features description')\n",
    "print(to_latex(df_desc[['Short name', 'Description']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}\n",
      "\\begin{tabular}{lrrlrrlrr}\n",
      "\\toprule\n",
      "   grammaticality & \\multicolumn{3}{l}{meaning\\textbackslash \\_preservation} & \\multicolumn{3}{l}{simplicity} \\\\\n",
      "       Short name & Valid &  Test &            Short name & Valid &  Test &                Short name & Valid &  Test \\\\\n",
      "\\midrule\n",
      " METEOR & 0.36 & 0.39 &  BLEUSmoothed & 0.59 & 0.52 &  NBOutputCharsPerSent & -0.52 & -0.45 \\\\\n",
      " BLEUSmoothed & 0.33 & 0.34 &  BLEU\\_3gram & 0.57 & 0.52 &  NBOutputSyllablesPerSent & -0.52 & -0.49 \\\\\n",
      " BLEU\\_4gram & 0.32 & 0.34 &  METEOR & 0.57 & 0.58 &  NBOutputWordsPerSent & -0.51 & -0.39 \\\\\n",
      " BLEU\\_3gram & 0.31 & 0.34 &  BLEU\\_2gram & 0.57 & 0.52 &  NBOutputChars & -0.48 & -0.37 \\\\\n",
      " TERp\\_NumEr & -0.30 & -0.31 &  BLEU\\_4gram & 0.57 & 0.51 &  NBOutputWords & -0.47 & -0.29 \\\\\n",
      " BLEU\\_2gram & 0.30 & 0.34 &  WordsInCommon & 0.55 & 0.50 &  NBOutputSyllables & -0.46 & -0.42 \\\\\n",
      " TERp & -0.30 & -0.32 &  BLEU\\_1gram & 0.55 & 0.52 &  NBOutputPunt & -0.42 & -0.31 \\\\\n",
      " ROUGE & 0.29 & 0.29 &  ROUGE & 0.55 & 0.47 &  NBSourceWords & -0.38 & -0.21 \\\\\n",
      " AvgLMProbsOutput & 0.28 & 0.34 &  TERp & -0.54 & -0.48 &  outputFKGL & -0.36 & -0.37 \\\\\n",
      " BLEU\\_1gram & 0.27 & 0.33 &  TERp\\_NumEr & -0.53 & -0.49 &  NBSourcePunct & -0.34 & -0.18 \\\\\n",
      " WordsInCommon & 0.27 & 0.30 &  TERp\\_Del & -0.50 & -0.52 &  TypeTokenRatio & -0.22 & -0.03 \\\\\n",
      " TERp\\_Del & -0.27 & -0.35 &  AvgCosineSim & 0.44 & 0.34 &  AvgConcreteness & 0.21 & 0.32 \\\\\n",
      " NBSourceWords & -0.25 & -0.07 &  AvgLMProbsOutput & 0.39 & 0.36 &  MinLMProbsOutput & 0.17 & 0.15 \\\\\n",
      " AvgCosineSim & 0.23 & 0.25 &  AvgConcreteness & -0.28 & -0.06 &  outputFRE & 0.16 & 0.27 \\\\\n",
      " MinLMProbsOutput & 0.11 & -0.07 &  NBSourceWords & -0.28 & -0.13 &  WordsInCommon & -0.15 & -0.22 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "def get_short_name(method_name):\n",
    "    method_name_to_short_name = {method_name: short_name \n",
    "                                 for method_name, short_name\n",
    "                                 in df_desc[['Method name', 'Short name']].values}\n",
    "    if method_name not in method_name_to_short_name:\n",
    "        return None\n",
    "    return method_name_to_short_name[method_name]\n",
    "\n",
    "\n",
    "processed_dfs = []\n",
    "n = 15\n",
    "for aspect in ['grammaticality', 'meaning_preservation', 'simplicity']:\n",
    "    df = single_feature_dfs[aspect].copy()\n",
    "    aspect = aspect.replace('_', '\\_')\n",
    "    df['team'] = df['team'].apply(get_short_name)\n",
    "    df = df.dropna()\n",
    "    df = df.head(n)[['team', 'valid_pearson', 'pearson']]\n",
    "    df.columns = [(aspect, 'Short name'), (aspect, 'Valid'), (aspect, 'Test')]\n",
    "    df.index = range(n)\n",
    "    processed_dfs.append(df)\n",
    "\n",
    "concat_df = pd.concat(processed_dfs, axis=1)\n",
    "concat_df.columns = pd.MultiIndex.from_tuples(concat_df.columns)\n",
    "print(to_latex(concat_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
